//! Service discovery and distributed coordination.
//!
//! This module provides abstractions for service discovery in distributed training,
//! allowing workers and parameter servers to find each other dynamically.
//!
//! # Implementations
//!
//! - [`InMemoryDiscovery`]: An in-memory implementation for testing and single-node setups.
//! - [`ZkDiscovery`]: ZooKeeper-based discovery (feature: `zookeeper`).
//! - [`ConsulDiscovery`]: Consul-based discovery (feature: `consul`).
//!
//! # Example
//!
//! ```rust
//! use monolith_training::discovery::{
//!     ServiceDiscovery, ServiceInfo, HealthStatus, InMemoryDiscovery,
//! };
//! use std::collections::HashMap;
//!
//! let discovery = InMemoryDiscovery::new();
//!
//! // Register a service
//! let service = ServiceInfo::new(
//!     "ps-0",
//!     "parameter-server",
//!     "ps",
//!     "127.0.0.1",
//!     5000,
//! );
//! discovery
//!     .register(service)
//!     .expect("in-memory register should succeed in usage example");
//!
//! // Discover services
//! let services = discovery
//!     .discover("ps")
//!     .expect("in-memory discover should succeed in usage example");
//! assert_eq!(services.len(), 1);
//! ```

use std::collections::HashMap;
#[cfg(any(feature = "zookeeper", feature = "consul", test))]
use std::future::Future;
#[cfg(any(feature = "zookeeper", feature = "consul"))]
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::{Arc, Mutex, RwLock};
use thiserror::Error;
use tokio::sync::broadcast::{self, Receiver, Sender};

#[cfg(feature = "consul")]
use rs_consul as consul;
#[cfg(feature = "zookeeper")]
use zookeeper_client as zk;

/// Errors that can occur during service discovery operations.
#[derive(Debug, Error)]
pub enum DiscoveryError {
    /// The service was not found.
    #[error("Service not found: {0}")]
    NotFound(String),

    /// Failed to connect to the discovery backend.
    #[error("Connection failed: {0}")]
    ConnectionFailed(String),

    /// The service is already registered.
    #[error("Service already registered: {0}")]
    AlreadyRegistered(String),

    /// A timeout occurred during the operation.
    #[error("Operation timed out: {0}")]
    Timeout(String),

    /// An internal error occurred.
    #[error("Internal error: {0}")]
    Internal(String),

    /// Configuration error.
    #[error("Configuration error: {0}")]
    ConfigError(String),
}

/// Result type for discovery operations.
pub type Result<T> = std::result::Result<T, DiscoveryError>;

/// Health status of a service.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, serde::Serialize, serde::Deserialize)]
pub enum HealthStatus {
    /// The service is healthy and ready to receive traffic.
    Healthy,
    /// The service is unhealthy and should not receive traffic.
    Unhealthy,
    /// The health status is unknown.
    Unknown,
    /// The service is starting up.
    Starting,
    /// The service is shutting down.
    Stopping,
}

impl Default for HealthStatus {
    fn default() -> Self {
        Self::Unknown
    }
}

/// Information about a registered service.
#[derive(Debug, Clone, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
pub struct ServiceInfo {
    /// Unique identifier for this service instance.
    pub id: String,
    /// Human-readable name of the service.
    pub name: String,
    /// Type of service (e.g., "ps" for parameter server, "worker" for worker).
    pub service_type: String,
    /// Host address of the service.
    pub host: String,
    /// Port number of the service.
    pub port: u16,
    /// Additional metadata about the service.
    pub metadata: HashMap<String, String>,
    /// Current health status of the service.
    pub health: HealthStatus,
}

impl ServiceInfo {
    /// Creates a new service info with the given parameters.
    ///
    /// # Arguments
    ///
    /// * `id` - Unique identifier for this service instance.
    /// * `name` - Human-readable name of the service.
    /// * `service_type` - Type of service.
    /// * `host` - Host address of the service.
    /// * `port` - Port number of the service.
    pub fn new(
        id: impl Into<String>,
        name: impl Into<String>,
        service_type: impl Into<String>,
        host: impl Into<String>,
        port: u16,
    ) -> Self {
        Self {
            id: id.into(),
            name: name.into(),
            service_type: service_type.into(),
            host: host.into(),
            port,
            metadata: HashMap::new(),
            health: HealthStatus::Unknown,
        }
    }

    /// Sets the health status.
    pub fn with_health(mut self, health: HealthStatus) -> Self {
        self.health = health;
        self
    }

    /// Adds metadata to the service info.
    pub fn with_metadata(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
        self.metadata.insert(key.into(), value.into());
        self
    }

    /// Returns the full address as a string.
    pub fn address(&self) -> String {
        format!("{}:{}", self.host, self.port)
    }
}

/// Events emitted by service discovery.
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum DiscoveryEvent {
    /// A new service was added.
    ServiceAdded(ServiceInfo),
    /// A service was removed.
    ServiceRemoved(String),
    /// A service was updated.
    ServiceUpdated(ServiceInfo),
}

/// Trait for service discovery implementations.
///
/// This trait defines the interface for service discovery backends,
/// allowing services to register themselves, discover other services,
/// and watch for changes.
pub trait ServiceDiscovery: Send + Sync {
    /// Registers a service with the discovery backend.
    ///
    /// # Arguments
    ///
    /// * `service` - The service information to register.
    ///
    /// # Returns
    ///
    /// `Ok(())` if the registration was successful, or an error otherwise.
    fn register(&self, service: ServiceInfo) -> Result<()>;

    /// Discovers all services of a given type.
    ///
    /// # Arguments
    ///
    /// * `service_type` - The type of services to discover.
    ///
    /// # Returns
    ///
    /// A list of services matching the given type.
    fn discover(&self, service_type: &str) -> Result<Vec<ServiceInfo>>;

    /// Watches for changes to services of a given type.
    ///
    /// # Arguments
    ///
    /// * `service_type` - The type of services to watch.
    ///
    /// # Returns
    ///
    /// A receiver that will receive discovery events.
    fn watch(&self, service_type: &str) -> Result<Receiver<DiscoveryEvent>>;

    /// Deregisters a service from the discovery backend.
    ///
    /// # Arguments
    ///
    /// * `service_id` - The ID of the service to deregister.
    ///
    /// # Returns
    ///
    /// `Ok(())` if the deregistration was successful, or an error otherwise.
    fn deregister(&self, service_id: &str) -> Result<()>;
}

/// Async-friendly service discovery API (used by the distributed runner).
///
/// For local/in-memory discovery we can implement these methods directly.
/// For ZK/Consul, callers can either wrap blocking APIs in `spawn_blocking`
/// or provide native async implementations later.
#[async_trait::async_trait]
pub trait ServiceDiscoveryAsync: Send + Sync {
    async fn connect(&self) -> Result<()>;
    async fn disconnect(&self) -> Result<()>;

    async fn register_async(&self, service: ServiceInfo) -> Result<()>;
    async fn discover_async(&self, service_type: &str) -> Result<Vec<ServiceInfo>>;
    async fn watch_async(&self, service_type: &str) -> Result<Receiver<DiscoveryEvent>>;

    async fn deregister_async(&self, service_id: &str) -> Result<()>;

    /// Backend-specific keepalive/heartbeat. Default is a no-op for backends
    /// that do not require explicit heartbeats (e.g. in-memory, ZK ephemerals).
    async fn heartbeat_async(&self, _service_id: &str) -> Result<()> {
        Ok(())
    }
}

#[async_trait::async_trait]
impl ServiceDiscoveryAsync for InMemoryDiscovery {
    async fn connect(&self) -> Result<()> {
        Ok(())
    }

    async fn disconnect(&self) -> Result<()> {
        Ok(())
    }

    async fn register_async(&self, service: ServiceInfo) -> Result<()> {
        self.register(service)
    }

    async fn discover_async(&self, service_type: &str) -> Result<Vec<ServiceInfo>> {
        self.discover(service_type)
    }

    async fn watch_async(&self, service_type: &str) -> Result<Receiver<DiscoveryEvent>> {
        self.watch(service_type)
    }

    async fn deregister_async(&self, service_id: &str) -> Result<()> {
        self.deregister(service_id)
    }
}

#[cfg(any(feature = "zookeeper", feature = "consul", test))]
fn spawn_watch_poll_loop<F, Fut, C, E>(
    sender: Sender<DiscoveryEvent>,
    backend: &'static str,
    poll_interval: std::time::Duration,
    should_continue: C,
    on_exit: E,
    mut poll_discover: F,
) -> tokio::task::JoinHandle<()>
where
    F: FnMut() -> Fut + Send + 'static,
    Fut: Future<Output = Result<Vec<ServiceInfo>>> + Send + 'static,
    C: Fn() -> bool + Send + 'static,
    E: FnOnce() + Send + 'static,
{
    tokio::spawn(async move {
        let mut prev: HashMap<String, ServiceInfo> = HashMap::new();
        loop {
            // If no receivers are subscribed anymore, stop the poller to avoid
            // leaking long-lived background tasks.
            if sender.receiver_count() == 0 || !should_continue() {
                break;
            }

            let next_list = match poll_discover().await {
                Ok(v) => v,
                Err(e) => {
                    tracing::debug!(
                        backend = backend,
                        error = %e,
                        "Discovery watch poll discover failed"
                    );
                    if matches!(e, DiscoveryError::ConfigError(_)) {
                        tracing::warn!(
                            backend = backend,
                            error = %e,
                            "Discovery watch poll encountered configuration error and will stop"
                        );
                        break;
                    }
                    if !should_continue() {
                        break;
                    }
                    tokio::time::sleep(poll_interval).await;
                    continue;
                }
            };

            let mut next: HashMap<String, ServiceInfo> = HashMap::new();
            for s in next_list {
                next.insert(s.id.clone(), s);
            }

            let mut should_stop = false;
            for (id, s) in next.iter() {
                let send_result = match prev.get(id) {
                    None => sender.send(DiscoveryEvent::ServiceAdded(s.clone())),
                    Some(prev_s) if prev_s != s => {
                        sender.send(DiscoveryEvent::ServiceUpdated(s.clone()))
                    }
                    Some(_) => continue,
                };
                if send_result.is_err() {
                    should_stop = true;
                    break;
                }
            }
            if !should_stop {
                for id in prev.keys() {
                    if !next.contains_key(id)
                        && sender.send(DiscoveryEvent::ServiceRemoved(id.clone())).is_err()
                    {
                        should_stop = true;
                        break;
                    }
                }
            }
            if should_stop {
                break;
            }

            prev = next;
            tokio::time::sleep(poll_interval).await;
        }

        on_exit();
    })
}

/// In-memory service discovery implementation for testing.
///
/// This implementation stores all service information in memory and is
/// suitable for testing and single-node deployments.
///
/// # Example
///
/// ```rust
/// use monolith_training::discovery::{InMemoryDiscovery, ServiceInfo, ServiceDiscovery};
///
/// let discovery = InMemoryDiscovery::new();
///
/// let service = ServiceInfo::new("ps-0", "PS 0", "ps", "localhost", 5000);
/// discovery
///     .register(service)
///     .expect("in-memory register should succeed in usage example");
///
/// let services = discovery
///     .discover("ps")
///     .expect("in-memory discover should succeed in usage example");
/// assert_eq!(services.len(), 1);
/// ```
pub struct InMemoryDiscovery {
    /// Registered services indexed by ID.
    services: RwLock<HashMap<String, ServiceInfo>>,
    /// Event senders for each service type.
    watchers: Mutex<HashMap<String, Sender<DiscoveryEvent>>>,
}

impl InMemoryDiscovery {
    /// Creates a new in-memory discovery instance.
    pub fn new() -> Self {
        Self {
            services: RwLock::new(HashMap::new()),
            watchers: Mutex::new(HashMap::new()),
        }
    }

    /// Returns the number of registered services.
    pub fn len(&self) -> usize {
        self.services
            .read()
            .expect("in-memory discovery services read lock should not be poisoned")
            .len()
    }

    /// Returns true if no services are registered.
    pub fn is_empty(&self) -> bool {
        self.services
            .read()
            .expect("in-memory discovery services read lock should not be poisoned")
            .is_empty()
    }

    /// Clears all registered services.
    pub fn clear(&self) {
        let mut services = self
            .services
            .write()
            .expect("in-memory discovery services write lock should not be poisoned");
        let service_ids: Vec<String> = services.keys().cloned().collect();

        for id in service_ids {
            if let Some(service) = services.remove(&id) {
                self.notify_watchers(&service.service_type, DiscoveryEvent::ServiceRemoved(id));
            }
        }
    }

    /// Updates the health status of a service.
    pub fn update_health(&self, service_id: &str, health: HealthStatus) -> Result<()> {
        let mut services = self
            .services
            .write()
            .expect("in-memory discovery services write lock should not be poisoned");
        let service = services
            .get_mut(service_id)
            .ok_or_else(|| DiscoveryError::NotFound(service_id.to_string()))?;

        service.health = health;
        let updated_service = service.clone();
        let service_type = service.service_type.clone();
        drop(services);

        self.notify_watchers(
            &service_type,
            DiscoveryEvent::ServiceUpdated(updated_service),
        );
        Ok(())
    }

    /// Notifies watchers of an event.
    fn notify_watchers(&self, service_type: &str, event: DiscoveryEvent) {
        let mut watchers = self
            .watchers
            .lock()
            .expect("in-memory discovery watchers mutex should not be poisoned");
        if let Some(sender) = watchers.get(service_type) {
            if sender.receiver_count() == 0 || sender.send(event).is_err() {
                // No active subscribers for this service type anymore.
                watchers.remove(service_type);
            }
        }
    }

    /// Gets or creates a sender for a service type.
    fn get_or_create_sender(&self, service_type: &str) -> Sender<DiscoveryEvent> {
        let mut watchers = self
            .watchers
            .lock()
            .expect("in-memory discovery watchers mutex should not be poisoned");
        watchers
            .entry(service_type.to_string())
            .or_insert_with(|| broadcast::channel(100).0)
            .clone()
    }
}

impl Default for InMemoryDiscovery {
    fn default() -> Self {
        Self::new()
    }
}

impl ServiceDiscovery for InMemoryDiscovery {
    fn register(&self, service: ServiceInfo) -> Result<()> {
        let mut services = self
            .services
            .write()
            .expect("in-memory discovery services write lock should not be poisoned");

        let is_update = services.contains_key(&service.id);
        // Default behavior: duplicate registration is an error. We only allow updates
        // when the caller explicitly marks the registration as idempotent.
        //
        // This keeps existing semantics/tests intact while still enabling the runner
        // to re-register after binding to an ephemeral port.
        let allow_update = service
            .metadata
            .get("allow_update")
            .map(|v| v == "true")
            .unwrap_or(false);
        if is_update && !allow_update {
            return Err(DiscoveryError::AlreadyRegistered(service.id.clone()));
        }

        let service_type = service.service_type.clone();
        let service_clone = service.clone();
        services.insert(service.id.clone(), service);
        drop(services);

        tracing::info!(
            service_id = %service_clone.id,
            service_type = %service_type,
            address = %service_clone.address(),
            "Registered service"
        );

        if is_update {
            self.notify_watchers(&service_type, DiscoveryEvent::ServiceUpdated(service_clone));
        } else {
            self.notify_watchers(&service_type, DiscoveryEvent::ServiceAdded(service_clone));
        }
        Ok(())
    }

    fn discover(&self, service_type: &str) -> Result<Vec<ServiceInfo>> {
        let services = self
            .services
            .read()
            .expect("in-memory discovery services read lock should not be poisoned");
        let matching: Vec<ServiceInfo> = services
            .values()
            .filter(|s| s.service_type == service_type)
            .cloned()
            .collect();

        tracing::debug!(
            service_type = %service_type,
            count = matching.len(),
            "Discovered services"
        );

        Ok(matching)
    }

    fn watch(&self, service_type: &str) -> Result<Receiver<DiscoveryEvent>> {
        let sender = self.get_or_create_sender(service_type);
        Ok(sender.subscribe())
    }

    fn deregister(&self, service_id: &str) -> Result<()> {
        let mut services = self
            .services
            .write()
            .expect("in-memory discovery services write lock should not be poisoned");

        let service = services
            .remove(service_id)
            .ok_or_else(|| DiscoveryError::NotFound(service_id.to_string()))?;

        let service_type = service.service_type.clone();
        drop(services);

        tracing::info!(
            service_id = %service_id,
            service_type = %service_type,
            "Deregistered service"
        );

        self.notify_watchers(
            &service_type,
            DiscoveryEvent::ServiceRemoved(service_id.to_string()),
        );
        Ok(())
    }
}

/// ZooKeeper-based service discovery.
///
/// This is a stub implementation that provides the interface for ZooKeeper-based
/// service discovery. The actual implementation requires the `zookeeper` feature.
///
/// # Configuration
///
/// ZooKeeper discovery requires the following configuration:
/// - `hosts`: Comma-separated list of ZooKeeper hosts
/// - `base_path`: Base path for service registration (default: `/services`)
/// - `session_timeout`: Session timeout in milliseconds (default: 30000)
#[cfg(feature = "zookeeper")]
pub struct ZkDiscovery {
    /// ZooKeeper connection hosts.
    hosts: String,
    /// Base path for service registration.
    base_path: String,
    /// Session timeout in milliseconds.
    session_timeout_ms: u64,
    /// Connected ZooKeeper client (set on `connect()`).
    client: tokio::sync::Mutex<Option<zk::Client>>,
    /// Paths for ephemerals registered by this process (keyed by service_id).
    registered_paths: tokio::sync::Mutex<HashMap<String, String>>,
    /// In-memory cache of services.
    services: RwLock<HashMap<String, ServiceInfo>>,
    /// Event senders for watchers.
    watchers: Arc<Mutex<HashMap<String, Sender<DiscoveryEvent>>>>,
    /// Generation counter for watch lifecycle control.
    watch_generation: Arc<AtomicU64>,
    /// Active watch-poll generations keyed by service type.
    watch_poll_generations: Arc<Mutex<HashMap<String, u64>>>,
}

#[cfg(feature = "zookeeper")]
impl ZkDiscovery {
    /// Creates a new ZooKeeper discovery instance.
    ///
    /// # Arguments
    ///
    /// * `hosts` - Comma-separated list of ZooKeeper hosts.
    /// * `base_path` - Base path for service registration.
    pub fn new(hosts: impl Into<String>, base_path: impl Into<String>) -> Self {
        Self {
            hosts: hosts.into(),
            base_path: base_path.into(),
            session_timeout_ms: 30000,
            client: tokio::sync::Mutex::new(None),
            registered_paths: tokio::sync::Mutex::new(HashMap::new()),
            services: RwLock::new(HashMap::new()),
            watchers: Arc::new(Mutex::new(HashMap::new())),
            watch_generation: Arc::new(AtomicU64::new(0)),
            watch_poll_generations: Arc::new(Mutex::new(HashMap::new())),
        }
    }

    /// Sets the session timeout.
    pub fn with_session_timeout(mut self, timeout_ms: u64) -> Self {
        self.session_timeout_ms = timeout_ms;
        self
    }

    /// Connects to ZooKeeper.
    ///
    /// This is a placeholder that would establish a connection to ZooKeeper.
    pub async fn connect(&self) -> Result<()> {
        validate_zk_hosts_for_operation("connect", &self.hosts)?;
        validate_zk_base_path_for_operation("connect", &self.base_path)?;

        tracing::info!(hosts = %self.hosts, base_path = %self.base_path, "Connecting to ZooKeeper");

        let mut guard = self.client.lock().await;
        if guard.is_some() {
            return Ok(());
        }

        let client = zk::Client::connector()
            .with_session_timeout(std::time::Duration::from_millis(self.session_timeout_ms))
            .connect(&self.hosts)
            .await
            .map_err(|e| DiscoveryError::ConnectionFailed(format!("ZK connect failed: {e}")))?;

        // Ensure base_path exists.
        // ZK has no "mkdir -p" primitive; create parents best-effort.
        ensure_zk_path(&client, &self.base_path).await?;

        *guard = Some(client);
        Ok(())
    }

    /// Disconnects from ZooKeeper.
    pub async fn disconnect(&self) -> Result<()> {
        tracing::info!("Disconnecting from ZooKeeper");

        // Drop the client, which closes the session and cleans ephemerals.
        {
            let mut guard = self.client.lock().await;
            *guard = None;
        }
        self.registered_paths.lock().await.clear();
        self.compact_dead_watch_senders();
        self.watch_generation.fetch_add(1, Ordering::SeqCst);
        self.watch_poll_generations
            .lock()
            .expect("zk discovery watch_poll_generations mutex should not be poisoned")
            .clear();
        Ok(())
    }

    /// Gets or creates a sender for a service type.
    fn get_or_create_sender(&self, service_type: &str) -> Sender<DiscoveryEvent> {
        let mut watchers = self
            .watchers
            .lock()
            .expect("zk discovery watchers mutex should not be poisoned");
        watchers
            .entry(service_type.to_string())
            .or_insert_with(|| broadcast::channel(100).0)
            .clone()
    }

    /// Notifies watchers for a service type and removes dead sender entries.
    fn notify_watchers(&self, service_type: &str, event: DiscoveryEvent) {
        let mut watchers = self
            .watchers
            .lock()
            .expect("zk discovery watchers mutex should not be poisoned");
        if let Some(sender) = watchers.get(service_type) {
            if sender.receiver_count() == 0 || sender.send(event).is_err() {
                watchers.remove(service_type);
            }
        }
    }

    /// Removes watcher sender for `service_type` if all receivers are dropped.
    fn compact_dead_watch_sender(&self, service_type: &str) {
        let mut watchers = self
            .watchers
            .lock()
            .expect("zk discovery watchers mutex should not be poisoned");
        if watchers
            .get(service_type)
            .map(|s| s.receiver_count() == 0)
            .unwrap_or(false)
        {
            watchers.remove(service_type);
        }
    }

    /// Compacts all watcher senders that have no active receivers.
    fn compact_dead_watch_senders(&self) {
        self.watchers
            .lock()
            .expect("zk discovery watchers mutex should not be poisoned")
            .retain(|_, sender| sender.receiver_count() > 0);
    }

    /// Returns true only when a new poll loop should be spawned for the service type.
    fn should_spawn_watch_poll(&self, service_type: &str) -> bool {
        let generation = self.watch_generation.load(Ordering::SeqCst);
        let mut active = self
            .watch_poll_generations
            .lock()
            .expect("zk discovery watch_poll_generations mutex should not be poisoned");
        match active.get(service_type).copied() {
            Some(g) if g == generation => false,
            _ => {
                active.insert(service_type.to_string(), generation);
                true
            }
        }
    }

    /// Cleans a poll-generation entry if it still matches the expected generation.
    fn cleanup_watch_poll_generation(&self, service_type: &str, generation: u64) {
        let mut active = self
            .watch_poll_generations
            .lock()
            .expect("zk discovery watch_poll_generations mutex should not be poisoned");
        if active.get(service_type).copied() == Some(generation) {
            active.remove(service_type);
        }
    }
}

#[cfg(feature = "zookeeper")]
impl ServiceDiscovery for ZkDiscovery {
    fn register(&self, service: ServiceInfo) -> Result<()> {
        tracing::info!(
            service_id = %service.id,
            service_type = %service.service_type,
            "Registering service with ZooKeeper"
        );

        // Keep sync API best-effort: update local cache only. The distributed runner uses
        // `ServiceDiscoveryAsync` for real ZK I/O.
        let mut services = self
            .services
            .write()
            .expect("zk discovery services write lock should not be poisoned");
        if services.contains_key(&service.id) {
            return Err(DiscoveryError::AlreadyRegistered(service.id.clone()));
        }
        services.insert(service.id.clone(), service.clone());

        let service_type = service.service_type.clone();
        self.notify_watchers(&service_type, DiscoveryEvent::ServiceAdded(service));
        Ok(())
    }

    fn discover(&self, service_type: &str) -> Result<Vec<ServiceInfo>> {
        tracing::debug!(
            service_type = %service_type,
            "Discovering services from ZooKeeper"
        );

        // Sync API returns from cache only; see `discover_async` for real ZK query.
        let services = self
            .services
            .read()
            .expect("zk discovery services read lock should not be poisoned");
        Ok(services
            .values()
            .filter(|s| s.service_type == service_type)
            .cloned()
            .collect())
    }

    fn watch(&self, service_type: &str) -> Result<Receiver<DiscoveryEvent>> {
        tracing::debug!(
            service_type = %service_type,
            "Setting up ZooKeeper watch"
        );

        let sender = self.get_or_create_sender(service_type);
        Ok(sender.subscribe())
    }

    fn deregister(&self, service_id: &str) -> Result<()> {
        tracing::info!(
            service_id = %service_id,
            "Deregistering service from ZooKeeper"
        );

        // Cache-only removal for sync API.
        let mut services = self
            .services
            .write()
            .expect("zk discovery services write lock should not be poisoned");
        let service = services
            .remove(service_id)
            .ok_or_else(|| DiscoveryError::NotFound(service_id.to_string()))?;
        drop(services);

        self.notify_watchers(
            &service.service_type,
            DiscoveryEvent::ServiceRemoved(service_id.to_string()),
        );
        Ok(())
    }
}

#[cfg(feature = "zookeeper")]
#[async_trait::async_trait]
impl ServiceDiscoveryAsync for ZkDiscovery {
    async fn connect(&self) -> Result<()> {
        ZkDiscovery::connect(self).await
    }

    async fn disconnect(&self) -> Result<()> {
        ZkDiscovery::disconnect(self).await
    }

    async fn register_async(&self, service: ServiceInfo) -> Result<()> {
        self.connect().await.map_err(|e| {
            self.compact_dead_watch_sender(&service.service_type);
            e
        })?;

        let client =
            self.client
                .lock()
                .await
                .as_ref()
                .cloned()
                .ok_or_else(|| {
                    self.compact_dead_watch_sender(&service.service_type);
                    DiscoveryError::ConnectionFailed("ZK client not connected".into())
                })?;

        let idx = service
            .metadata
            .get("index")
            .and_then(|s| s.parse::<i32>().ok())
            .or_else(|| {
                service
                    .id
                    .rsplit_once('-')
                    .and_then(|(_, n)| n.parse::<i32>().ok())
            })
            .unwrap_or(0);

        // Match Python: /monolith/<job>/<service_type>.<index> with payload "host:port".
        let path = format!(
            "{}/{}.{}",
            self.base_path.trim_end_matches('/'),
            service.service_type,
            idx
        );
        let data = service.address().into_bytes();

        // Create ephemeral node with payload "host:port". If exists, set_data.
        let create_opts = zk::CreateMode::Ephemeral.with_acls(zk::Acls::anyone_all());
        match client.create(&path, &data, &create_opts).await {
            Ok(_) => {}
            Err(zk::Error::NodeExists) => {
                client
                    .set_data(&path, &data, None)
                    .await
                    .map_err(|e| {
                        self.compact_dead_watch_sender(&service.service_type);
                        DiscoveryError::Internal(format!("ZK set_data failed: {e}"))
                    })?;
            }
            Err(e) => {
                self.compact_dead_watch_sender(&service.service_type);
                return Err(DiscoveryError::Internal(format!("ZK create failed: {e}")));
            }
        };

        self.registered_paths
            .lock()
            .await
            .insert(service.id.clone(), path.clone());

        // Update local cache (for quick discover + tests).
        self.services
            .write()
            .expect("zk discovery services write lock should not be poisoned")
            .insert(service.id.clone(), service.clone());
        let service_type = service.service_type.clone();
        self.notify_watchers(&service_type, DiscoveryEvent::ServiceAdded(service));
        Ok(())
    }

    async fn discover_async(&self, service_type: &str) -> Result<Vec<ServiceInfo>> {
        self.connect().await?;
        let client =
            self.client.lock().await.as_ref().cloned().ok_or_else(|| {
                DiscoveryError::ConnectionFailed("ZK client not connected".into())
            })?;

        let base = self.base_path.trim_end_matches('/');
        let children = client
            .list_children(base)
            .await
            .map_err(|e| DiscoveryError::Internal(format!("ZK list_children failed: {e}")))?;

        let mut out = Vec::new();
        for child in children {
            let name = child;
            if !name.starts_with(&format!("{}.", service_type)) {
                continue;
            }
            let path = format!("{}/{}", base, name);
            if let Ok((data, _stat)) = client.get_data(&path).await {
                if let Ok(addr) = String::from_utf8(data) {
                    if let Some((host, port_str)) = addr.split_once(':') {
                        if let Ok(port) = port_str.parse::<u16>() {
                            let idx = name
                                .trim_start_matches(&format!("{}.", service_type))
                                .to_string();
                            let id = format!("{}-{}", service_type, idx);
                            let mut svc =
                                ServiceInfo::new(id.clone(), id.clone(), service_type, host, port);
                            svc.metadata.insert("addr".into(), addr.clone());
                            svc.metadata.insert("index".into(), idx);
                            out.push(svc);
                        }
                    }
                }
            }
        }

        // Keep cache in sync.
        {
            let mut cache = self
                .services
                .write()
                .expect("zk discovery services write lock should not be poisoned");
            cache.retain(|_, v| v.service_type != service_type);
            for svc in &out {
                cache.insert(svc.id.clone(), svc.clone());
            }
        }

        Ok(out)
    }

    async fn watch_async(&self, service_type: &str) -> Result<Receiver<DiscoveryEvent>> {
        validate_zk_hosts_for_operation("watch_service", &self.hosts).map_err(|e| {
            self.compact_dead_watch_sender(service_type);
            e
        })?;
        validate_zk_base_path_for_operation("watch_service", &self.base_path).map_err(|e| {
            self.compact_dead_watch_sender(service_type);
            e
        })?;

        // Poll-based watcher: keeps parity with Python's callback-based watchers without
        // relying on ZK persistent watch semantics (which can be lossy during reconnect).
        let sender = self.get_or_create_sender(service_type);
        let rx = sender.subscribe();

        if self.should_spawn_watch_poll(service_type) {
            let svc_type = service_type.to_string();
            let this = Arc::new(self.clone_for_watch());
            let sender_for_poll = sender.clone();
            let watch_generation = Arc::clone(&self.watch_generation);
            let this_for_cleanup = Arc::clone(&this);
            let generation = watch_generation.load(Ordering::SeqCst);
            let svc_type_for_cleanup = svc_type.clone();
            spawn_watch_poll_loop(
                sender_for_poll,
                "zk",
                std::time::Duration::from_secs(1),
                move || watch_generation.load(Ordering::SeqCst) == generation,
                move || {
                    this_for_cleanup
                        .cleanup_watch_poll_generation(&svc_type_for_cleanup, generation);
                    this_for_cleanup.compact_dead_watch_sender(&svc_type_for_cleanup);
                },
                move || {
                    let this = Arc::clone(&this);
                    let svc_type = svc_type.clone();
                    async move { this.discover_async(&svc_type).await }
                },
            );
        }

        Ok(rx)
    }

    async fn deregister_async(&self, service_id: &str) -> Result<()> {
        let service = match {
            let mut services = self
                .services
                .write()
                .expect("zk discovery services write lock should not be poisoned");
            services.remove(service_id)
        } {
            Some(service) => service,
            None => {
                // Best-effort stale-path cleanup for drift between local cache and
                // backend registration bookkeeping.
                self.registered_paths.lock().await.remove(service_id);
                return Err(DiscoveryError::NotFound(service_id.to_string()));
            }
        };
        self.notify_watchers(
            &service.service_type,
            DiscoveryEvent::ServiceRemoved(service_id.to_string()),
        );

        let path_opt = self.registered_paths.lock().await.remove(service_id);
        let Some(path) = path_opt else {
            return Ok(());
        };

        let mut remote_error: Option<DiscoveryError> = None;
        if let Err(e) = self.connect().await {
            remote_error = Some(e);
        } else {
            let client_opt = self.client.lock().await.as_ref().cloned();
            match client_opt {
                Some(client) => {
                    if let Err(e) = client.delete(&path, None).await {
                        remote_error = Some(DiscoveryError::Internal(format!("ZK delete failed: {e}")));
                    }
                }
                None => {
                    remote_error =
                        Some(DiscoveryError::ConnectionFailed("ZK client not connected".into()));
                }
            }
        }

        if let Some(err) = remote_error {
            Err(err)
        } else {
            Ok(())
        }
    }
}

/// Consul-based service discovery.
///
/// This is a stub implementation that provides the interface for Consul-based
/// service discovery. The actual implementation requires the `consul` feature.
///
/// # Configuration
///
/// Consul discovery requires the following configuration:
/// - `address`: Consul agent address (default: `http://localhost:8500`)
/// - `datacenter`: Datacenter name (optional)
/// - `token`: ACL token for authentication (optional)
#[cfg(feature = "consul")]
pub struct ConsulDiscovery {
    /// Consul agent address.
    address: String,
    /// Datacenter name.
    datacenter: Option<String>,
    /// ACL token for authentication.
    token: Option<String>,
    /// Connected Consul client.
    client: tokio::sync::Mutex<Option<Arc<consul::Consul>>>,
    /// Consul "service name" used for discovery.
    service_name: String,
    /// In-memory cache of services.
    services: RwLock<HashMap<String, ServiceInfo>>,
    /// Event senders for watchers.
    watchers: Arc<Mutex<HashMap<String, Sender<DiscoveryEvent>>>>,
    /// Generation counter for watch lifecycle control.
    watch_generation: Arc<AtomicU64>,
    /// Active watch-poll generations keyed by service type.
    watch_poll_generations: Arc<Mutex<HashMap<String, u64>>>,
}

#[cfg(feature = "consul")]
impl ConsulDiscovery {
    /// Creates a new Consul discovery instance.
    ///
    /// # Arguments
    ///
    /// * `address` - Consul agent address.
    pub fn new(address: impl Into<String>) -> Self {
        Self {
            address: address.into(),
            datacenter: None,
            token: None,
            client: tokio::sync::Mutex::new(None),
            service_name: "monolith".to_string(),
            services: RwLock::new(HashMap::new()),
            watchers: Arc::new(Mutex::new(HashMap::new())),
            watch_generation: Arc::new(AtomicU64::new(0)),
            watch_poll_generations: Arc::new(Mutex::new(HashMap::new())),
        }
    }

    /// Sets the datacenter.
    pub fn with_datacenter(mut self, datacenter: impl Into<String>) -> Self {
        self.datacenter = Some(datacenter.into());
        self
    }

    /// Sets the ACL token.
    pub fn with_token(mut self, token: impl Into<String>) -> Self {
        self.token = Some(token.into());
        self
    }

    /// Sets the Consul service name used for registration/discovery.
    pub fn with_service_name(mut self, service_name: impl Into<String>) -> Self {
        self.service_name = service_name.into();
        self
    }

    /// Connects to Consul.
    ///
    /// This is a placeholder that would establish a connection to Consul.
    pub async fn connect(&self) -> Result<()> {
        tracing::info!(
            address = %self.address,
            datacenter = ?self.datacenter,
            "Connecting to Consul"
        );
        let mut guard = self.client.lock().await;
        if guard.is_some() {
            return Ok(());
        }
        let normalized_address = normalize_consul_address_for_operation("connect", &self.address)?;
        let mut cfg = consul::Config {
            address: normalized_address,
            token: self.token.clone(),
            ..Default::default()
        };
        // `rs-consul` uses QueryOptions for datacenter; keep here for parity.
        if cfg.address.is_empty() {
            cfg.address = "http://127.0.0.1:8500".to_string();
        }
        *guard = Some(Arc::new(consul::Consul::new(cfg)));
        Ok(())
    }

    /// Gets or creates a sender for a service type.
    fn get_or_create_sender(&self, service_type: &str) -> Sender<DiscoveryEvent> {
        let mut watchers = self
            .watchers
            .lock()
            .expect("consul discovery watchers mutex should not be poisoned");
        watchers
            .entry(service_type.to_string())
            .or_insert_with(|| broadcast::channel(100).0)
            .clone()
    }

    /// Notifies watchers for a service type and removes dead sender entries.
    fn notify_watchers(&self, service_type: &str, event: DiscoveryEvent) {
        let mut watchers = self
            .watchers
            .lock()
            .expect("consul discovery watchers mutex should not be poisoned");
        if let Some(sender) = watchers.get(service_type) {
            if sender.receiver_count() == 0 || sender.send(event).is_err() {
                watchers.remove(service_type);
            }
        }
    }

    /// Removes watcher sender for `service_type` if all receivers are dropped.
    fn compact_dead_watch_sender(&self, service_type: &str) {
        let mut watchers = self
            .watchers
            .lock()
            .expect("consul discovery watchers mutex should not be poisoned");
        if watchers
            .get(service_type)
            .map(|s| s.receiver_count() == 0)
            .unwrap_or(false)
        {
            watchers.remove(service_type);
        }
    }

    /// Compacts all watcher senders that have no active receivers.
    fn compact_dead_watch_senders(&self) {
        self.watchers
            .lock()
            .expect("consul discovery watchers mutex should not be poisoned")
            .retain(|_, sender| sender.receiver_count() > 0);
    }

    /// Returns true only when a new poll loop should be spawned for the service type.
    fn should_spawn_watch_poll(&self, service_type: &str) -> bool {
        let generation = self.watch_generation.load(Ordering::SeqCst);
        let mut active = self
            .watch_poll_generations
            .lock()
            .expect("consul discovery watch_poll_generations mutex should not be poisoned");
        match active.get(service_type).copied() {
            Some(g) if g == generation => false,
            _ => {
                active.insert(service_type.to_string(), generation);
                true
            }
        }
    }

    /// Cleans a poll-generation entry if it still matches the expected generation.
    fn cleanup_watch_poll_generation(&self, service_type: &str, generation: u64) {
        let mut active = self
            .watch_poll_generations
            .lock()
            .expect("consul discovery watch_poll_generations mutex should not be poisoned");
        if active.get(service_type).copied() == Some(generation) {
            active.remove(service_type);
        }
    }
}

#[cfg(feature = "consul")]
impl ServiceDiscovery for ConsulDiscovery {
    fn register(&self, service: ServiceInfo) -> Result<()> {
        tracing::info!(
            service_id = %service.id,
            service_type = %service.service_type,
            "Registering service with Consul"
        );

        // Cache-only for sync API.
        let mut services = self
            .services
            .write()
            .expect("consul discovery services write lock should not be poisoned");
        if services.contains_key(&service.id) {
            return Err(DiscoveryError::AlreadyRegistered(service.id.clone()));
        }
        services.insert(service.id.clone(), service.clone());
        let service_type = service.service_type.clone();
        self.notify_watchers(&service_type, DiscoveryEvent::ServiceAdded(service));
        Ok(())
    }

    fn discover(&self, service_type: &str) -> Result<Vec<ServiceInfo>> {
        tracing::debug!(
            service_type = %service_type,
            "Discovering services from Consul"
        );

        // Cache-only for sync API.
        let services = self
            .services
            .read()
            .expect("consul discovery services read lock should not be poisoned");
        Ok(services
            .values()
            .filter(|s| s.service_type == service_type)
            .cloned()
            .collect())
    }

    fn watch(&self, service_type: &str) -> Result<Receiver<DiscoveryEvent>> {
        tracing::debug!(
            service_type = %service_type,
            "Setting up Consul watch"
        );

        let sender = self.get_or_create_sender(service_type);
        Ok(sender.subscribe())
    }

    fn deregister(&self, service_id: &str) -> Result<()> {
        tracing::info!(
            service_id = %service_id,
            "Deregistering service from Consul"
        );

        let mut services = self
            .services
            .write()
            .expect("consul discovery services write lock should not be poisoned");
        let service = services
            .remove(service_id)
            .ok_or_else(|| DiscoveryError::NotFound(service_id.to_string()))?;
        drop(services);

        self.notify_watchers(
            &service.service_type,
            DiscoveryEvent::ServiceRemoved(service_id.to_string()),
        );
        Ok(())
    }
}

#[cfg(feature = "consul")]
#[async_trait::async_trait]
impl ServiceDiscoveryAsync for ConsulDiscovery {
    async fn connect(&self) -> Result<()> {
        ConsulDiscovery::connect(self).await
    }

    async fn disconnect(&self) -> Result<()> {
        {
            let mut guard = self.client.lock().await;
            *guard = None;
        }
        self.compact_dead_watch_senders();
        self.watch_generation.fetch_add(1, Ordering::SeqCst);
        self.watch_poll_generations
            .lock()
            .expect("consul discovery watch_poll_generations mutex should not be poisoned")
            .clear();
        Ok(())
    }

    async fn register_async(&self, service: ServiceInfo) -> Result<()> {
        normalize_consul_address_for_operation("register_entity", &self.address).map_err(|e| {
            self.compact_dead_watch_sender(&service.service_type);
            e
        })?;
        self.connect().await.map_err(|e| {
            self.compact_dead_watch_sender(&service.service_type);
            e
        })?;
        let client = self.client.lock().await.as_ref().cloned().ok_or_else(|| {
            self.compact_dead_watch_sender(&service.service_type);
            DiscoveryError::ConnectionFailed("Consul client not connected".into())
        })?;

        // Use the global catalog register endpoint (HashiCorp Consul).
        //
        // NOTE: Python's `monolith/native_training/consul.py` uses a ByteDance-specific
        // lookup API. This Rust implementation targets stock Consul deployments.
        let tags = vec![
            format!("name:{}", service.service_type),
            format!(
                "index:{}",
                service.metadata.get("index").cloned().unwrap_or_default()
            ),
            format!("ip:{}", service.host),
        ];

        let svc = consul::types::RegisterEntityService {
            ID: Some(service.id.clone()),
            Service: self.service_name.clone(),
            Tags: tags,
            TaggedAddresses: HashMap::new(),
            Meta: HashMap::new(),
            Port: Some(service.port),
            Namespace: None,
        };

        let payload = consul::types::RegisterEntityPayload {
            ID: None,
            Node: service.id.clone(),
            Address: service.host.clone(),
            Datacenter: self.datacenter.clone(),
            TaggedAddresses: HashMap::new(),
            NodeMeta: HashMap::new(),
            Service: Some(svc),
            Checks: Vec::new(),
            SkipNodeUpdate: Some(true),
        };

        client.register_entity(&payload).await.map_err(|e| {
            self.compact_dead_watch_sender(&service.service_type);
            map_consul_request_error("register_entity", e)
        })?;

        self.services
            .write()
            .expect("consul discovery services write lock should not be poisoned")
            .insert(service.id.clone(), service.clone());
        let service_type = service.service_type.clone();
        self.notify_watchers(&service_type, DiscoveryEvent::ServiceAdded(service));
        Ok(())
    }

    async fn discover_async(&self, service_type: &str) -> Result<Vec<ServiceInfo>> {
        normalize_consul_address_for_operation("get_service_nodes", &self.address)?;
        self.connect().await?;
        let client = self.client.lock().await.as_ref().cloned().ok_or_else(|| {
            DiscoveryError::ConnectionFailed("Consul client not connected".into())
        })?;

        let consul_service = self.service_name.as_str();
        let nodes = client
            .get_service_nodes(
                consul::types::GetServiceNodesRequest {
                    service: consul_service,
                    passing: true,
                    ..Default::default()
                },
                None,
            )
            .await
            .map_err(|e| map_consul_request_error("get_service_nodes", e))?;

        let mut out = Vec::new();
        for sn in nodes.response {
            // Filter by tags for this service_type (we stored as "name:<type>").
            if !sn
                .service
                .tags
                .iter()
                .any(|t| t == &format!("name:{}", service_type))
            {
                continue;
            }

            let host = if sn.service.address.is_empty() {
                sn.node.address
            } else {
                sn.service.address
            };
            let port = sn.service.port;
            let id = sn.service.id;

            let mut svc = ServiceInfo::new(id.clone(), id.clone(), service_type, host, port);
            svc.metadata.insert("addr".into(), svc.address());
            out.push(svc);
        }

        Ok(out)
    }

    async fn watch_async(&self, service_type: &str) -> Result<Receiver<DiscoveryEvent>> {
        normalize_consul_address_for_operation("watch_service", &self.address)
            .map_err(|e| {
                self.compact_dead_watch_sender(service_type);
                e
            })?;

        // Poll-based watcher to avoid depending on Consul long-poll semantics here.
        let sender = self.get_or_create_sender(service_type);
        let rx = sender.subscribe();

        if self.should_spawn_watch_poll(service_type) {
            let svc_type = service_type.to_string();
            let this = Arc::new(self.clone_for_watch());
            let sender_for_poll = sender.clone();
            let watch_generation = Arc::clone(&self.watch_generation);
            let this_for_cleanup = Arc::clone(&this);
            let generation = watch_generation.load(Ordering::SeqCst);
            let svc_type_for_cleanup = svc_type.clone();
            spawn_watch_poll_loop(
                sender_for_poll,
                "consul",
                std::time::Duration::from_secs(1),
                move || watch_generation.load(Ordering::SeqCst) == generation,
                move || {
                    this_for_cleanup
                        .cleanup_watch_poll_generation(&svc_type_for_cleanup, generation);
                    this_for_cleanup.compact_dead_watch_sender(&svc_type_for_cleanup);
                },
                move || {
                    let this = Arc::clone(&this);
                    let svc_type = svc_type.clone();
                    async move { this.discover_async(&svc_type).await }
                },
            );
        }

        Ok(rx)
    }

    async fn deregister_async(&self, service_id: &str) -> Result<()> {
        let service = self
            .services
            .write()
            .expect("consul discovery services write lock should not be poisoned")
            .remove(service_id)
            .ok_or_else(|| DiscoveryError::NotFound(service_id.to_string()))?;
        self.notify_watchers(
            &service.service_type,
            DiscoveryEvent::ServiceRemoved(service_id.to_string()),
        );

        normalize_consul_address_for_operation("deregister_entity", &self.address)?;
        self.connect().await?;
        let client = self.client.lock().await.as_ref().cloned().ok_or_else(|| {
            DiscoveryError::ConnectionFailed("Consul client not connected".into())
        })?;

        let payload = consul::types::DeregisterEntityPayload {
            Node: None,
            Datacenter: self.datacenter.clone(),
            CheckID: None,
            ServiceID: Some(service_id.to_string()),
            Namespace: None,
        };

        client
            .deregister_entity(&payload)
            .await
            .map_err(|e| map_consul_request_error("deregister_entity", e))?;
        Ok(())
    }
}

// ============================================================================
// Helpers
// ============================================================================

#[cfg(feature = "zookeeper")]
async fn ensure_zk_path(client: &zk::Client, path: &str) -> Result<()> {
    let mut cur = String::new();
    for part in path.split('/').filter(|p| !p.is_empty()) {
        cur.push('/');
        cur.push_str(part);
        let opts = zk::CreateMode::Persistent.with_acls(zk::Acls::anyone_all());
        let _ = client.create(&cur, b"", &opts).await;
    }
    Ok(())
}

#[cfg(feature = "zookeeper")]
fn validate_zk_hosts_for_operation(context: &str, hosts: &str) -> Result<()> {
    let cfg_err =
        |detail: &str| DiscoveryError::ConfigError(format!("ZooKeeper {context} invalid hosts: {detail}"));

    if hosts.trim() != hosts {
        return Err(cfg_err("leading/trailing whitespace"));
    }
    if hosts.is_empty() {
        return Err(cfg_err("empty hosts"));
    }
    if hosts.chars().any(char::is_whitespace) {
        return Err(cfg_err("whitespace in hosts"));
    }
    for entry in hosts.split(',') {
        if entry.is_empty() {
            return Err(cfg_err("empty host entry"));
        }

        if let Some(rest) = entry.strip_prefix('[') {
            let (host, trailing) = rest
                .split_once(']')
                .ok_or_else(|| cfg_err("invalid host entry"))?;
            if host.is_empty() {
                return Err(cfg_err("empty host"));
            }
            if let Some(port) = trailing.strip_prefix(':') {
                if port.is_empty() {
                    return Err(cfg_err("invalid port"));
                }
                port.parse::<u16>().map_err(|_| cfg_err("invalid port"))?;
            } else if !trailing.is_empty() {
                return Err(cfg_err("invalid host entry"));
            }
            continue;
        }

        if let Some((host, port)) = entry.rsplit_once(':') {
            if host.contains(':') {
                return Err(cfg_err("invalid host entry"));
            }
            if host.is_empty() {
                return Err(cfg_err("empty host"));
            }
            if port.is_empty() {
                return Err(cfg_err("invalid port"));
            }
            if !port.chars().all(|c| c.is_ascii_digit()) {
                return Err(cfg_err("invalid port"));
            }
            port.parse::<u16>().map_err(|_| cfg_err("invalid port"))?;
        }
    }
    Ok(())
}

#[cfg(feature = "zookeeper")]
fn validate_zk_base_path_for_operation(context: &str, base_path: &str) -> Result<()> {
    let cfg_err = |detail: &str| {
        DiscoveryError::ConfigError(format!("ZooKeeper {context} invalid base_path: {detail}"))
    };

    if base_path.trim() != base_path {
        return Err(cfg_err("leading/trailing whitespace"));
    }
    if base_path.is_empty() {
        return Err(cfg_err("empty path"));
    }
    if !base_path.starts_with('/') {
        return Err(cfg_err("path must start with /"));
    }
    if base_path.chars().any(char::is_whitespace) {
        return Err(cfg_err("whitespace in path"));
    }
    if base_path.contains("//") {
        return Err(cfg_err("empty path segment"));
    }
    Ok(())
}

#[cfg(feature = "consul")]
fn map_consul_request_error(context: &str, err: impl std::fmt::Debug) -> DiscoveryError {
    let detail = format!("{err:?}");
    let detail_lower = detail.to_ascii_lowercase();
    let is_config_error = detail.contains("InvalidUri")
        || detail.contains("InvalidAuthority")
        || detail.contains("InvalidPort")
        || detail_lower.contains("invalid port")
        || detail_lower.contains("invalid scheme")
        || detail_lower.contains("invalid host")
        || detail_lower.contains("invalid authority")
        || detail_lower.contains("relative url without a base")
        || detail_lower.contains("empty host");

    if is_config_error {
        DiscoveryError::ConfigError(format!("Consul {context} invalid address: {detail}"))
    } else {
        DiscoveryError::Internal(format!("Consul {context} failed: {detail}"))
    }
}

#[cfg(feature = "consul")]
fn normalize_consul_address_for_operation(context: &str, address: &str) -> Result<String> {
    let cfg_err = |detail: &str| {
        DiscoveryError::ConfigError(format!("Consul {context} invalid address: {detail}"))
    };

    let trimmed = address.trim();
    if trimmed != address {
        return Err(cfg_err("leading/trailing whitespace"));
    }
    let normalized = if trimmed.is_empty() {
        "http://127.0.0.1:8500".to_string()
    } else if trimmed.contains("://") {
        trimmed.to_string()
    } else {
        format!("http://{trimmed}")
    };

    let (raw_scheme, remainder) = normalized
        .split_once("://")
        .ok_or_else(|| cfg_err("missing scheme delimiter"))?;
    let scheme = raw_scheme.to_ascii_lowercase();
    if scheme != "http" && scheme != "https" {
        return Err(cfg_err("invalid scheme"));
    }

    let authority_end = remainder.find(['/', '?', '#']).unwrap_or(remainder.len());
    let authority = &remainder[..authority_end];
    let suffix = &remainder[authority_end..];
    if authority.is_empty() {
        return Err(cfg_err("empty host"));
    }
    if authority.chars().any(char::is_whitespace) {
        return Err(cfg_err("whitespace in authority"));
    }
    if authority.contains('@') {
        return Err(cfg_err("userinfo in authority"));
    }
    if !suffix.is_empty() && suffix != "/" {
        if suffix.starts_with('?') {
            return Err(cfg_err("query is not allowed"));
        }
        if suffix.starts_with('#') {
            return Err(cfg_err("fragment is not allowed"));
        }
        return Err(cfg_err("path is not allowed"));
    }

    if let Some(rest) = authority.strip_prefix('[') {
        let (host, trailing) = rest
            .split_once(']')
            .ok_or_else(|| cfg_err("invalid IPv6 host"))?;
        if host.is_empty() {
            return Err(cfg_err("empty host"));
        }
        if let Some(port) = trailing.strip_prefix(':') {
            if port.is_empty() {
                return Err(cfg_err("invalid port"));
            }
            port.parse::<u16>()
                .map_err(|_| cfg_err("invalid port"))?;
        } else if !trailing.is_empty() {
            return Err(cfg_err("invalid authority"));
        }
        return Ok(format!("{scheme}://{authority}"));
    }

    let (host, maybe_port) = match authority.rsplit_once(':') {
        Some((host, port)) if !port.is_empty() && port.chars().all(|c| c.is_ascii_digit()) => {
            (host, Some(port))
        }
        Some((_host, _port)) if authority.contains(':') => return Err(cfg_err("invalid port")),
        _ => (authority, None),
    };
    if host.is_empty() {
        return Err(cfg_err("empty host"));
    }
    if let Some(port) = maybe_port {
        port.parse::<u16>()
            .map_err(|_| cfg_err("invalid port"))?;
    }
    Ok(format!("{scheme}://{authority}"))
}

#[cfg(feature = "zookeeper")]
impl ZkDiscovery {
    // Small helper so we can spawn watch tasks without requiring `ZkDiscovery: Clone`.
    fn clone_for_watch(&self) -> Self {
        Self {
            hosts: self.hosts.clone(),
            base_path: self.base_path.clone(),
            session_timeout_ms: self.session_timeout_ms,
            client: tokio::sync::Mutex::new(None),
            registered_paths: tokio::sync::Mutex::new(HashMap::new()),
            services: RwLock::new(HashMap::new()),
            watchers: Arc::clone(&self.watchers),
            watch_generation: Arc::clone(&self.watch_generation),
            watch_poll_generations: Arc::clone(&self.watch_poll_generations),
        }
    }
}

#[cfg(feature = "consul")]
impl ConsulDiscovery {
    fn clone_for_watch(&self) -> Self {
        Self {
            address: self.address.clone(),
            datacenter: self.datacenter.clone(),
            token: self.token.clone(),
            client: tokio::sync::Mutex::new(None),
            service_name: self.service_name.clone(),
            services: RwLock::new(HashMap::new()),
            watchers: Arc::clone(&self.watchers),
            watch_generation: Arc::clone(&self.watch_generation),
            watch_poll_generations: Arc::clone(&self.watch_poll_generations),
        }
    }
}

/// A thread-safe wrapper around a service discovery implementation.
pub type SharedDiscovery = Arc<dyn ServiceDiscovery>;

/// Creates a new shared in-memory discovery instance.
pub fn new_in_memory_discovery() -> SharedDiscovery {
    Arc::new(InMemoryDiscovery::new())
}

/// Creates a new shared ZooKeeper discovery instance.
#[cfg(feature = "zookeeper")]
pub fn new_zk_discovery(hosts: impl Into<String>, base_path: impl Into<String>) -> SharedDiscovery {
    Arc::new(ZkDiscovery::new(hosts, base_path))
}

/// Creates a new shared Consul discovery instance.
#[cfg(feature = "consul")]
pub fn new_consul_discovery(address: impl Into<String>) -> SharedDiscovery {
    Arc::new(ConsulDiscovery::new(address))
}

/// Creates a new shared Consul discovery instance with a custom service name.
///
/// In practice, `service_name` should be a stable job identifier (e.g. `"monolith-job"`).
#[cfg(feature = "consul")]
pub fn new_consul_discovery_with_service_name(
    address: impl Into<String>,
    service_name: impl Into<String>,
) -> SharedDiscovery {
    Arc::new(ConsulDiscovery::new(address).with_service_name(service_name))
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_service_info_creation() {
        let service = ServiceInfo::new("ps-0", "Parameter Server 0", "ps", "127.0.0.1", 5000);

        assert_eq!(service.id, "ps-0");
        assert_eq!(service.name, "Parameter Server 0");
        assert_eq!(service.service_type, "ps");
        assert_eq!(service.host, "127.0.0.1");
        assert_eq!(service.port, 5000);
        assert_eq!(service.health, HealthStatus::Unknown);
        assert!(service.metadata.is_empty());
    }

    #[test]
    fn test_service_info_with_metadata() {
        let service = ServiceInfo::new("worker-0", "Worker 0", "worker", "192.168.1.1", 6000)
            .with_health(HealthStatus::Healthy)
            .with_metadata("gpu_count", "2")
            .with_metadata("memory_gb", "32");

        assert_eq!(service.health, HealthStatus::Healthy);
        assert_eq!(service.metadata.get("gpu_count"), Some(&"2".to_string()));
        assert_eq!(service.metadata.get("memory_gb"), Some(&"32".to_string()));
    }

    #[test]
    fn test_service_info_address() {
        let service = ServiceInfo::new("test", "Test", "test", "10.0.0.1", 8080);
        assert_eq!(service.address(), "10.0.0.1:8080");
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_map_consul_request_error_classifies_invalid_port_as_config_error() {
        let err = map_consul_request_error("register_entity", "InvalidPort");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("register_entity") && msg.contains("invalid address")),
            "expected ConfigError carrying register_entity invalid-address context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_map_consul_request_error_classifies_invalid_scheme_as_config_error() {
        let err = map_consul_request_error("get_service_nodes", "invalid scheme");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("invalid address")),
            "expected ConfigError carrying get_service_nodes invalid-address context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_map_consul_request_error_keeps_connection_failures_internal() {
        let err = map_consul_request_error("get_service_nodes", "Connection refused");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("Connection refused")),
            "expected Internal carrying get_service_nodes runtime-failure context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_map_consul_request_error_classifies_relative_url_without_base_as_config_error() {
        let err = map_consul_request_error(
            "get_service_nodes",
            "relative URL without a base",
        );
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("invalid address")),
            "expected ConfigError carrying get_service_nodes invalid-address context for relative-URL marker, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_adds_http_scheme() {
        let normalized = normalize_consul_address_for_operation("get_service_nodes", "127.0.0.1:8501")
            .expect("host:port address should normalize to explicit http URL");
        assert_eq!(
            normalized, "http://127.0.0.1:8501",
            "host:port Consul address should normalize by prepending http scheme"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_adds_http_scheme_to_host_without_port() {
        let normalized = normalize_consul_address_for_operation("connect", "127.0.0.1")
            .expect("host address should normalize to explicit http URL");
        assert_eq!(
            normalized, "http://127.0.0.1",
            "host-only Consul address should normalize by prepending http scheme"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_adds_http_scheme_to_host_without_port_and_root_slash(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "127.0.0.1/")
            .expect("host root-slash address should normalize to explicit http URL");
        assert_eq!(
            normalized, "http://127.0.0.1",
            "host-only root-slash Consul address should normalize by prepending http scheme and trimming root suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_adds_http_scheme_to_host_port_and_root_slash() {
        let normalized = normalize_consul_address_for_operation("connect", "127.0.0.1:8501/")
            .expect("host:port root-slash address should normalize to explicit http URL");
        assert_eq!(
            normalized, "http://127.0.0.1:8501",
            "host:port root-slash Consul address should normalize by prepending http scheme and trimming root suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_adds_http_scheme_to_hostname_with_port() {
        let normalized = normalize_consul_address_for_operation("connect", "localhost:8501")
            .expect("hostname:port address should normalize to explicit http URL");
        assert_eq!(
            normalized, "http://localhost:8501",
            "hostname:port Consul address should normalize by prepending http scheme"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_adds_http_scheme_to_hostname_with_port_and_root_slash(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "localhost:8501/")
            .expect("hostname:port root-slash address should normalize to explicit http URL");
        assert_eq!(
            normalized, "http://localhost:8501",
            "hostname:port root-slash Consul address should normalize by prepending http scheme and trimming root suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_adds_http_scheme_to_hostname_without_port() {
        let normalized = normalize_consul_address_for_operation("connect", "localhost")
            .expect("hostname address should normalize to explicit http URL");
        assert_eq!(
            normalized, "http://localhost",
            "hostname-only Consul address should normalize by prepending http scheme"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_adds_http_scheme_to_hostname_without_port_and_root_slash(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "localhost/")
            .expect("hostname root-slash address should normalize to explicit http URL");
        assert_eq!(
            normalized, "http://localhost",
            "hostname-only root-slash Consul address should normalize by prepending http scheme and trimming root suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_explicit_https_scheme() {
        let normalized =
            normalize_consul_address_for_operation("connect", "https://127.0.0.1:8501/")
                .expect("explicit https scheme with root path should normalize");
        assert_eq!(
            normalized, "https://127.0.0.1:8501",
            "normalization should preserve https scheme and trim root path suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_explicit_https_scheme_with_hostname() {
        let normalized =
            normalize_consul_address_for_operation("connect", "https://localhost:8501/")
                .expect("explicit https scheme with hostname authority should normalize");
        assert_eq!(
            normalized, "https://localhost:8501",
            "normalization should preserve https scheme and trim root path suffix for hostname authorities"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_explicit_https_scheme_with_hostname_without_port(
    ) {
        let normalized =
            normalize_consul_address_for_operation("connect", "https://localhost/")
                .expect("explicit https scheme with hostname-only authority should normalize");
        assert_eq!(
            normalized, "https://localhost",
            "normalization should preserve https scheme and trim root path suffix for hostname-only authorities"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_explicit_https_scheme_with_ipv6() {
        let normalized = normalize_consul_address_for_operation("connect", "https://[::1]:8501/")
            .expect("explicit https scheme with IPv6 authority should normalize");
        assert_eq!(
            normalized, "https://[::1]:8501",
            "normalization should preserve https scheme and trim root path suffix for IPv6 authorities"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_adds_http_scheme_to_ipv6_with_port() {
        let normalized = normalize_consul_address_for_operation("connect", "[::1]:8501")
            .expect("IPv6 host:port address should normalize to explicit http URL");
        assert_eq!(
            normalized, "http://[::1]:8501",
            "bracketed IPv6 host:port Consul address should normalize by prepending http scheme"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_adds_http_scheme_to_ipv6_with_port_and_root_slash(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "[::1]:8501/")
            .expect("IPv6 host:port root-slash address should normalize to explicit http URL");
        assert_eq!(
            normalized, "http://[::1]:8501",
            "bracketed IPv6 host:port root-slash Consul address should normalize by prepending http scheme and trimming root suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_adds_http_scheme_to_ipv6_without_port() {
        let normalized = normalize_consul_address_for_operation("connect", "[::1]")
            .expect("IPv6 host-only address should normalize to explicit http URL");
        assert_eq!(
            normalized, "http://[::1]",
            "bracketed IPv6 host-only Consul address should normalize by prepending http scheme"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_adds_http_scheme_to_ipv6_without_port_and_root_slash(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "[::1]/")
            .expect("IPv6 host-only root-slash address should normalize to explicit http URL");
        assert_eq!(
            normalized, "http://[::1]",
            "bracketed IPv6 host-only root-slash Consul address should normalize by prepending http scheme and trimming root suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_rejects_leading_trailing_whitespace() {
        let err = normalize_consul_address_for_operation(
            "connect",
            " http://127.0.0.1:8500 ",
        )
        .expect_err("leading/trailing whitespace should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid address")
                    && msg.contains("leading/trailing whitespace")),
            "expected ConfigError containing leading/trailing-whitespace details, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_scheme() {
        let normalized = normalize_consul_address_for_operation(
            "get_service_nodes",
            "HtTp://127.0.0.1:8500/",
        )
        .expect("case-insensitive scheme with root path should normalize");
        assert_eq!(
            normalized, "http://127.0.0.1:8500",
            "normalization should canonicalize scheme casing and trim root path suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_scheme_no_root_slash()
    {
        let normalized =
            normalize_consul_address_for_operation("connect", "HtTp://127.0.0.1:8500")
                .expect("case-insensitive scheme without root path should normalize");
        assert_eq!(
            normalized, "http://127.0.0.1:8500",
            "normalization should canonicalize scheme casing without requiring a root path suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_scheme_with_host_without_port_no_root_slash(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "HtTp://127.0.0.1")
            .expect("case-insensitive host-only authority without root path should normalize");
        assert_eq!(
            normalized, "http://127.0.0.1",
            "normalization should canonicalize scheme casing for host-only authorities without requiring a root path suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_scheme_with_host_without_port(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "HtTp://127.0.0.1/")
            .expect("case-insensitive host-only authority with root path should normalize");
        assert_eq!(
            normalized, "http://127.0.0.1",
            "normalization should canonicalize scheme casing and trim root path suffix for host-only authorities"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_scheme_with_hostname_without_port_no_root_slash(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "HtTp://localhost")
            .expect("case-insensitive hostname-only authority without root path should normalize");
        assert_eq!(
            normalized, "http://localhost",
            "normalization should canonicalize scheme casing for hostname-only authorities without requiring a root path suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_scheme_with_hostname_without_port(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "HtTp://localhost/")
            .expect("case-insensitive hostname-only authority with root path should normalize");
        assert_eq!(
            normalized, "http://localhost",
            "normalization should canonicalize scheme casing and trim root path suffix for hostname-only authorities"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_scheme_with_hostname_no_root_slash(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "HtTp://localhost:8500")
            .expect("case-insensitive hostname authority without root path should normalize");
        assert_eq!(
            normalized, "http://localhost:8500",
            "normalization should canonicalize scheme casing for hostname authorities without requiring a root path suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_scheme_with_hostname() {
        let normalized = normalize_consul_address_for_operation(
            "connect",
            "HtTp://localhost:8500/",
        )
        .expect("case-insensitive hostname authority with root path should normalize");
        assert_eq!(
            normalized, "http://localhost:8500",
            "normalization should canonicalize scheme casing and trim root path suffix for hostname authorities"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_https_scheme() {
        let normalized = normalize_consul_address_for_operation(
            "connect",
            "HtTpS://127.0.0.1:8501/",
        )
        .expect("case-insensitive https scheme with root path should normalize");
        assert_eq!(
            normalized, "https://127.0.0.1:8501",
            "normalization should canonicalize https scheme casing and trim root path suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_https_scheme_no_root_slash(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "HtTpS://127.0.0.1:8501")
            .expect("case-insensitive https scheme without root path should normalize");
        assert_eq!(
            normalized, "https://127.0.0.1:8501",
            "normalization should canonicalize https scheme casing without requiring a root path suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_https_scheme_with_host_without_port_no_root_slash(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "HtTpS://127.0.0.1")
            .expect("case-insensitive https host-only authority without root path should normalize");
        assert_eq!(
            normalized, "https://127.0.0.1",
            "normalization should canonicalize https scheme casing for host-only authorities without requiring a root path suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_https_scheme_with_host_without_port(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "HtTpS://127.0.0.1/")
            .expect("case-insensitive https host-only authority with root path should normalize");
        assert_eq!(
            normalized, "https://127.0.0.1",
            "normalization should canonicalize https scheme casing and trim root path suffix for host-only authorities"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_https_scheme_with_ipv6() {
        let normalized = normalize_consul_address_for_operation(
            "connect",
            "HtTpS://[::1]:8501/",
        )
        .expect("case-insensitive https IPv6 authority with root path should normalize");
        assert_eq!(
            normalized, "https://[::1]:8501",
            "normalization should canonicalize https scheme casing and trim root path suffix for IPv6 authorities"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_https_scheme_with_ipv6_no_root_slash(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "HtTpS://[::1]:8501")
            .expect("case-insensitive https IPv6 authority without root path should normalize");
        assert_eq!(
            normalized, "https://[::1]:8501",
            "normalization should canonicalize https scheme casing for IPv6 authorities without requiring a root path suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_https_scheme_with_hostname(
    ) {
        let normalized = normalize_consul_address_for_operation(
            "connect",
            "HtTpS://localhost:8501/",
        )
        .expect("case-insensitive https hostname authority with root path should normalize");
        assert_eq!(
            normalized, "https://localhost:8501",
            "normalization should canonicalize https scheme casing and trim root path suffix for hostname authorities"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_https_scheme_with_hostname_no_root_slash(
    ) {
        let normalized =
            normalize_consul_address_for_operation("connect", "HtTpS://localhost:8501")
                .expect("case-insensitive https hostname authority without root slash should normalize");
        assert_eq!(
            normalized, "https://localhost:8501",
            "normalization should canonicalize https scheme casing for hostname authorities without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_https_scheme_with_hostname_without_port(
    ) {
        let normalized =
            normalize_consul_address_for_operation("connect", "HtTpS://localhost/")
                .expect("case-insensitive https hostname-only authority with root path should normalize");
        assert_eq!(
            normalized, "https://localhost",
            "normalization should canonicalize https scheme casing and trim root path suffix for hostname-only authorities"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_https_scheme_with_hostname_without_port_no_root_slash(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "HtTpS://localhost")
            .expect("case-insensitive https hostname-only authority without root slash should normalize");
        assert_eq!(
            normalized, "https://localhost",
            "normalization should canonicalize https scheme casing for hostname-only authorities without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_scheme_with_ipv6() {
        let normalized =
            normalize_consul_address_for_operation("connect", "HTTP://[::1]:8501/")
                .expect("case-insensitive IPv6 authority with root path should normalize");
        assert_eq!(
            normalized, "http://[::1]:8501",
            "normalization should canonicalize scheme casing and trim root path suffix for IPv6 authorities"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_case_insensitive_scheme_with_ipv6_no_root_slash(
    ) {
        let normalized = normalize_consul_address_for_operation("connect", "HTTP://[::1]:8501")
            .expect("case-insensitive IPv6 authority without root path should normalize");
        assert_eq!(
            normalized, "http://[::1]:8501",
            "normalization should canonicalize scheme casing for IPv6 authorities without requiring a root path suffix"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_rejects_address_path() {
        let err = normalize_consul_address_for_operation("register_entity", "http://127.0.0.1:8500/v1")
            .expect_err("non-root path in Consul address should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("register_entity")
                    && msg.contains("invalid address")
                    && msg.contains("path is not allowed")),
            "expected ConfigError containing address-path rejection details, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_rejects_address_query() {
        let err = normalize_consul_address_for_operation("connect", "http://127.0.0.1:8500?dc=prod")
            .expect_err("query in Consul address should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid address")
                    && msg.contains("query is not allowed")),
            "expected ConfigError containing address-query rejection details, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_rejects_address_fragment() {
        let err = normalize_consul_address_for_operation("deregister_entity", "http://127.0.0.1:8500#consul")
            .expect_err("fragment in Consul address should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("deregister_entity")
                    && msg.contains("invalid address")
                    && msg.contains("fragment is not allowed")),
            "expected ConfigError containing address-fragment rejection details, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_rejects_whitespace_authority() {
        let err = normalize_consul_address_for_operation("get_service_nodes", "http://127.0.0.1 :8500")
            .expect_err("whitespace authority should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("get_service_nodes")
                    && msg.contains("invalid address")
                    && msg.contains("whitespace in authority")),
            "expected ConfigError containing whitespace-authority details, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_rejects_out_of_range_port() {
        let err = normalize_consul_address_for_operation("connect", "http://127.0.0.1:70000")
            .expect_err("out-of-range authority port should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid address")
                    && msg.contains("invalid port")),
            "expected ConfigError containing out-of-range-port details, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_rejects_invalid_ipv6_authority() {
        let err = normalize_consul_address_for_operation("register_entity", "http://[::1:8500")
            .expect_err("invalid IPv6 authority should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("register_entity")
                    && msg.contains("invalid address")
                    && msg.contains("invalid IPv6 host")),
            "expected ConfigError containing invalid-IPv6-authority details, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_defaults_empty_address() {
        let normalized = normalize_consul_address_for_operation("connect", "")
            .expect("empty address should normalize to default local Consul endpoint");
        assert_eq!(
            normalized, "http://127.0.0.1:8500",
            "empty Consul address should normalize to default endpoint"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_rejects_invalid_ipv6_suffix() {
        let err = normalize_consul_address_for_operation("register_entity", "http://[::1]x:8500")
            .expect_err("invalid IPv6 suffix should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("register_entity")
                    && msg.contains("invalid address")
                    && msg.contains("invalid authority")),
            "expected ConfigError containing invalid-IPv6-suffix details, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_accepts_ipv6_with_port() {
        let normalized = normalize_consul_address_for_operation("connect", "http://[::1]:8500")
            .expect("valid bracketed IPv6 authority should normalize");
        assert_eq!(
            normalized, "http://[::1]:8500",
            "valid bracketed IPv6 authority should be preserved during normalization"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_normalize_consul_address_for_operation_rejects_userinfo_authority() {
        let err = normalize_consul_address_for_operation("get_service_nodes", "http://user@127.0.0.1:8500")
            .expect_err("userinfo authority should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("get_service_nodes")
                    && msg.contains("invalid address")
                    && msg.contains("userinfo in authority")),
            "expected ConfigError containing userinfo-authority details, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_validate_zk_hosts_for_operation_accepts_comma_separated_hosts() {
        validate_zk_hosts_for_operation("connect", "127.0.0.1:2181,127.0.0.1:2182")
            .expect("valid comma-separated ZooKeeper hosts should pass validation");
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_validate_zk_hosts_for_operation_rejects_leading_trailing_whitespace() {
        let err = validate_zk_hosts_for_operation("connect", " 127.0.0.1:2181 ")
            .expect_err("leading/trailing whitespace should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("leading/trailing whitespace")),
            "expected ConfigError containing leading/trailing-whitespace host details, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_validate_zk_hosts_for_operation_rejects_whitespace_in_hosts() {
        let err = validate_zk_hosts_for_operation("connect", "127.0.0.1:2181, 127.0.0.1:2182")
            .expect_err("internal whitespace should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("whitespace in hosts")),
            "expected ConfigError containing whitespace-in-hosts details, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_validate_zk_hosts_for_operation_rejects_empty_hosts() {
        let err = validate_zk_hosts_for_operation("connect", "")
            .expect_err("empty hosts should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty hosts")),
            "expected ConfigError containing empty-hosts details, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_validate_zk_hosts_for_operation_rejects_empty_host_entry() {
        let err = validate_zk_hosts_for_operation("connect", "127.0.0.1:2181,,127.0.0.1:2182")
            .expect_err("empty host entry should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty host entry")),
            "expected ConfigError containing empty-host-entry details, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_validate_zk_hosts_for_operation_rejects_invalid_port() {
        let err = validate_zk_hosts_for_operation("connect", "127.0.0.1:notaport")
            .expect_err("non-numeric host port should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing invalid-port host details, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_validate_zk_hosts_for_operation_rejects_out_of_range_port() {
        let err = validate_zk_hosts_for_operation("connect", "127.0.0.1:70000")
            .expect_err("out-of-range host port should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing out-of-range port details, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_validate_zk_hosts_for_operation_rejects_malformed_ipv6_authority() {
        let err = validate_zk_hosts_for_operation("connect", "[::1")
            .expect_err("malformed bracketed IPv6 authority should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid host entry")),
            "expected ConfigError containing invalid host-entry details, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_validate_zk_hosts_for_operation_accepts_ipv6_with_port() {
        validate_zk_hosts_for_operation("connect", "[::1]:2181")
            .expect("valid bracketed IPv6 host with numeric port should pass validation");
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_validate_zk_base_path_for_operation_accepts_absolute_path() {
        validate_zk_base_path_for_operation("connect", "/services/ps")
            .expect("absolute ZooKeeper base path should pass validation");
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_validate_zk_base_path_for_operation_rejects_leading_trailing_whitespace() {
        let err = validate_zk_base_path_for_operation("connect", " /services ")
            .expect_err("leading/trailing whitespace should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid base_path")
                    && msg.contains("leading/trailing whitespace")),
            "expected ConfigError containing base_path whitespace details, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_validate_zk_base_path_for_operation_rejects_empty_path() {
        let err = validate_zk_base_path_for_operation("connect", "")
            .expect_err("empty base path should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid base_path")
                    && msg.contains("empty path")),
            "expected ConfigError containing empty-path details, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_validate_zk_base_path_for_operation_rejects_missing_leading_slash() {
        let err = validate_zk_base_path_for_operation("connect", "services")
            .expect_err("relative base path should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid base_path")
                    && msg.contains("path must start with /")),
            "expected ConfigError containing missing-leading-slash details, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_validate_zk_base_path_for_operation_rejects_internal_whitespace() {
        let err = validate_zk_base_path_for_operation("connect", "/ser vices")
            .expect_err("internal whitespace should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid base_path")
                    && msg.contains("whitespace in path")),
            "expected ConfigError containing internal-whitespace details, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_validate_zk_base_path_for_operation_rejects_empty_segment() {
        let err = validate_zk_base_path_for_operation("connect", "/services//ps")
            .expect_err("empty path segment should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid base_path")
                    && msg.contains("empty path segment")),
            "expected ConfigError containing empty-segment details, got {err:?}"
        );
    }

    #[test]
    fn test_in_memory_register_and_discover() {
        let discovery = InMemoryDiscovery::new();

        // Register a parameter server
        let ps = ServiceInfo::new("ps-0", "PS 0", "ps", "localhost", 5000)
            .with_health(HealthStatus::Healthy);
        discovery
            .register(ps)
            .expect("registering ps service should succeed");

        // Register workers
        let worker1 = ServiceInfo::new("worker-0", "Worker 0", "worker", "localhost", 6000);
        let worker2 = ServiceInfo::new("worker-1", "Worker 1", "worker", "localhost", 6001);
        discovery
            .register(worker1)
            .expect("registering worker-0 service should succeed");
        discovery
            .register(worker2)
            .expect("registering worker-1 service should succeed");

        // Discover by type
        let ps_services = discovery
            .discover("ps")
            .expect("discover(ps) should succeed");
        assert_eq!(ps_services.len(), 1);
        assert_eq!(ps_services[0].id, "ps-0");

        let worker_services = discovery
            .discover("worker")
            .expect("discover(worker) should succeed");
        assert_eq!(worker_services.len(), 2);

        // Discover non-existent type
        let empty = discovery
            .discover("nonexistent")
            .expect("discover(nonexistent) should succeed");
        assert!(empty.is_empty());
    }

    #[test]
    fn test_in_memory_deregister() {
        let discovery = InMemoryDiscovery::new();

        let service = ServiceInfo::new("test-1", "Test 1", "test", "localhost", 8000);
        discovery
            .register(service)
            .expect("registering test-1 service should succeed");

        assert_eq!(discovery.len(), 1);

        discovery
            .deregister("test-1")
            .expect("deregistering test-1 service should succeed");
        assert_eq!(discovery.len(), 0);

        // Deregister non-existent service should fail
        let err = discovery
            .deregister("nonexistent")
            .expect_err("deregistering missing service should fail with NotFound");
        assert!(
            matches!(err, DiscoveryError::NotFound(ref service_id) if service_id == "nonexistent"),
            "expected NotFound(nonexistent), got {err:?}"
        );
    }

    #[test]
    fn test_in_memory_duplicate_registration() {
        let discovery = InMemoryDiscovery::new();

        let service = ServiceInfo::new("dup-1", "Duplicate", "test", "localhost", 8000);
        discovery
            .register(service.clone())
            .expect("initial duplicate-test registration should succeed");

        // Second registration should fail
        let err = discovery
            .register(service)
            .expect_err("duplicate service registration should fail with AlreadyRegistered");
        assert!(
            matches!(err, DiscoveryError::AlreadyRegistered(ref service_id) if service_id == "dup-1"),
            "expected AlreadyRegistered(dup-1), got {err:?}"
        );
    }

    #[test]
    fn test_in_memory_update_health() {
        let discovery = InMemoryDiscovery::new();

        let service = ServiceInfo::new("health-test", "Health Test", "test", "localhost", 8000)
            .with_health(HealthStatus::Starting);
        discovery
            .register(service)
            .expect("registering health-test service should succeed");

        // Update health
        discovery
            .update_health("health-test", HealthStatus::Healthy)
            .expect("updating health-test to Healthy should succeed");

        let services = discovery
            .discover("test")
            .expect("discover(test) should succeed after first health update");
        assert_eq!(services[0].health, HealthStatus::Healthy);

        // Update to unhealthy
        discovery
            .update_health("health-test", HealthStatus::Unhealthy)
            .expect("updating health-test to Unhealthy should succeed");

        let services = discovery
            .discover("test")
            .expect("discover(test) should succeed after second health update");
        assert_eq!(services[0].health, HealthStatus::Unhealthy);

        // Update non-existent service should fail
        let err = discovery
            .update_health("nonexistent", HealthStatus::Healthy)
            .expect_err("updating health for missing service should fail with NotFound");
        assert!(
            matches!(err, DiscoveryError::NotFound(ref service_id) if service_id == "nonexistent"),
            "expected NotFound(nonexistent), got {err:?}"
        );
    }

    #[test]
    fn test_in_memory_clear() {
        let discovery = InMemoryDiscovery::new();

        discovery
            .register(ServiceInfo::new("s1", "S1", "test", "localhost", 8001))
            .expect("registering s1 should succeed");
        discovery
            .register(ServiceInfo::new("s2", "S2", "test", "localhost", 8002))
            .expect("registering s2 should succeed");
        discovery
            .register(ServiceInfo::new("s3", "S3", "other", "localhost", 8003))
            .expect("registering s3 should succeed");

        assert_eq!(discovery.len(), 3);

        discovery.clear();

        assert_eq!(discovery.len(), 0);
        assert!(discovery.is_empty());
    }

    #[tokio::test]
    async fn test_in_memory_watch() {
        let discovery = InMemoryDiscovery::new();

        // Set up a watcher before registration
        let mut receiver = discovery
            .watch("ps")
            .expect("watch(ps) should succeed");

        // Register a service
        let service = ServiceInfo::new("ps-watch", "PS Watch", "ps", "localhost", 5000);
        discovery
            .register(service.clone())
            .expect("registering ps-watch service should succeed");

        // Check that we received the event
        let event = receiver
            .recv()
            .await
            .expect("watch receiver should emit ServiceAdded event");
        assert!(
            matches!(event, DiscoveryEvent::ServiceAdded(ref s) if s.id == "ps-watch"),
            "expected ServiceAdded(ps-watch), got {event:?}"
        );

        // Deregister and check for removal event
        discovery
            .deregister("ps-watch")
            .expect("deregistering ps-watch should succeed");

        let event = receiver
            .recv()
            .await
            .expect("watch receiver should emit ServiceRemoved event");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-watch"),
            "expected ServiceRemoved(ps-watch), got {event:?}"
        );
    }

    #[tokio::test]
    async fn test_in_memory_watch_update() {
        let discovery = InMemoryDiscovery::new();

        let service = ServiceInfo::new("update-test", "Update Test", "worker", "localhost", 6000)
            .with_health(HealthStatus::Starting);
        discovery
            .register(service)
            .expect("registering update-test service should succeed");

        let mut receiver = discovery
            .watch("worker")
            .expect("watch(worker) should succeed");

        // Update health status
        discovery
            .update_health("update-test", HealthStatus::Healthy)
            .expect("updating update-test health should succeed");

        let event = receiver
            .recv()
            .await
            .expect("watch receiver should emit ServiceUpdated event");
        assert!(
            matches!(
                event,
                DiscoveryEvent::ServiceUpdated(ref s)
                if s.id == "update-test" && s.health == HealthStatus::Healthy
            ),
            "expected ServiceUpdated(update-test, Healthy), got {event:?}"
        );
    }

    #[test]
    fn test_in_memory_removes_dead_watchers_after_notification() {
        let discovery = InMemoryDiscovery::new();
        let rx = discovery
            .watch("ps")
            .expect("watch(ps) should succeed");
        assert!(
            discovery
                .watchers
                .lock()
                .expect("in-memory watchers mutex should not be poisoned")
                .contains_key("ps"),
            "watch sender should exist after subscribing"
        );

        drop(rx);

        let service = ServiceInfo::new("ps-0", "PS 0", "ps", "localhost", 5000);
        discovery
            .register(service)
            .expect("registering ps-0 service should succeed");
        assert!(
            !discovery
                .watchers
                .lock()
                .expect("in-memory watchers mutex should not be poisoned")
                .contains_key("ps"),
            "dead watcher sender should be removed after notification"
        );
    }

    #[tokio::test]
    async fn test_spawn_watch_poll_loop_emits_added_and_removed_events() {
        let (sender, _) = tokio::sync::broadcast::channel(16);
        let mut rx = sender.subscribe();
        let poll_calls = std::sync::Arc::new(std::sync::atomic::AtomicUsize::new(0));
        let poll_calls_for_loop = std::sync::Arc::clone(&poll_calls);

        let handle = spawn_watch_poll_loop(
            sender,
            "test",
            std::time::Duration::from_millis(5),
            || true,
            || {},
            move || {
                let call = poll_calls_for_loop.fetch_add(1, std::sync::atomic::Ordering::SeqCst);
                async move {
                    if call == 0 {
                        Ok(vec![ServiceInfo::new(
                            "ps-0",
                            "ps-0",
                            "ps",
                            "127.0.0.1",
                            5000,
                        )])
                    } else {
                        Ok(Vec::new())
                    }
                }
            },
        );

        let added = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceAdded")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(added, DiscoveryEvent::ServiceAdded(ref s) if s.id == "ps-0"),
            "expected ServiceAdded(ps-0), got {added:?}"
        );

        let removed = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(removed, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {removed:?}"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_millis(200), handle)
            .await
            .expect("watch loop should stop when no receivers")
            .expect("watch task join failed");
    }

    #[tokio::test]
    async fn test_spawn_watch_poll_loop_emits_updated_events() {
        let (sender, _) = tokio::sync::broadcast::channel(16);
        let mut rx = sender.subscribe();
        let poll_calls = std::sync::Arc::new(std::sync::atomic::AtomicUsize::new(0));
        let poll_calls_for_loop = std::sync::Arc::clone(&poll_calls);

        let handle = spawn_watch_poll_loop(
            sender,
            "test",
            std::time::Duration::from_millis(5),
            || true,
            || {},
            move || {
                let call = poll_calls_for_loop.fetch_add(1, std::sync::atomic::Ordering::SeqCst);
                async move {
                    let health = if call == 0 {
                        HealthStatus::Starting
                    } else {
                        HealthStatus::Healthy
                    };
                    Ok(vec![
                        ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000).with_health(health),
                    ])
                }
            },
        );

        let added = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceAdded")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(
                added,
                DiscoveryEvent::ServiceAdded(ref s)
                if s.id == "ps-0" && s.health == HealthStatus::Starting
            ),
            "expected ServiceAdded(ps-0, Starting), got {added:?}"
        );

        let updated = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceUpdated")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(
                updated,
                DiscoveryEvent::ServiceUpdated(ref s)
                if s.id == "ps-0" && s.health == HealthStatus::Healthy
            ),
            "expected ServiceUpdated(ps-0, Healthy), got {updated:?}"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_millis(200), handle)
            .await
            .expect("watch loop should stop when no receivers")
            .expect("watch task join failed");
    }

    #[tokio::test]
    async fn test_spawn_watch_poll_loop_stops_after_receivers_drop() {
        let (sender, _) = tokio::sync::broadcast::channel(16);
        let rx = sender.subscribe();
        let poll_calls = std::sync::Arc::new(std::sync::atomic::AtomicUsize::new(0));
        let poll_calls_for_loop = std::sync::Arc::clone(&poll_calls);

        let handle = spawn_watch_poll_loop(
            sender,
            "test",
            std::time::Duration::from_millis(5),
            || true,
            || {},
            move || {
                poll_calls_for_loop.fetch_add(1, std::sync::atomic::Ordering::SeqCst);
                async move { Ok(Vec::new()) }
            },
        );

        tokio::time::sleep(std::time::Duration::from_millis(25)).await;
        assert!(
            poll_calls.load(std::sync::atomic::Ordering::SeqCst) > 0,
            "watch poll loop should execute while receiver is alive"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_millis(200), handle)
            .await
            .expect("watch loop should stop when receiver is dropped")
            .expect("watch task join failed");
    }

    #[tokio::test]
    async fn test_spawn_watch_poll_loop_stops_when_continue_predicate_false() {
        let (sender, _) = tokio::sync::broadcast::channel(16);
        let _rx = sender.subscribe();
        let poll_calls = std::sync::Arc::new(std::sync::atomic::AtomicUsize::new(0));
        let poll_calls_for_loop = std::sync::Arc::clone(&poll_calls);
        let keep_running = std::sync::Arc::new(std::sync::atomic::AtomicBool::new(true));
        let keep_running_for_loop = std::sync::Arc::clone(&keep_running);

        let handle = spawn_watch_poll_loop(
            sender,
            "test",
            std::time::Duration::from_millis(5),
            move || keep_running_for_loop.load(std::sync::atomic::Ordering::SeqCst),
            || {},
            move || {
                poll_calls_for_loop.fetch_add(1, std::sync::atomic::Ordering::SeqCst);
                async move { Ok(Vec::new()) }
            },
        );

        tokio::time::sleep(std::time::Duration::from_millis(25)).await;
        assert!(
            poll_calls.load(std::sync::atomic::Ordering::SeqCst) > 0,
            "watch poll loop should execute while continue predicate is true"
        );

        keep_running.store(false, std::sync::atomic::Ordering::SeqCst);
        tokio::time::timeout(std::time::Duration::from_millis(200), handle)
            .await
            .expect("watch loop should stop when continue predicate flips false")
            .expect("watch task join failed");
    }

    #[tokio::test]
    async fn test_spawn_watch_poll_loop_runs_on_exit_callback() {
        let (sender, _rx) = tokio::sync::broadcast::channel(16);
        let on_exit_called = std::sync::Arc::new(std::sync::atomic::AtomicBool::new(false));
        let on_exit_called_for_loop = std::sync::Arc::clone(&on_exit_called);

        let handle = spawn_watch_poll_loop(
            sender,
            "test",
            std::time::Duration::from_millis(5),
            || false,
            move || on_exit_called_for_loop.store(true, std::sync::atomic::Ordering::SeqCst),
            move || async move { Ok(Vec::new()) },
        );

        tokio::time::timeout(std::time::Duration::from_millis(200), handle)
            .await
            .expect("watch loop should stop immediately")
            .expect("watch task join failed");
        assert!(
            on_exit_called.load(std::sync::atomic::Ordering::SeqCst),
            "on_exit callback should run when poll loop exits"
        );
    }

    #[tokio::test]
    async fn test_spawn_watch_poll_loop_recovers_after_discover_error() {
        let (sender, _) = tokio::sync::broadcast::channel(16);
        let mut rx = sender.subscribe();
        let poll_calls = std::sync::Arc::new(std::sync::atomic::AtomicUsize::new(0));
        let poll_calls_for_loop = std::sync::Arc::clone(&poll_calls);
        let keep_running = std::sync::Arc::new(std::sync::atomic::AtomicBool::new(true));
        let keep_running_for_loop = std::sync::Arc::clone(&keep_running);
        let on_exit_called = std::sync::Arc::new(std::sync::atomic::AtomicBool::new(false));
        let on_exit_called_for_loop = std::sync::Arc::clone(&on_exit_called);

        let handle = spawn_watch_poll_loop(
            sender,
            "test",
            std::time::Duration::from_millis(5),
            move || keep_running_for_loop.load(std::sync::atomic::Ordering::SeqCst),
            move || on_exit_called_for_loop.store(true, std::sync::atomic::Ordering::SeqCst),
            move || {
                let call = poll_calls_for_loop.fetch_add(1, std::sync::atomic::Ordering::SeqCst);
                async move {
                    if call == 0 {
                        Err(DiscoveryError::Internal("transient discover error".into()))
                    } else {
                        Ok(vec![ServiceInfo::new(
                            "ps-0",
                            "ps-0",
                            "ps",
                            "127.0.0.1",
                            5000,
                        )])
                    }
                }
            },
        );

        let added = tokio::time::timeout(std::time::Duration::from_millis(250), rx.recv())
            .await
            .expect("timed out waiting for ServiceAdded after transient discover error")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(added, DiscoveryEvent::ServiceAdded(ref s) if s.id == "ps-0"),
            "expected ServiceAdded(ps-0), got {added:?}"
        );

        assert!(
            poll_calls.load(std::sync::atomic::Ordering::SeqCst) >= 2,
            "watch poll loop should retry discover after transient failure"
        );

        keep_running.store(false, std::sync::atomic::Ordering::SeqCst);
        drop(rx);

        tokio::time::timeout(std::time::Duration::from_millis(250), handle)
            .await
            .expect("watch loop should stop after continue predicate flips false")
            .expect("watch task join failed");
        assert!(
            on_exit_called.load(std::sync::atomic::Ordering::SeqCst),
            "on_exit callback should run after recovery and graceful shutdown"
        );
    }

    #[tokio::test]
    async fn test_spawn_watch_poll_loop_stops_on_config_error() {
        let (sender, _) = tokio::sync::broadcast::channel(16);
        let _rx = sender.subscribe();
        let poll_calls = std::sync::Arc::new(std::sync::atomic::AtomicUsize::new(0));
        let poll_calls_for_loop = std::sync::Arc::clone(&poll_calls);
        let on_exit_called = std::sync::Arc::new(std::sync::atomic::AtomicBool::new(false));
        let on_exit_called_for_loop = std::sync::Arc::clone(&on_exit_called);

        let handle = spawn_watch_poll_loop(
            sender,
            "test",
            std::time::Duration::from_millis(5),
            || true,
            move || on_exit_called_for_loop.store(true, std::sync::atomic::Ordering::SeqCst),
            move || {
                poll_calls_for_loop.fetch_add(1, std::sync::atomic::Ordering::SeqCst);
                async move {
                    Err(DiscoveryError::ConfigError(
                        "invalid discovery configuration".into(),
                    ))
                }
            },
        );

        tokio::time::timeout(std::time::Duration::from_millis(250), handle)
            .await
            .expect("watch loop should stop immediately on configuration errors")
            .expect("watch task join failed");
        assert_eq!(
            poll_calls.load(std::sync::atomic::Ordering::SeqCst),
            1,
            "watch loop should not retry after configuration errors"
        );
        assert!(
            on_exit_called.load(std::sync::atomic::Ordering::SeqCst),
            "on_exit callback should run when poll loop exits on configuration error"
        );
    }

    #[test]
    fn test_shared_discovery() {
        let discovery: SharedDiscovery = new_in_memory_discovery();

        let service = ServiceInfo::new("shared-test", "Shared Test", "test", "localhost", 9000);
        discovery
            .register(service)
            .expect("shared discovery register should succeed");

        let services = discovery
            .discover("test")
            .expect("shared discovery discover(test) should succeed");
        assert_eq!(services.len(), 1);
    }

    #[test]
    fn test_health_status_default() {
        let status: HealthStatus = Default::default();
        assert_eq!(status, HealthStatus::Unknown);
    }

    #[test]
    fn test_discovery_event_equality() {
        let service1 = ServiceInfo::new("s1", "S1", "test", "localhost", 8000);
        let service2 = ServiceInfo::new("s1", "S1", "test", "localhost", 8000);

        let event1 = DiscoveryEvent::ServiceAdded(service1);
        let event2 = DiscoveryEvent::ServiceAdded(service2);

        assert_eq!(event1, event2);

        let removed1 = DiscoveryEvent::ServiceRemoved("s1".to_string());
        let removed2 = DiscoveryEvent::ServiceRemoved("s1".to_string());

        assert_eq!(removed1, removed2);
    }

    #[test]
    fn test_multiple_service_types() {
        let discovery = InMemoryDiscovery::new();

        // Register services of different types
        for i in 0..3 {
            let ps = ServiceInfo::new(
                format!("ps-{}", i),
                format!("PS {}", i),
                "ps",
                "localhost",
                5000 + i as u16,
            );
            discovery
                .register(ps)
                .expect("registering ps service should succeed");
        }

        for i in 0..5 {
            let worker = ServiceInfo::new(
                format!("worker-{}", i),
                format!("Worker {}", i),
                "worker",
                "localhost",
                6000 + i as u16,
            );
            discovery
                .register(worker)
                .expect("registering worker service should succeed");
        }

        // Verify counts
        assert_eq!(
            discovery
                .discover("ps")
                .expect("discover(ps) should succeed")
                .len(),
            3
        );
        assert_eq!(
            discovery
                .discover("worker")
                .expect("discover(worker) should succeed")
                .len(),
            5
        );
        assert_eq!(discovery.len(), 8);
    }

    #[cfg(feature = "zookeeper")]
    fn zk_has_watcher(zk: &ZkDiscovery, service_type: &str) -> bool {
        zk.watchers
            .lock()
            .expect("zk watchers mutex should not be poisoned")
            .contains_key(service_type)
    }

    #[cfg(feature = "zookeeper")]
    fn zk_watcher_count(zk: &ZkDiscovery) -> usize {
        zk.watchers
            .lock()
            .expect("zk watchers mutex should not be poisoned")
            .len()
    }

    #[cfg(feature = "zookeeper")]
    fn zk_watchers_is_empty(zk: &ZkDiscovery) -> bool {
        zk.watchers
            .lock()
            .expect("zk watchers mutex should not be poisoned")
            .is_empty()
    }

    #[cfg(feature = "zookeeper")]
    fn zk_watch_poll_count(zk: &ZkDiscovery) -> usize {
        zk.watch_poll_generations
            .lock()
            .expect("zk watch_poll_generations mutex should not be poisoned")
            .len()
    }

    #[cfg(feature = "zookeeper")]
    fn zk_watch_poll_is_empty(zk: &ZkDiscovery) -> bool {
        zk.watch_poll_generations
            .lock()
            .expect("zk watch_poll_generations mutex should not be poisoned")
            .is_empty()
    }

    #[cfg(feature = "zookeeper")]
    fn zk_watch_poll_remove(zk: &ZkDiscovery, service_type: &str) {
        zk.watch_poll_generations
            .lock()
            .expect("zk watch_poll_generations mutex should not be poisoned")
            .remove(service_type);
    }

    #[cfg(feature = "zookeeper")]
    fn zk_has_watch_poll_generation(zk: &ZkDiscovery, service_type: &str) -> bool {
        zk.watch_poll_generations
            .lock()
            .expect("zk watch_poll_generations mutex should not be poisoned")
            .contains_key(service_type)
    }

    #[cfg(feature = "zookeeper")]
    fn zk_watch_poll_get(zk: &ZkDiscovery, service_type: &str) -> Option<u64> {
        zk.watch_poll_generations
            .lock()
            .expect("zk watch_poll_generations mutex should not be poisoned")
            .get(service_type)
            .copied()
    }

    #[cfg(feature = "consul")]
    fn consul_has_watcher(consul: &ConsulDiscovery, service_type: &str) -> bool {
        consul
            .watchers
            .lock()
            .expect("consul watchers mutex should not be poisoned")
            .contains_key(service_type)
    }

    #[cfg(feature = "consul")]
    fn consul_watchers_is_empty(consul: &ConsulDiscovery) -> bool {
        consul
            .watchers
            .lock()
            .expect("consul watchers mutex should not be poisoned")
            .is_empty()
    }

    #[cfg(feature = "consul")]
    fn consul_watcher_count(consul: &ConsulDiscovery) -> usize {
        consul
            .watchers
            .lock()
            .expect("consul watchers mutex should not be poisoned")
            .len()
    }

    #[cfg(feature = "consul")]
    fn consul_watch_poll_count(consul: &ConsulDiscovery) -> usize {
        consul
            .watch_poll_generations
            .lock()
            .expect("consul watch_poll_generations mutex should not be poisoned")
            .len()
    }

    #[cfg(feature = "consul")]
    fn consul_watch_poll_is_empty(consul: &ConsulDiscovery) -> bool {
        consul
            .watch_poll_generations
            .lock()
            .expect("consul watch_poll_generations mutex should not be poisoned")
            .is_empty()
    }

    #[cfg(feature = "consul")]
    fn consul_watch_poll_remove(consul: &ConsulDiscovery, service_type: &str) {
        consul
            .watch_poll_generations
            .lock()
            .expect("consul watch_poll_generations mutex should not be poisoned")
            .remove(service_type);
    }

    #[cfg(feature = "consul")]
    fn consul_has_watch_poll_generation(consul: &ConsulDiscovery, service_type: &str) -> bool {
        consul
            .watch_poll_generations
            .lock()
            .expect("consul watch_poll_generations mutex should not be poisoned")
            .contains_key(service_type)
    }

    #[cfg(feature = "consul")]
    fn consul_watch_poll_get(consul: &ConsulDiscovery, service_type: &str) -> Option<u64> {
        consul
            .watch_poll_generations
            .lock()
            .expect("consul watch_poll_generations mutex should not be poisoned")
            .get(service_type)
            .copied()
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_zk_discovery_creation() {
        let zk = ZkDiscovery::new("localhost:2181", "/services").with_session_timeout(60000);
        assert_eq!(zk.hosts, "localhost:2181");
        assert_eq!(zk.base_path, "/services");
        assert_eq!(
            zk.session_timeout_ms, 60000,
            "with_session_timeout should override default session timeout"
        );
        assert!(
            zk.watchers
                .lock()
                .expect("zk watchers mutex should not be poisoned")
                .is_empty(),
            "newly constructed discovery should start without watcher senders"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_zk_discovery_creation_uses_default_session_timeout() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");
        assert_eq!(
            zk.session_timeout_ms, 30000,
            "default ZooKeeper session timeout should match Python parity expectation"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_disconnect_increments_watch_generation() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");
        let before = zk.watch_generation.load(std::sync::atomic::Ordering::SeqCst);
        zk.disconnect().await.expect("disconnect should succeed");
        let after = zk.watch_generation.load(std::sync::atomic::Ordering::SeqCst);
        assert_eq!(after, before + 1);
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_disconnect_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        zk.disconnect().await.expect("disconnect should succeed");

        assert!(
            !zk_has_watcher(&zk, "ps"),
            "disconnect should compact dead watcher senders"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_disconnect_preserves_live_watchers() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        zk.disconnect().await.expect("disconnect should succeed");

        assert!(
            zk_has_watcher(&zk, "ps"),
            "disconnect should preserve live watcher senders"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_disconnect_compacts_only_dead_watchers() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");
        let dead_rx = zk.watch("ps").expect("watch should succeed");
        let _live_rx = zk.watch("worker").expect("watch should succeed");
        assert_eq!(
            zk_watcher_count(&zk),
            2,
            "test setup should seed two watcher senders"
        );
        drop(dead_rx);

        zk.disconnect().await.expect("disconnect should succeed");

        assert!(
            !zk_has_watcher(&zk, "ps"),
            "disconnect should compact dead watcher sender for dropped receiver"
        );
        assert!(
            zk_has_watcher(&zk, "worker"),
            "disconnect should preserve watcher sender with active receiver"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_disconnect_clears_watch_poll_generation_entries() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");
        assert!(zk.should_spawn_watch_poll("ps"));
        assert!(zk.should_spawn_watch_poll("worker"));
        assert_eq!(
            zk_watch_poll_count(&zk),
            2,
            "test setup should seed watch-poll generation entries"
        );

        zk.disconnect().await.expect("disconnect should succeed");

        assert!(
            zk_watch_poll_is_empty(&zk),
            "disconnect should clear active watch-poll generation entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_disconnect_preserves_local_service_cache() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        assert_eq!(
            zk.discover("ps").expect("discover should succeed").len(),
            1,
            "test setup should seed one cached service"
        );

        zk.disconnect().await.expect("disconnect should succeed");

        assert_eq!(
            zk.discover("ps").expect("discover should succeed").len(),
            1,
            "disconnect should preserve local cached services"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_disconnect_clears_registered_paths() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        assert!(
            zk.registered_paths.lock().await.contains_key("ps-0"),
            "test setup should seed registered path bookkeeping"
        );

        zk.disconnect().await.expect("disconnect should succeed");

        assert!(
            zk.registered_paths.lock().await.is_empty(),
            "disconnect should clear registered path bookkeeping state"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_should_spawn_watch_poll_once_per_generation() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");

        assert!(
            zk.should_spawn_watch_poll("ps"),
            "first watch on service type should spawn poller"
        );
        assert!(
            !zk.should_spawn_watch_poll("ps"),
            "second watch on same service type and generation should not respawn poller"
        );
        zk_watch_poll_remove(&zk, "ps");
        assert!(
            zk.should_spawn_watch_poll("ps"),
            "poller should respawn once prior generation entry is cleaned"
        );
        assert!(
            zk.should_spawn_watch_poll("worker"),
            "different service type should spawn its own poller"
        );

        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            zk.should_spawn_watch_poll("ps"),
            "after disconnect generation bump should allow respawn"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_cleanup_watch_poll_generation_preserves_newer_generation_entry() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");
        assert!(zk.should_spawn_watch_poll("ps"));
        let old_generation = zk.watch_generation.load(std::sync::atomic::Ordering::SeqCst);

        zk.disconnect().await.expect("disconnect should succeed");
        assert!(zk.should_spawn_watch_poll("ps"));
        let new_generation = zk.watch_generation.load(std::sync::atomic::Ordering::SeqCst);
        assert!(
            new_generation > old_generation,
            "disconnect should advance watch generation"
        );

        zk.cleanup_watch_poll_generation("ps", old_generation);
        assert_eq!(
            zk_watch_poll_get(&zk, "ps"),
            Some(new_generation),
            "cleanup for stale generation must not remove newer generation entry"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_sync_watch_receives_removed_event_on_deregister() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("register should succeed");

        let mut rx = zk.watch("ps").expect("watch should succeed");
        zk.deregister("ps-0")
            .expect("deregister should succeed and notify watchers");

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_deduplicates_poll_generation_entries() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");

        let rx1 = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect("first watch_async should succeed");
        assert_eq!(zk_watch_poll_count(&zk), 1);

        let rx2 = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect("second watch_async should succeed");
        assert_eq!(
            zk_watch_poll_count(&zk),
            1,
            "same service type should not create duplicate poll-generation entries"
        );

        let rx3 = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "worker")
            .await
            .expect("watch_async for second service type should succeed");
        assert_eq!(
            zk_watch_poll_count(&zk),
            2,
            "second service type should create a second poll-generation entry"
        );

        drop(rx1);
        drop(rx2);
        drop(rx3);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if zk_watch_poll_is_empty(&zk) {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("watch poll generation entries should clear after subscribers drop");
        assert!(
            zk_watchers_is_empty(&zk),
            "watch_async should compact dead watcher sender entries after all receivers drop"
        );
        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            zk_watch_poll_is_empty(&zk),
            "disconnect should preserve cleared watch poll generation state"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_valid_multi_hosts_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let zk =
            ZkDiscovery::new("127.0.0.1:1,127.0.0.1:2", "/services").with_session_timeout(100);
        let rx = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect("valid multi-host list should be accepted by watch_async");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        assert!(
            zk_has_watch_poll_generation(&zk, "ps"),
            "watch_async should seed poll-generation bookkeeping before disconnect"
        );

        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_valid_mixed_ipv4_ipv6_hosts_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let zk =
            ZkDiscovery::new("[::1]:1,127.0.0.1:2", "/services").with_session_timeout(100);
        let rx = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect("valid mixed-family host list should be accepted by watch_async");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        assert!(
            zk_has_watch_poll_generation(&zk, "ps"),
            "watch_async should seed poll-generation bookkeeping before disconnect"
        );

        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_valid_ipv6_multi_hosts_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let zk = ZkDiscovery::new("[::1]:1,[::2]:2", "/services").with_session_timeout(100);
        let rx = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect("valid IPv6 multi-host list should be accepted by watch_async");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        assert!(
            zk_has_watch_poll_generation(&zk, "ps"),
            "watch_async should seed poll-generation bookkeeping before disconnect"
        );

        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_valid_single_ipv6_host_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let zk = ZkDiscovery::new("[::1]:1", "/services").with_session_timeout(100);
        let rx = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect("valid single IPv6 host should be accepted by watch_async");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        assert!(
            zk_has_watch_poll_generation(&zk, "ps"),
            "watch_async should seed poll-generation bookkeeping before disconnect"
        );

        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_valid_single_ipv4_host_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        let rx = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect("valid single IPv4 host should be accepted by watch_async");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        assert!(
            zk_has_watch_poll_generation(&zk, "ps"),
            "watch_async should seed poll-generation bookkeeping before disconnect"
        );

        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_valid_single_hostname_host_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let zk = ZkDiscovery::new("localhost:1", "/services").with_session_timeout(100);
        let rx = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect("valid single hostname host should be accepted by watch_async");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        assert!(
            zk_has_watch_poll_generation(&zk, "ps"),
            "watch_async should seed poll-generation bookkeeping before disconnect"
        );

        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_valid_host_only_multi_hosts_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1,127.0.0.1", "/services").with_session_timeout(100);
        let rx = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect("valid host-only multi-host list should be accepted by watch_async");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        assert!(
            zk_has_watch_poll_generation(&zk, "ps"),
            "watch_async should seed poll-generation bookkeeping before disconnect"
        );

        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_valid_host_only_mixed_ipv4_ipv6_hosts_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let zk = ZkDiscovery::new("[::1],127.0.0.1", "/services").with_session_timeout(100);
        let rx = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect("valid host-only mixed-family list should be accepted by watch_async");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        assert!(
            zk_has_watch_poll_generation(&zk, "ps"),
            "watch_async should seed poll-generation bookkeeping before disconnect"
        );

        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_valid_host_only_ipv6_multi_hosts_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let zk = ZkDiscovery::new("[::1],[::2]", "/services").with_session_timeout(100);
        let rx = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect("valid host-only IPv6 multi-host list should be accepted by watch_async");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        assert!(
            zk_has_watch_poll_generation(&zk, "ps"),
            "watch_async should seed poll-generation bookkeeping before disconnect"
        );

        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_valid_host_only_single_ipv6_host_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let zk = ZkDiscovery::new("[::1]", "/services").with_session_timeout(100);
        let rx = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect("valid host-only single IPv6 host should be accepted by watch_async");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        assert!(
            zk_has_watch_poll_generation(&zk, "ps"),
            "watch_async should seed poll-generation bookkeeping before disconnect"
        );

        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_valid_host_only_single_ipv4_host_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1", "/services").with_session_timeout(100);
        let rx = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect("valid host-only single IPv4 host should be accepted by watch_async");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        assert!(
            zk_has_watch_poll_generation(&zk, "ps"),
            "watch_async should seed poll-generation bookkeeping before disconnect"
        );

        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_valid_host_only_single_hostname_host_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let zk = ZkDiscovery::new("localhost", "/services").with_session_timeout(100);
        let rx = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect("valid host-only single hostname host should be accepted by watch_async");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        assert!(
            zk_has_watch_poll_generation(&zk, "ps"),
            "watch_async should seed poll-generation bookkeeping before disconnect"
        );

        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        zk.disconnect().await.expect("disconnect should succeed");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_invalid_hosts_rejects_without_state_changes() {
        let zk = ZkDiscovery::new(" 127.0.0.1:2181 ", "/services");

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("invalid hosts should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("leading/trailing whitespace")),
            "expected ConfigError containing watch_service invalid-hosts context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "invalid-hosts watch_async should not create watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "invalid-hosts watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_empty_hosts_rejects_without_state_changes() {
        let zk = ZkDiscovery::new("", "/services");

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("empty hosts should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty hosts")),
            "expected ConfigError containing watch_service empty-hosts context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "empty-hosts watch_async should not create watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "empty-hosts watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_invalid_port_rejects_without_state_changes() {
        let zk = ZkDiscovery::new("127.0.0.1:notaport", "/services");

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("invalid-port hosts should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing watch_service invalid-port context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "invalid-port watch_async should not create watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "invalid-port watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_out_of_range_port_rejects_without_state_changes() {
        let zk = ZkDiscovery::new("127.0.0.1:70000", "/services");

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("out-of-range host port should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing watch_service out-of-range-port context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "out-of-range-port watch_async should not create watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "out-of-range-port watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_out_of_range_port_compacts_dead_watch_sender() {
        let zk = ZkDiscovery::new("127.0.0.1:70000", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("out-of-range host port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing watch_service out-of-range-port context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "out-of-range-port watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_out_of_range_port_preserves_live_watch_sender() {
        let zk = ZkDiscovery::new("127.0.0.1:70000", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("out-of-range host port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing watch_service out-of-range-port context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "out-of-range-port watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_invalid_port_compacts_dead_watch_sender() {
        let zk = ZkDiscovery::new("127.0.0.1:notaport", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("invalid-port hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing watch_service invalid-port context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "invalid-port watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_invalid_port_preserves_live_watch_sender() {
        let zk = ZkDiscovery::new("127.0.0.1:notaport", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("invalid-port hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing watch_service invalid-port context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "invalid-port watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_malformed_ipv6_host_entry_rejects_without_state_changes() {
        let zk = ZkDiscovery::new("[::1", "/services");

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("malformed IPv6 host entry should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid host entry")),
            "expected ConfigError containing watch_service invalid-host-entry context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "malformed-host-entry watch_async should not create watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "malformed-host-entry watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_malformed_ipv6_host_entry_compacts_dead_watch_sender() {
        let zk = ZkDiscovery::new("[::1", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("malformed host entry should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid host entry")),
            "expected ConfigError containing watch_service malformed-host-entry context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "malformed-host-entry watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_malformed_ipv6_host_entry_preserves_live_watch_sender() {
        let zk = ZkDiscovery::new("[::1", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("malformed host entry should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid host entry")),
            "expected ConfigError containing watch_service malformed-host-entry context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "malformed-host-entry watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_invalid_hosts_compacts_dead_watch_sender() {
        let zk = ZkDiscovery::new(" 127.0.0.1:2181 ", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("invalid hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("leading/trailing whitespace")),
            "expected ConfigError containing watch_service invalid-hosts context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "invalid-hosts watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_invalid_hosts_preserves_live_watch_sender() {
        let zk = ZkDiscovery::new(" 127.0.0.1:2181 ", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("invalid hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("leading/trailing whitespace")),
            "expected ConfigError containing watch_service invalid-hosts context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "invalid-hosts watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_empty_hosts_compacts_dead_watch_sender() {
        let zk = ZkDiscovery::new("", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("empty hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty hosts")),
            "expected ConfigError containing watch_service empty-hosts context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "empty-hosts watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_empty_hosts_preserves_live_watch_sender() {
        let zk = ZkDiscovery::new("", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("empty hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty hosts")),
            "expected ConfigError containing watch_service empty-hosts context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "empty-hosts watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_empty_host_entry_rejects_without_state_changes() {
        let zk = ZkDiscovery::new("127.0.0.1:2181,,127.0.0.1:2182", "/services");

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("empty host entry should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty host entry")),
            "expected ConfigError containing watch_service empty-host-entry context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "empty-host-entry watch_async should not create watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "empty-host-entry watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_empty_host_entry_compacts_dead_watch_sender() {
        let zk = ZkDiscovery::new("127.0.0.1:2181,,127.0.0.1:2182", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("empty host entry should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty host entry")),
            "expected ConfigError containing watch_service empty-host-entry context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "empty-host-entry watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_empty_host_entry_preserves_live_watch_sender() {
        let zk = ZkDiscovery::new("127.0.0.1:2181,,127.0.0.1:2182", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("empty host entry should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty host entry")),
            "expected ConfigError containing watch_service empty-host-entry context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "empty-host-entry watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_whitespace_in_hosts_rejects_without_state_changes() {
        let zk = ZkDiscovery::new("127.0.0.1:2181, 127.0.0.1:2182", "/services");

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("whitespace-in-hosts should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("whitespace in hosts")),
            "expected ConfigError containing watch_service whitespace-in-hosts context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "whitespace-in-hosts watch_async should not create watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "whitespace-in-hosts watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_whitespace_in_hosts_compacts_dead_watch_sender() {
        let zk = ZkDiscovery::new("127.0.0.1:2181, 127.0.0.1:2182", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("whitespace-in-hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("whitespace in hosts")),
            "expected ConfigError containing watch_service whitespace-in-hosts context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "whitespace-in-hosts watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_whitespace_in_hosts_preserves_live_watch_sender() {
        let zk = ZkDiscovery::new("127.0.0.1:2181, 127.0.0.1:2182", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("whitespace-in-hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid hosts")
                    && msg.contains("whitespace in hosts")),
            "expected ConfigError containing watch_service whitespace-in-hosts context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "whitespace-in-hosts watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_invalid_base_path_rejects_without_state_changes() {
        let zk = ZkDiscovery::new("127.0.0.1:2181", "services");

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("invalid base_path should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid base_path")
                    && msg.contains("path must start with /")),
            "expected ConfigError containing watch_service invalid-base_path context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "invalid-base_path watch_async should not create watcher sender entries"
        );
        assert!(
            !zk_has_watch_poll_generation(&zk, "ps"),
            "invalid-base_path watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_invalid_base_path_compacts_dead_watch_sender() {
        let zk = ZkDiscovery::new("127.0.0.1:2181", "services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("invalid base_path should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid base_path")
                    && msg.contains("path must start with /")),
            "expected ConfigError containing watch_service invalid-base_path context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "invalid-base_path watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_watch_async_invalid_base_path_preserves_live_watch_sender() {
        let zk = ZkDiscovery::new("127.0.0.1:2181", "services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let err = <ZkDiscovery as ServiceDiscoveryAsync>::watch_async(&zk, "ps")
            .await
            .expect_err("invalid base_path should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid base_path")
                    && msg.contains("path must start with /")),
            "expected ConfigError containing watch_service invalid-base_path context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "invalid-base_path watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_zk_sync_register_removes_dead_watchers() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        drop(rx);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("register should succeed");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "dead watch sender should be removed after notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_zk_sync_deregister_removes_dead_watchers() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("register should succeed");

        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        zk.deregister("ps-0")
            .expect("deregister should succeed and trigger cleanup");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "dead watch sender should be removed after deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_zk_sync_deregister_missing_service_preserves_watchers() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = zk.deregister("missing");
        let err = result.expect_err("sync missing-service deregister should return NotFound");
        assert!(
            matches!(err, DiscoveryError::NotFound(ref id) if id == "missing"),
            "expected NotFound(missing), got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "sync missing-service deregister should not mutate active watch sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_zk_compact_dead_watch_sender_keeps_live_sender() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        zk.compact_dead_watch_sender("ps");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should not be removed by compaction"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[test]
    fn test_zk_compact_dead_watch_sender_removes_dropped_sender() {
        let zk = ZkDiscovery::new("localhost:2181", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        zk.compact_dead_watch_sender("ps");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "dropped watcher sender should be removed by compaction"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_failure_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("async register should fail when ZooKeeper is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "failed async register should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_failure_keeps_live_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("async register should fail when ZooKeeper is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved on async register failure"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_failure_does_not_cache_service() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        let service = ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(&zk, service)
            .await;
        let err = result.expect_err("async register should fail when ZooKeeper is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "failed async register should not populate local service cache"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_multi_hosts_failure_compacts_dead_watchers() {
        let zk =
            ZkDiscovery::new("127.0.0.1:1,127.0.0.1:2", "/services").with_session_timeout(100);
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err =
            result.expect_err("async register should fail when valid multi-host endpoints are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid multi-host register, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid multi-host register failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_multi_hosts_failure_keeps_live_watchers() {
        let zk =
            ZkDiscovery::new("127.0.0.1:1,127.0.0.1:2", "/services").with_session_timeout(100);
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err =
            result.expect_err("async register should fail when valid multi-host endpoints are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid multi-host register, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid multi-host register failure should preserve live watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_multi_hosts_failure_does_not_cache_service() {
        let zk =
            ZkDiscovery::new("127.0.0.1:1,127.0.0.1:2", "/services").with_session_timeout(100);
        let service = ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(&zk, service).await;
        let err =
            result.expect_err("async register should fail when valid multi-host endpoints are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid multi-host register, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid multi-host register failure should not populate local service cache"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_mixed_ipv4_ipv6_hosts_failure_compacts_dead_watchers() {
        let zk =
            ZkDiscovery::new("[::1]:1,127.0.0.1:2", "/services").with_session_timeout(100);
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result
            .expect_err("async register should fail when valid mixed-family hosts are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid mixed-family register, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid mixed-family register failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_mixed_ipv4_ipv6_hosts_failure_keeps_live_watchers() {
        let zk =
            ZkDiscovery::new("[::1]:1,127.0.0.1:2", "/services").with_session_timeout(100);
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result
            .expect_err("async register should fail when valid mixed-family hosts are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid mixed-family register, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid mixed-family register failure should preserve live watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_mixed_ipv4_ipv6_hosts_failure_does_not_cache_service() {
        let zk =
            ZkDiscovery::new("[::1]:1,127.0.0.1:2", "/services").with_session_timeout(100);
        let service = ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(&zk, service).await;
        let err = result
            .expect_err("async register should fail when valid mixed-family hosts are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid mixed-family register, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid mixed-family register failure should not populate local service cache"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_ipv6_multi_hosts_failure_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("[::1]:1,[::2]:2", "/services").with_session_timeout(100);
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err =
            result.expect_err("async register should fail when valid IPv6 multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid IPv6 multi-host register, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid IPv6 multi-host register failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_ipv6_multi_hosts_failure_keeps_live_watchers() {
        let zk = ZkDiscovery::new("[::1]:1,[::2]:2", "/services").with_session_timeout(100);
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err =
            result.expect_err("async register should fail when valid IPv6 multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid IPv6 multi-host register, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid IPv6 multi-host register failure should preserve live watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_ipv6_multi_hosts_failure_does_not_cache_service() {
        let zk = ZkDiscovery::new("[::1]:1,[::2]:2", "/services").with_session_timeout(100);
        let service = ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(&zk, service).await;
        let err =
            result.expect_err("async register should fail when valid IPv6 multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid IPv6 multi-host register, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid IPv6 multi-host register failure should not populate local service cache"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_single_ipv6_host_failure_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("[::1]:1", "/services").with_session_timeout(100);
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err =
            result.expect_err("async register should fail when valid single IPv6 host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv6 host register, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid single IPv6 host register failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_single_ipv6_host_failure_keeps_live_watchers() {
        let zk = ZkDiscovery::new("[::1]:1", "/services").with_session_timeout(100);
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err =
            result.expect_err("async register should fail when valid single IPv6 host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv6 host register, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid single IPv6 host register failure should preserve live watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_single_ipv6_host_failure_does_not_cache_service() {
        let zk = ZkDiscovery::new("[::1]:1", "/services").with_session_timeout(100);
        let service = ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(&zk, service).await;
        let err =
            result.expect_err("async register should fail when valid single IPv6 host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv6 host register, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid single IPv6 host register failure should not populate local service cache"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_single_ipv4_host_failure_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err =
            result.expect_err("async register should fail when valid single IPv4 host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv4 host register, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid single IPv4 host register failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_single_ipv4_host_failure_keeps_live_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err =
            result.expect_err("async register should fail when valid single IPv4 host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv4 host register, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid single IPv4 host register failure should preserve live watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_single_ipv4_host_failure_does_not_cache_service() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        let service = ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(&zk, service).await;
        let err =
            result.expect_err("async register should fail when valid single IPv4 host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv4 host register, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid single IPv4 host register failure should not populate local service cache"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_single_hostname_host_failure_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("localhost:1", "/services").with_session_timeout(100);
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result
            .expect_err("async register should fail when valid single hostname host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single hostname host register, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid single hostname host register failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_single_hostname_host_failure_keeps_live_watchers() {
        let zk = ZkDiscovery::new("localhost:1", "/services").with_session_timeout(100);
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result
            .expect_err("async register should fail when valid single hostname host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single hostname host register, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid single hostname host register failure should preserve live watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_single_hostname_host_failure_does_not_cache_service() {
        let zk = ZkDiscovery::new("localhost:1", "/services").with_session_timeout(100);
        let service = ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(&zk, service).await;
        let err = result
            .expect_err("async register should fail when valid single hostname host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single hostname host register, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid single hostname host register failure should not populate local service cache"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_multi_hosts_failure_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1,127.0.0.1", "/services").with_session_timeout(100);
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result
            .expect_err("async register should fail when valid host-only multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only multi-host register, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid host-only multi-host register failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_multi_hosts_failure_keeps_live_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1,127.0.0.1", "/services").with_session_timeout(100);
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result
            .expect_err("async register should fail when valid host-only multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only multi-host register, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid host-only multi-host register failure should preserve live watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_multi_hosts_failure_does_not_cache_service() {
        let zk = ZkDiscovery::new("127.0.0.1,127.0.0.1", "/services").with_session_timeout(100);
        let service = ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(&zk, service).await;
        let err = result
            .expect_err("async register should fail when valid host-only multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only multi-host register, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid host-only multi-host register failure should not populate local service cache"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_mixed_ipv4_ipv6_hosts_failure_compacts_dead_watchers(
    ) {
        let zk = ZkDiscovery::new("[::1],127.0.0.1", "/services").with_session_timeout(100);
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err(
            "async register should fail when valid host-only mixed-family list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only mixed-family register, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid host-only mixed-family register failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_mixed_ipv4_ipv6_hosts_failure_keeps_live_watchers(
    ) {
        let zk = ZkDiscovery::new("[::1],127.0.0.1", "/services").with_session_timeout(100);
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err(
            "async register should fail when valid host-only mixed-family list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only mixed-family register, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid host-only mixed-family register failure should preserve live watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_mixed_ipv4_ipv6_hosts_failure_does_not_cache_service(
    ) {
        let zk = ZkDiscovery::new("[::1],127.0.0.1", "/services").with_session_timeout(100);
        let service = ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(&zk, service).await;
        let err = result.expect_err(
            "async register should fail when valid host-only mixed-family list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only mixed-family register, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid host-only mixed-family register failure should not populate local service cache"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_ipv6_multi_hosts_failure_compacts_dead_watchers()
    {
        let zk = ZkDiscovery::new("[::1],[::2]", "/services").with_session_timeout(100);
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err(
            "async register should fail when valid host-only IPv6 multi-host list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only IPv6 multi-host register, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid host-only IPv6 multi-host register failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_ipv6_multi_hosts_failure_keeps_live_watchers()
    {
        let zk = ZkDiscovery::new("[::1],[::2]", "/services").with_session_timeout(100);
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err(
            "async register should fail when valid host-only IPv6 multi-host list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only IPv6 multi-host register, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid host-only IPv6 multi-host register failure should preserve live watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_ipv6_multi_hosts_failure_does_not_cache_service(
    ) {
        let zk = ZkDiscovery::new("[::1],[::2]", "/services").with_session_timeout(100);
        let service = ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(&zk, service).await;
        let err = result.expect_err(
            "async register should fail when valid host-only IPv6 multi-host list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only IPv6 multi-host register, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid host-only IPv6 multi-host register failure should not populate local service cache"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_single_ipv6_host_failure_compacts_dead_watchers(
    ) {
        let zk = ZkDiscovery::new("[::1]", "/services").with_session_timeout(100);
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err(
            "async register should fail when valid host-only single IPv6 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv6 host register, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid host-only single IPv6 host register failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_single_ipv6_host_failure_keeps_live_watchers()
    {
        let zk = ZkDiscovery::new("[::1]", "/services").with_session_timeout(100);
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err(
            "async register should fail when valid host-only single IPv6 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv6 host register, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid host-only single IPv6 host register failure should preserve live watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_single_ipv6_host_failure_does_not_cache_service(
    ) {
        let zk = ZkDiscovery::new("[::1]", "/services").with_session_timeout(100);
        let service = ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(&zk, service).await;
        let err = result.expect_err(
            "async register should fail when valid host-only single IPv6 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv6 host register, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid host-only single IPv6 host register failure should not populate local service cache"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_single_ipv4_host_failure_compacts_dead_watchers(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1", "/services").with_session_timeout(100);
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err(
            "async register should fail when valid host-only single IPv4 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv4 host register, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid host-only single IPv4 host register failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_single_ipv4_host_failure_keeps_live_watchers(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1", "/services").with_session_timeout(100);
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err(
            "async register should fail when valid host-only single IPv4 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv4 host register, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid host-only single IPv4 host register failure should preserve live watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_single_ipv4_host_failure_does_not_cache_service(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1", "/services").with_session_timeout(100);
        let service = ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(&zk, service).await;
        let err = result.expect_err(
            "async register should fail when valid host-only single IPv4 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv4 host register, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid host-only single IPv4 host register failure should not populate local service cache"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_single_hostname_host_failure_compacts_dead_watchers(
    ) {
        let zk = ZkDiscovery::new("localhost", "/services").with_session_timeout(100);
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err(
            "async register should fail when valid host-only single hostname host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single hostname host register, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid host-only single hostname host register failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_single_hostname_host_failure_keeps_live_watchers(
    ) {
        let zk = ZkDiscovery::new("localhost", "/services").with_session_timeout(100);
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err(
            "async register should fail when valid host-only single hostname host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single hostname host register, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid host-only single hostname host register failure should preserve live watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_valid_host_only_single_hostname_host_failure_does_not_cache_service(
    ) {
        let zk = ZkDiscovery::new("localhost", "/services").with_session_timeout(100);
        let service = ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(&zk, service).await;
        let err = result.expect_err(
            "async register should fail when valid host-only single hostname host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single hostname host register, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid host-only single hostname host register failure should not populate local service cache"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_invalid_hosts_is_config_error() {
        let zk = ZkDiscovery::new(" 127.0.0.1:2181 ", "/services");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err = result.expect_err("whitespace-padded hosts should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("leading/trailing whitespace")),
            "expected ConfigError containing invalid-hosts connect context, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_empty_hosts_is_config_error() {
        let zk = ZkDiscovery::new("", "/services");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err = result.expect_err("empty hosts should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty hosts")),
            "expected ConfigError containing empty-hosts connect context, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_empty_host_entry_is_config_error() {
        let zk = ZkDiscovery::new("127.0.0.1:2181,,127.0.0.1:2182", "/services");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err = result.expect_err("empty host entry should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty host entry")),
            "expected ConfigError containing empty-host-entry connect context, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_whitespace_in_hosts_is_config_error() {
        let zk = ZkDiscovery::new("127.0.0.1:2181, 127.0.0.1:2182", "/services");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err = result.expect_err("whitespace-in-hosts should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("whitespace in hosts")),
            "expected ConfigError containing whitespace-in-hosts connect context, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_invalid_port_is_config_error() {
        let zk = ZkDiscovery::new("127.0.0.1:notaport", "/services");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err = result.expect_err("invalid-port hosts should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing invalid-port connect context, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_out_of_range_port_is_config_error() {
        let zk = ZkDiscovery::new("127.0.0.1:70000", "/services");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err = result.expect_err("out-of-range host port should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing out-of-range-port connect context, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_malformed_ipv6_host_entry_is_config_error() {
        let zk = ZkDiscovery::new("[::1", "/services");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err = result.expect_err("malformed IPv6 host entry should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid host entry")),
            "expected ConfigError containing malformed-host-entry connect context, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_single_ipv6_host_returns_connection_failed_when_unreachable() {
        let zk = ZkDiscovery::new("[::1]:1", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err =
            result.expect_err("unreachable but valid single IPv6 host should fail connecting");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv6 host, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_single_ipv4_host_returns_connection_failed_when_unreachable() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err =
            result.expect_err("unreachable but valid single IPv4 host should fail connecting");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv4 host, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_single_hostname_host_returns_connection_failed_when_unreachable()
    {
        let zk = ZkDiscovery::new("localhost:1", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err =
            result.expect_err("unreachable but valid single hostname host should fail connecting");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single hostname host, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_multi_hosts_returns_connection_failed_when_unreachable() {
        let zk =
            ZkDiscovery::new("127.0.0.1:1,127.0.0.1:2", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err = result.expect_err("unreachable but valid multi-host list should fail connecting");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid multi-host list, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_mixed_ipv4_ipv6_hosts_returns_connection_failed_when_unreachable()
    {
        let zk =
            ZkDiscovery::new("[::1]:1,127.0.0.1:2", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err =
            result.expect_err("unreachable but valid mixed-family hosts should fail connecting");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid mixed-family hosts, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_ipv6_multi_hosts_returns_connection_failed_when_unreachable() {
        let zk = ZkDiscovery::new("[::1]:1,[::2]:2", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err =
            result.expect_err("unreachable but valid IPv6 multi-host list should fail connecting");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid IPv6 multi-host list, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_host_only_multi_hosts_returns_connection_failed_when_unreachable()
    {
        let zk = ZkDiscovery::new("127.0.0.1,127.0.0.1", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err = result.expect_err("unreachable but valid host-only multi-host list should fail connecting");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only multi-host list, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_host_only_mixed_ipv4_ipv6_hosts_returns_connection_failed_when_unreachable(
    ) {
        let zk = ZkDiscovery::new("[::1],127.0.0.1", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err = result
            .expect_err("unreachable but valid host-only mixed-family list should fail connecting");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only mixed-family list, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_host_only_ipv6_multi_hosts_returns_connection_failed_when_unreachable()
    {
        let zk = ZkDiscovery::new("[::1],[::2]", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err = result.expect_err(
            "unreachable but valid host-only IPv6 multi-host list should fail connecting",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only IPv6 multi-host list, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_host_only_single_ipv6_host_returns_connection_failed_when_unreachable(
    ) {
        let zk = ZkDiscovery::new("[::1]", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err = result.expect_err(
            "unreachable but valid host-only single IPv6 host should fail connecting",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv6 host, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_host_only_single_ipv4_host_returns_connection_failed_when_unreachable(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err = result.expect_err(
            "unreachable but valid host-only single IPv4 host should fail connecting",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv4 host, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_host_only_single_hostname_host_returns_connection_failed_when_unreachable(
    ) {
        let zk = ZkDiscovery::new("localhost", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err = result.expect_err(
            "unreachable but valid host-only single hostname host should fail connecting",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single hostname host, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_host_port_single_ipv4_host_disconnect_and_reconnect() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        let first = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let first_err = first.expect_err(
            "unreachable but valid host:port single IPv4 host should fail connecting",
        );
        assert!(
            matches!(first_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for host:port IPv4 host, got {first_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed host:port IPv4 connect should not retain client handle"
        );

        <ZkDiscovery as ServiceDiscoveryAsync>::disconnect(&zk)
            .await
            .expect("disconnect should succeed after failed connect attempt");
        let second = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let second_err = second.expect_err(
            "reconnect attempt with unreachable but valid host:port single IPv4 host should fail",
        );
        assert!(
            matches!(second_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context on reconnect for host:port IPv4 host, got {second_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed reconnect for host:port IPv4 connect should keep client handle empty"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_host_only_single_ipv4_host_disconnect_and_reconnect() {
        let zk = ZkDiscovery::new("127.0.0.1", "/services").with_session_timeout(100);
        let first = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let first_err = first.expect_err(
            "unreachable but valid host-only single IPv4 host should fail connecting",
        );
        assert!(
            matches!(first_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for host-only IPv4 host, got {first_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed host-only IPv4 connect should not retain client handle"
        );

        <ZkDiscovery as ServiceDiscoveryAsync>::disconnect(&zk)
            .await
            .expect("disconnect should succeed after failed connect attempt");
        let second = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let second_err = second.expect_err(
            "reconnect attempt with unreachable but valid host-only single IPv4 host should fail",
        );
        assert!(
            matches!(second_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context on reconnect for host-only IPv4 host, got {second_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed reconnect for host-only IPv4 connect should keep client handle empty"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_host_port_single_ipv6_host_disconnect_and_reconnect() {
        let zk = ZkDiscovery::new("[::1]:1", "/services").with_session_timeout(100);
        let first = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let first_err = first.expect_err(
            "unreachable but valid host:port single IPv6 host should fail connecting",
        );
        assert!(
            matches!(first_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for host:port IPv6 host, got {first_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed host:port IPv6 connect should not retain client handle"
        );

        <ZkDiscovery as ServiceDiscoveryAsync>::disconnect(&zk)
            .await
            .expect("disconnect should succeed after failed connect attempt");
        let second = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let second_err = second.expect_err(
            "reconnect attempt with unreachable but valid host:port single IPv6 host should fail",
        );
        assert!(
            matches!(second_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context on reconnect for host:port IPv6 host, got {second_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed reconnect for host:port IPv6 connect should keep client handle empty"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_host_only_single_ipv6_host_disconnect_and_reconnect() {
        let zk = ZkDiscovery::new("[::1]", "/services").with_session_timeout(100);
        let first = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let first_err = first.expect_err(
            "unreachable but valid host-only single IPv6 host should fail connecting",
        );
        assert!(
            matches!(first_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for host-only IPv6 host, got {first_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed host-only IPv6 connect should not retain client handle"
        );

        <ZkDiscovery as ServiceDiscoveryAsync>::disconnect(&zk)
            .await
            .expect("disconnect should succeed after failed connect attempt");
        let second = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let second_err = second.expect_err(
            "reconnect attempt with unreachable but valid host-only single IPv6 host should fail",
        );
        assert!(
            matches!(second_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context on reconnect for host-only IPv6 host, got {second_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed reconnect for host-only IPv6 connect should keep client handle empty"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_host_port_single_hostname_disconnect_and_reconnect() {
        let zk = ZkDiscovery::new("localhost:1", "/services").with_session_timeout(100);
        let first = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let first_err = first.expect_err(
            "unreachable but valid host:port single hostname should fail connecting",
        );
        assert!(
            matches!(first_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for host:port hostname, got {first_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed host:port hostname connect should not retain client handle"
        );

        <ZkDiscovery as ServiceDiscoveryAsync>::disconnect(&zk)
            .await
            .expect("disconnect should succeed after failed connect attempt");
        let second = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let second_err = second.expect_err(
            "reconnect attempt with unreachable but valid host:port single hostname should fail",
        );
        assert!(
            matches!(second_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context on reconnect for host:port hostname, got {second_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed reconnect for host:port hostname connect should keep client handle empty"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_host_only_single_hostname_disconnect_and_reconnect() {
        let zk = ZkDiscovery::new("localhost", "/services").with_session_timeout(100);
        let first = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let first_err = first.expect_err(
            "unreachable but valid host-only single hostname should fail connecting",
        );
        assert!(
            matches!(first_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for host-only hostname, got {first_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed host-only hostname connect should not retain client handle"
        );

        <ZkDiscovery as ServiceDiscoveryAsync>::disconnect(&zk)
            .await
            .expect("disconnect should succeed after failed connect attempt");
        let second = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let second_err = second.expect_err(
            "reconnect attempt with unreachable but valid host-only single hostname should fail",
        );
        assert!(
            matches!(second_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context on reconnect for host-only hostname, got {second_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed reconnect for host-only hostname connect should keep client handle empty"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_multi_hosts_disconnect_and_reconnect() {
        let zk =
            ZkDiscovery::new("127.0.0.1:1,127.0.0.1:2", "/services").with_session_timeout(100);
        let first = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let first_err = first
            .expect_err("unreachable but valid multi-host list should fail connecting");
        assert!(
            matches!(first_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for multi-host list, got {first_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed multi-host connect should not retain client handle"
        );

        <ZkDiscovery as ServiceDiscoveryAsync>::disconnect(&zk)
            .await
            .expect("disconnect should succeed after failed connect attempt");
        let second = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let second_err = second.expect_err(
            "reconnect attempt with unreachable but valid multi-host list should fail",
        );
        assert!(
            matches!(second_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context on reconnect for multi-host list, got {second_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed reconnect for multi-host connect should keep client handle empty"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_mixed_ipv4_ipv6_hosts_disconnect_and_reconnect() {
        let zk = ZkDiscovery::new("[::1]:1,127.0.0.1:2", "/services").with_session_timeout(100);
        let first = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let first_err =
            first.expect_err("unreachable but valid mixed-family hosts should fail connecting");
        assert!(
            matches!(first_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for mixed-family hosts, got {first_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed mixed-family connect should not retain client handle"
        );

        <ZkDiscovery as ServiceDiscoveryAsync>::disconnect(&zk)
            .await
            .expect("disconnect should succeed after failed connect attempt");
        let second = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let second_err = second.expect_err(
            "reconnect attempt with unreachable but valid mixed-family hosts should fail",
        );
        assert!(
            matches!(second_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context on reconnect for mixed-family hosts, got {second_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed reconnect for mixed-family connect should keep client handle empty"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_ipv6_multi_hosts_disconnect_and_reconnect() {
        let zk = ZkDiscovery::new("[::1]:1,[::2]:2", "/services").with_session_timeout(100);
        let first = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let first_err = first
            .expect_err("unreachable but valid IPv6 multi-host list should fail connecting");
        assert!(
            matches!(first_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for IPv6 multi-host list, got {first_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed IPv6 multi-host connect should not retain client handle"
        );

        <ZkDiscovery as ServiceDiscoveryAsync>::disconnect(&zk)
            .await
            .expect("disconnect should succeed after failed connect attempt");
        let second = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let second_err = second.expect_err(
            "reconnect attempt with unreachable but valid IPv6 multi-host list should fail",
        );
        assert!(
            matches!(second_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context on reconnect for IPv6 multi-host list, got {second_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed reconnect for IPv6 multi-host connect should keep client handle empty"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_host_only_multi_hosts_disconnect_and_reconnect() {
        let zk = ZkDiscovery::new("127.0.0.1,127.0.0.1", "/services").with_session_timeout(100);
        let first = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let first_err = first.expect_err(
            "unreachable but valid host-only multi-host list should fail connecting",
        );
        assert!(
            matches!(first_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for host-only multi-host list, got {first_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed host-only multi-host connect should not retain client handle"
        );

        <ZkDiscovery as ServiceDiscoveryAsync>::disconnect(&zk)
            .await
            .expect("disconnect should succeed after failed connect attempt");
        let second = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let second_err = second.expect_err(
            "reconnect attempt with unreachable but valid host-only multi-host list should fail",
        );
        assert!(
            matches!(second_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context on reconnect for host-only multi-host list, got {second_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed reconnect for host-only multi-host connect should keep client handle empty"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_host_only_mixed_ipv4_ipv6_hosts_disconnect_and_reconnect() {
        let zk = ZkDiscovery::new("[::1],127.0.0.1", "/services").with_session_timeout(100);
        let first = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let first_err = first.expect_err(
            "unreachable but valid host-only mixed-family list should fail connecting",
        );
        assert!(
            matches!(first_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for host-only mixed-family list, got {first_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed host-only mixed-family connect should not retain client handle"
        );

        <ZkDiscovery as ServiceDiscoveryAsync>::disconnect(&zk)
            .await
            .expect("disconnect should succeed after failed connect attempt");
        let second = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let second_err = second.expect_err(
            "reconnect attempt with unreachable but valid host-only mixed-family list should fail",
        );
        assert!(
            matches!(second_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context on reconnect for host-only mixed-family list, got {second_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed reconnect for host-only mixed-family connect should keep client handle empty"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_valid_host_only_ipv6_multi_hosts_disconnect_and_reconnect() {
        let zk = ZkDiscovery::new("[::1],[::2]", "/services").with_session_timeout(100);
        let first = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let first_err = first.expect_err(
            "unreachable but valid host-only IPv6 multi-host list should fail connecting",
        );
        assert!(
            matches!(first_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for host-only IPv6 multi-host list, got {first_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed host-only IPv6 multi-host connect should not retain client handle"
        );

        <ZkDiscovery as ServiceDiscoveryAsync>::disconnect(&zk)
            .await
            .expect("disconnect should succeed after failed connect attempt");
        let second = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let second_err = second.expect_err(
            "reconnect attempt with unreachable but valid host-only IPv6 multi-host list should fail",
        );
        assert!(
            matches!(second_err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context on reconnect for host-only IPv6 multi-host list, got {second_err:?}"
        );
        assert!(
            zk.client.lock().await.is_none(),
            "failed reconnect for host-only IPv6 multi-host connect should keep client handle empty"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_invalid_hosts_compacts_dead_watchers() {
        let zk = ZkDiscovery::new(" 127.0.0.1:2181 ", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("invalid hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("leading/trailing whitespace")),
            "expected ConfigError containing invalid-hosts register context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "config-error register should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_invalid_hosts_keeps_live_watchers() {
        let zk = ZkDiscovery::new(" 127.0.0.1:2181 ", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("invalid hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("leading/trailing whitespace")),
            "expected ConfigError containing invalid-hosts register context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved on invalid-hosts register failure"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_empty_hosts_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("empty hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty hosts")),
            "expected ConfigError containing empty-hosts register context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "config-error register should compact dead watcher sender entries for empty hosts"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_empty_hosts_keeps_live_watchers() {
        let zk = ZkDiscovery::new("", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("empty hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty hosts")),
            "expected ConfigError containing empty-hosts register context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved on empty-hosts register failure"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_empty_host_entry_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:2181,,127.0.0.1:2182", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("empty host entry should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty host entry")),
            "expected ConfigError containing empty-host-entry register context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "config-error register should compact dead watcher sender entries for empty-host-entry hosts"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_empty_host_entry_keeps_live_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:2181,,127.0.0.1:2182", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("empty host entry should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty host entry")),
            "expected ConfigError containing empty-host-entry register context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved on empty-host-entry register failure"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_whitespace_in_hosts_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:2181, 127.0.0.1:2182", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("whitespace-in-hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("whitespace in hosts")),
            "expected ConfigError containing whitespace-in-hosts register context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "config-error register should compact dead watcher sender entries for whitespace-in-hosts"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_whitespace_in_hosts_keeps_live_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:2181, 127.0.0.1:2182", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("whitespace-in-hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("whitespace in hosts")),
            "expected ConfigError containing whitespace-in-hosts register context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved on whitespace-in-hosts register failure"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_malformed_ipv6_host_entry_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("[::1", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("malformed host entry should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid host entry")),
            "expected ConfigError containing malformed-host-entry register context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "config-error register should compact dead watcher sender entries for malformed host entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_malformed_ipv6_host_entry_keeps_live_watchers() {
        let zk = ZkDiscovery::new("[::1", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("malformed host entry should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid host entry")),
            "expected ConfigError containing malformed-host-entry register context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved on malformed-host-entry register failure"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_invalid_port_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:notaport", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("invalid-port hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing invalid-port register context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "config-error register should compact dead watcher sender entries for invalid-port hosts"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_out_of_range_port_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:70000", "/services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("out-of-range host port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing out-of-range-port register context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "config-error register should compact dead watcher sender entries for out-of-range host ports"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_invalid_port_keeps_live_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:notaport", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("invalid-port hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing invalid-port register context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved on invalid-port register failure"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_out_of_range_port_keeps_live_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:70000", "/services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("out-of-range host port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing out-of-range-port register context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved on out-of-range-port register failure"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_invalid_hosts_preserves_local_cache() {
        let zk = ZkDiscovery::new(" 127.0.0.1:2181 ", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err("invalid hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("leading/trailing whitespace")),
            "expected ConfigError containing invalid-hosts discover context, got {err:?}"
        );
        assert_eq!(
            zk.discover("ps").expect("discover should succeed after config failure").len(),
            1,
            "config-error async discover should preserve local cache entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_empty_hosts_preserves_local_cache() {
        let zk = ZkDiscovery::new("", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err("empty hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty hosts")),
            "expected ConfigError containing empty-hosts discover context, got {err:?}"
        );
        assert_eq!(
            zk.discover("ps").expect("discover should succeed after config failure").len(),
            1,
            "empty-hosts async discover config error should preserve local cache entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_empty_host_entry_preserves_local_cache() {
        let zk = ZkDiscovery::new("127.0.0.1:2181,,127.0.0.1:2182", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err("empty host entry should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty host entry")),
            "expected ConfigError containing empty-host-entry discover context, got {err:?}"
        );
        assert_eq!(
            zk.discover("ps").expect("discover should succeed after config failure").len(),
            1,
            "empty-host-entry async discover config error should preserve local cache entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_whitespace_in_hosts_preserves_local_cache() {
        let zk = ZkDiscovery::new("127.0.0.1:2181, 127.0.0.1:2182", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err("whitespace-in-hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("whitespace in hosts")),
            "expected ConfigError containing whitespace-in-hosts discover context, got {err:?}"
        );
        assert_eq!(
            zk.discover("ps").expect("discover should succeed after config failure").len(),
            1,
            "whitespace-in-hosts async discover config error should preserve local cache entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_invalid_port_preserves_local_cache() {
        let zk = ZkDiscovery::new("127.0.0.1:notaport", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err("invalid-port hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing invalid-port discover context, got {err:?}"
        );
        assert_eq!(
            zk.discover("ps").expect("discover should succeed after config failure").len(),
            1,
            "invalid-port async discover config error should preserve local cache entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_out_of_range_port_preserves_local_cache() {
        let zk = ZkDiscovery::new("127.0.0.1:70000", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err("out-of-range hosts port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing out-of-range-port discover context, got {err:?}"
        );
        assert_eq!(
            zk.discover("ps").expect("discover should succeed after config failure").len(),
            1,
            "out-of-range-port async discover config error should preserve local cache entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_malformed_ipv6_host_entry_preserves_local_cache() {
        let zk = ZkDiscovery::new("[::1", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err("malformed IPv6 host entry should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid host entry")),
            "expected ConfigError containing malformed-host-entry discover context, got {err:?}"
        );
        assert_eq!(
            zk.discover("ps").expect("discover should succeed after config failure").len(),
            1,
            "malformed-host-entry async discover config error should preserve local cache entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_connect_invalid_base_path_is_config_error() {
        let zk = ZkDiscovery::new("127.0.0.1:2181", "services");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::connect(&zk).await;
        let err = result.expect_err("relative base_path should be rejected");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid base_path")
                    && msg.contains("path must start with /")),
            "expected ConfigError containing invalid-base_path connect context, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_invalid_base_path_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:2181", "services");
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("invalid base_path should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid base_path")
                    && msg.contains("path must start with /")),
            "expected ConfigError containing invalid-base_path register context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "config-error register should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_register_invalid_base_path_keeps_live_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:2181", "services");
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::register_async(
            &zk,
            ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000),
        )
        .await;
        let err = result.expect_err("invalid base_path should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid base_path")
                    && msg.contains("path must start with /")),
            "expected ConfigError containing invalid-base_path register context, got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved on invalid-base_path register failure"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_invalid_base_path_preserves_local_cache() {
        let zk = ZkDiscovery::new("127.0.0.1:2181", "services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err("invalid base_path should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid base_path")
                    && msg.contains("path must start with /")),
            "expected ConfigError containing invalid-base_path discover context, got {err:?}"
        );
        assert_eq!(
            zk.discover("ps").expect("discover should succeed after config failure").len(),
            1,
            "config-error async discover should preserve local cache entries"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_failure_still_removes_local_cache_and_notifies_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("async deregister should fail when ZooKeeper is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "failed async deregister should still remove service from local cache"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_multi_hosts_failure_still_removes_local_cache_and_notifies_watchers(
    ) {
        let zk =
            ZkDiscovery::new("127.0.0.1:1,127.0.0.1:2", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid multi-host endpoints are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid multi-host deregister, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid multi-host async deregister failure should still remove service from local cache"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_multi_hosts_failure_compacts_dead_watchers() {
        let zk =
            ZkDiscovery::new("127.0.0.1:1,127.0.0.1:2", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid multi-host endpoints are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid multi-host deregister, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid multi-host deregister failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_multi_hosts_failure_cleans_registered_path() {
        let zk =
            ZkDiscovery::new("127.0.0.1:1,127.0.0.1:2", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid multi-host endpoints are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid multi-host deregister, got {err:?}"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "valid multi-host deregister failure should remove registered path entry even when backend delete fails"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_multi_hosts_failure_keeps_live_watchers() {
        let zk =
            ZkDiscovery::new("127.0.0.1:1,127.0.0.1:2", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid multi-host endpoints are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid multi-host deregister, got {err:?}"
        );
        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid multi-host deregister failure should preserve live watcher sender after notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_mixed_ipv4_ipv6_hosts_failure_still_removes_local_cache_and_notifies_watchers(
    ) {
        let zk =
            ZkDiscovery::new("[::1]:1,127.0.0.1:2", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid mixed-family hosts are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid mixed-family deregister, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid mixed-family async deregister failure should still remove service from local cache"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_mixed_ipv4_ipv6_hosts_failure_compacts_dead_watchers()
    {
        let zk =
            ZkDiscovery::new("[::1]:1,127.0.0.1:2", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid mixed-family hosts are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid mixed-family deregister, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid mixed-family deregister failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_mixed_ipv4_ipv6_hosts_failure_cleans_registered_path()
    {
        let zk =
            ZkDiscovery::new("[::1]:1,127.0.0.1:2", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid mixed-family hosts are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid mixed-family deregister, got {err:?}"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "valid mixed-family deregister failure should remove registered path entry even when backend delete fails"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_mixed_ipv4_ipv6_hosts_failure_keeps_live_watchers() {
        let zk =
            ZkDiscovery::new("[::1]:1,127.0.0.1:2", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid mixed-family hosts are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid mixed-family deregister, got {err:?}"
        );
        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid mixed-family deregister failure should preserve live watcher sender after notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_ipv6_multi_hosts_failure_still_removes_local_cache_and_notifies_watchers(
    ) {
        let zk = ZkDiscovery::new("[::1]:1,[::2]:2", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err =
            result.expect_err("async deregister should fail when valid IPv6 multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid IPv6 multi-host deregister, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid IPv6 multi-host async deregister failure should still remove service from local cache"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_ipv6_multi_hosts_failure_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("[::1]:1,[::2]:2", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err =
            result.expect_err("async deregister should fail when valid IPv6 multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid IPv6 multi-host deregister, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid IPv6 multi-host deregister failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_ipv6_multi_hosts_failure_cleans_registered_path() {
        let zk = ZkDiscovery::new("[::1]:1,[::2]:2", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err =
            result.expect_err("async deregister should fail when valid IPv6 multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid IPv6 multi-host deregister, got {err:?}"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "valid IPv6 multi-host deregister failure should remove registered path entry even when backend delete fails"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_ipv6_multi_hosts_failure_keeps_live_watchers() {
        let zk = ZkDiscovery::new("[::1]:1,[::2]:2", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err =
            result.expect_err("async deregister should fail when valid IPv6 multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid IPv6 multi-host deregister, got {err:?}"
        );
        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid IPv6 multi-host deregister failure should preserve live watcher sender after notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_single_ipv6_host_failure_still_removes_local_cache_and_notifies_watchers(
    ) {
        let zk = ZkDiscovery::new("[::1]:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err =
            result.expect_err("async deregister should fail when valid single IPv6 host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv6 host deregister, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid single IPv6 host async deregister failure should still remove service from local cache"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_single_ipv6_host_failure_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("[::1]:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err =
            result.expect_err("async deregister should fail when valid single IPv6 host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv6 host deregister, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid single IPv6 host deregister failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_single_ipv6_host_failure_cleans_registered_path() {
        let zk = ZkDiscovery::new("[::1]:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err =
            result.expect_err("async deregister should fail when valid single IPv6 host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv6 host deregister, got {err:?}"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "valid single IPv6 host deregister failure should remove registered path entry even when backend delete fails"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_single_ipv6_host_failure_keeps_live_watchers() {
        let zk = ZkDiscovery::new("[::1]:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err =
            result.expect_err("async deregister should fail when valid single IPv6 host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv6 host deregister, got {err:?}"
        );
        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid single IPv6 host deregister failure should preserve live watcher sender after notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_single_ipv4_host_failure_still_removes_local_cache_and_notifies_watchers(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err =
            result.expect_err("async deregister should fail when valid single IPv4 host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv4 host deregister, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid single IPv4 host async deregister failure should still remove service from local cache"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_single_ipv4_host_failure_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err =
            result.expect_err("async deregister should fail when valid single IPv4 host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv4 host deregister, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid single IPv4 host deregister failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_single_ipv4_host_failure_cleans_registered_path() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err =
            result.expect_err("async deregister should fail when valid single IPv4 host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv4 host deregister, got {err:?}"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "valid single IPv4 host deregister failure should remove registered path entry even when backend delete fails"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_single_ipv4_host_failure_keeps_live_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err =
            result.expect_err("async deregister should fail when valid single IPv4 host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv4 host deregister, got {err:?}"
        );
        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid single IPv4 host deregister failure should preserve live watcher sender after notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_single_hostname_host_failure_still_removes_local_cache_and_notifies_watchers(
    ) {
        let zk = ZkDiscovery::new("localhost:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid single hostname host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single hostname host deregister, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid single hostname host async deregister failure should still remove service from local cache"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_single_hostname_host_failure_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("localhost:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid single hostname host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single hostname host deregister, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid single hostname host deregister failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_single_hostname_host_failure_cleans_registered_path() {
        let zk = ZkDiscovery::new("localhost:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid single hostname host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single hostname host deregister, got {err:?}"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "valid single hostname host deregister failure should remove registered path entry even when backend delete fails"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_single_hostname_host_failure_keeps_live_watchers() {
        let zk = ZkDiscovery::new("localhost:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid single hostname host is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single hostname host deregister, got {err:?}"
        );
        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid single hostname host deregister failure should preserve live watcher sender after notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_multi_hosts_failure_still_removes_local_cache_and_notifies_watchers(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1,127.0.0.1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid host-only multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only multi-host deregister, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid host-only multi-host async deregister failure should still remove service from local cache"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_multi_hosts_failure_compacts_dead_watchers()
    {
        let zk = ZkDiscovery::new("127.0.0.1,127.0.0.1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid host-only multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only multi-host deregister, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid host-only multi-host deregister failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_multi_hosts_failure_cleans_registered_path()
    {
        let zk = ZkDiscovery::new("127.0.0.1,127.0.0.1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid host-only multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only multi-host deregister, got {err:?}"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "valid host-only multi-host deregister failure should remove registered path entry even when backend delete fails"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_multi_hosts_failure_keeps_live_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1,127.0.0.1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result
            .expect_err("async deregister should fail when valid host-only multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only multi-host deregister, got {err:?}"
        );
        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid host-only multi-host deregister failure should preserve live watcher sender after notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_mixed_ipv4_ipv6_hosts_failure_still_removes_local_cache_and_notifies_watchers(
    ) {
        let zk = ZkDiscovery::new("[::1],127.0.0.1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only mixed-family list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only mixed-family deregister, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid host-only mixed-family async deregister failure should still remove service from local cache"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_mixed_ipv4_ipv6_hosts_failure_compacts_dead_watchers(
    ) {
        let zk = ZkDiscovery::new("[::1],127.0.0.1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only mixed-family list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only mixed-family deregister, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid host-only mixed-family deregister failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_mixed_ipv4_ipv6_hosts_failure_cleans_registered_path(
    ) {
        let zk = ZkDiscovery::new("[::1],127.0.0.1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only mixed-family list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only mixed-family deregister, got {err:?}"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "valid host-only mixed-family deregister failure should remove registered path entry even when backend delete fails"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_mixed_ipv4_ipv6_hosts_failure_keeps_live_watchers(
    ) {
        let zk = ZkDiscovery::new("[::1],127.0.0.1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only mixed-family list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only mixed-family deregister, got {err:?}"
        );
        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid host-only mixed-family deregister failure should preserve live watcher sender after notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_ipv6_multi_hosts_failure_still_removes_local_cache_and_notifies_watchers(
    ) {
        let zk = ZkDiscovery::new("[::1],[::2]", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only IPv6 multi-host list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only IPv6 multi-host deregister, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid host-only IPv6 multi-host async deregister failure should still remove service from local cache"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_ipv6_multi_hosts_failure_compacts_dead_watchers(
    ) {
        let zk = ZkDiscovery::new("[::1],[::2]", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only IPv6 multi-host list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only IPv6 multi-host deregister, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid host-only IPv6 multi-host deregister failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_ipv6_multi_hosts_failure_cleans_registered_path(
    ) {
        let zk = ZkDiscovery::new("[::1],[::2]", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only IPv6 multi-host list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only IPv6 multi-host deregister, got {err:?}"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "valid host-only IPv6 multi-host deregister failure should remove registered path entry even when backend delete fails"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_ipv6_multi_hosts_failure_keeps_live_watchers(
    ) {
        let zk = ZkDiscovery::new("[::1],[::2]", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only IPv6 multi-host list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only IPv6 multi-host deregister, got {err:?}"
        );
        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid host-only IPv6 multi-host deregister failure should preserve live watcher sender after notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_single_ipv6_host_failure_still_removes_local_cache_and_notifies_watchers(
    ) {
        let zk = ZkDiscovery::new("[::1]", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only single IPv6 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv6 host deregister, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid host-only single IPv6 host async deregister failure should still remove service from local cache"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_single_ipv6_host_failure_compacts_dead_watchers(
    ) {
        let zk = ZkDiscovery::new("[::1]", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only single IPv6 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv6 host deregister, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid host-only single IPv6 host deregister failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_single_ipv6_host_failure_cleans_registered_path(
    ) {
        let zk = ZkDiscovery::new("[::1]", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only single IPv6 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv6 host deregister, got {err:?}"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "valid host-only single IPv6 host deregister failure should remove registered path entry even when backend delete fails"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_single_ipv6_host_failure_keeps_live_watchers(
    ) {
        let zk = ZkDiscovery::new("[::1]", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only single IPv6 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv6 host deregister, got {err:?}"
        );
        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid host-only single IPv6 host deregister failure should preserve live watcher sender after notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_single_ipv4_host_failure_still_removes_local_cache_and_notifies_watchers(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only single IPv4 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv4 host deregister, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid host-only single IPv4 host async deregister failure should still remove service from local cache"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_single_ipv4_host_failure_compacts_dead_watchers(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only single IPv4 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv4 host deregister, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid host-only single IPv4 host deregister failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_single_ipv4_host_failure_cleans_registered_path(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only single IPv4 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv4 host deregister, got {err:?}"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "valid host-only single IPv4 host deregister failure should remove registered path entry even when backend delete fails"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_single_ipv4_host_failure_keeps_live_watchers(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only single IPv4 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv4 host deregister, got {err:?}"
        );
        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid host-only single IPv4 host deregister failure should preserve live watcher sender after notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_single_hostname_host_failure_still_removes_local_cache_and_notifies_watchers(
    ) {
        let zk = ZkDiscovery::new("localhost", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only single hostname host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single hostname host deregister, got {err:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "valid host-only single hostname host async deregister failure should still remove service from local cache"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_single_hostname_host_failure_compacts_dead_watchers(
    ) {
        let zk = ZkDiscovery::new("localhost", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only single hostname host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single hostname host deregister, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "valid host-only single hostname host deregister failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_single_hostname_host_failure_cleans_registered_path(
    ) {
        let zk = ZkDiscovery::new("localhost", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only single hostname host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single hostname host deregister, got {err:?}"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "valid host-only single hostname host deregister failure should remove registered path entry even when backend delete fails"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_valid_host_only_single_hostname_host_failure_keeps_live_watchers(
    ) {
        let zk = ZkDiscovery::new("localhost", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err(
            "async deregister should fail when valid host-only single hostname host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single hostname host deregister, got {err:?}"
        );
        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "valid host-only single hostname host deregister failure should preserve live watcher sender after notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_invalid_hosts_still_notifies_and_returns_error() {
        let zk = ZkDiscovery::new(" 127.0.0.1:2181 ", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let mut rx = zk.watch("ps").expect("watch should succeed");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("invalid hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("leading/trailing whitespace")),
            "expected ConfigError containing invalid-hosts connect context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "local cache entry should remain removed even when async deregister fails on invalid hosts"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "registered-path bookkeeping should remain removed even on invalid-host config failure"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved after invalid-hosts deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_invalid_hosts_compacts_dead_watchers() {
        let zk = ZkDiscovery::new(" 127.0.0.1:2181 ", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("invalid hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("leading/trailing whitespace")),
            "expected ConfigError containing invalid-hosts connect context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "dead watcher sender should be compacted on invalid-hosts deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_empty_hosts_still_notifies_and_returns_error() {
        let zk = ZkDiscovery::new("", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let mut rx = zk.watch("ps").expect("watch should succeed");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("empty hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty hosts")),
            "expected ConfigError containing empty-hosts connect context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "local cache entry should remain removed even when async deregister fails on empty hosts"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "registered-path bookkeeping should remain removed even on empty-hosts config failure"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved after empty-hosts deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_empty_hosts_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("empty hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty hosts")),
            "expected ConfigError containing empty-hosts connect context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "dead watcher sender should be compacted on empty-hosts deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_empty_host_entry_still_notifies_and_returns_error() {
        let zk = ZkDiscovery::new("127.0.0.1:2181,,127.0.0.1:2182", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let mut rx = zk.watch("ps").expect("watch should succeed");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("empty host entry should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty host entry")),
            "expected ConfigError containing empty-host-entry connect context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "local cache entry should remain removed even when async deregister fails on empty-host-entry hosts"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "registered-path bookkeeping should remain removed even on empty-host-entry config failure"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved after empty-host-entry deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_empty_host_entry_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:2181,,127.0.0.1:2182", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("empty host entry should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("empty host entry")),
            "expected ConfigError containing empty-host-entry connect context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "dead watcher sender should be compacted on empty-host-entry deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_whitespace_in_hosts_still_notifies_and_returns_error() {
        let zk = ZkDiscovery::new("127.0.0.1:2181, 127.0.0.1:2182", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let mut rx = zk.watch("ps").expect("watch should succeed");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("whitespace-in-hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("whitespace in hosts")),
            "expected ConfigError containing whitespace-in-hosts connect context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "local cache entry should remain removed even when async deregister fails on whitespace-in-hosts"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "registered-path bookkeeping should remain removed even on whitespace-in-hosts config failure"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved after whitespace-in-hosts deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_whitespace_in_hosts_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:2181, 127.0.0.1:2182", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("whitespace-in-hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("whitespace in hosts")),
            "expected ConfigError containing whitespace-in-hosts connect context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "dead watcher sender should be compacted on whitespace-in-hosts deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_malformed_ipv6_host_entry_still_notifies_and_returns_error() {
        let zk = ZkDiscovery::new("[::1", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let mut rx = zk.watch("ps").expect("watch should succeed");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("malformed host entry should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid host entry")),
            "expected ConfigError containing malformed-host-entry connect context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "local cache entry should remain removed even when async deregister fails on malformed host entries"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "registered-path bookkeeping should remain removed even on malformed-host-entry config failure"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved after malformed-host-entry deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_malformed_ipv6_host_entry_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("[::1", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("malformed host entry should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid host entry")),
            "expected ConfigError containing malformed-host-entry connect context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "dead watcher sender should be compacted on malformed-host-entry deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_invalid_port_still_notifies_and_returns_error() {
        let zk = ZkDiscovery::new("127.0.0.1:notaport", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let mut rx = zk.watch("ps").expect("watch should succeed");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("invalid-port hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing invalid-port connect context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "local cache entry should remain removed even when async deregister fails on invalid-port hosts"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "registered-path bookkeeping should remain removed even on invalid-port config failure"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved after invalid-port deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_invalid_port_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:notaport", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("invalid-port hosts should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing invalid-port connect context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "dead watcher sender should be compacted on invalid-port deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_out_of_range_port_still_notifies_and_returns_error() {
        let zk = ZkDiscovery::new("127.0.0.1:70000", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let mut rx = zk.watch("ps").expect("watch should succeed");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("out-of-range host port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing out-of-range-port connect context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "local cache entry should remain removed even when async deregister fails on out-of-range host ports"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "registered-path bookkeeping should remain removed even on out-of-range-port config failure"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved after out-of-range-port deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_out_of_range_port_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:70000", "/services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("out-of-range host port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid hosts")
                    && msg.contains("invalid port")),
            "expected ConfigError containing out-of-range-port connect context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "dead watcher sender should be compacted on out-of-range-port deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_invalid_base_path_still_notifies_and_returns_error() {
        let zk = ZkDiscovery::new("127.0.0.1:2181", "services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let mut rx = zk.watch("ps").expect("watch should succeed");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("invalid base_path should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid base_path")
                    && msg.contains("path must start with /")),
            "expected ConfigError containing invalid-base_path connect context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "local cache entry should remain removed even when async deregister fails on invalid base_path"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "registered-path bookkeeping should remain removed even on invalid-base_path config failure"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved after invalid-base-path deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_invalid_base_path_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:2181", "services");
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());
        let rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("invalid base_path should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("connect")
                    && msg.contains("invalid base_path")
                    && msg.contains("path must start with /")),
            "expected ConfigError containing invalid-base_path connect context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "dead watcher sender should be compacted on invalid-base-path deregister notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_local_only_service_returns_ok() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let mut rx = zk.watch("ps").expect("watch should succeed");
        <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0")
            .await
            .expect("async deregister should succeed for local-only service without registered backend path");
        assert!(
            zk.discover("ps").expect("discover should succeed").is_empty(),
            "local-only async deregister should clear local cache"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_local_only_service_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let rx = zk.watch("ps").expect("watch should succeed");
        drop(rx);

        <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0")
            .await
            .expect("async deregister should succeed for local-only service without registered backend path");
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "local-only async deregister should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_failure_compacts_dead_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let rx = zk.watch("ps").expect("watch should succeed");
        drop(rx);

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("async deregister should fail when ZooKeeper is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context, got {err:?}"
        );
        assert!(
            !zk_has_watcher(&zk, "ps"),
            "failed async deregister should compact dead watcher sender"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_failure_cleans_registered_path() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("async deregister should fail when ZooKeeper is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context, got {err:?}"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("ps-0"),
            "registered path entry should be removed even when backend delete fails"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_failure_keeps_live_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");
        zk.registered_paths
            .lock()
            .await
            .insert("ps-0".to_string(), "/services/ps/ps-0".to_string());

        let mut rx = zk.watch("ps").expect("watch should succeed");
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "ps-0").await;
        let err = result.expect_err("async deregister should fail when ZooKeeper is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context, got {err:?}"
        );
        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "ps-0"),
            "expected ServiceRemoved(ps-0), got {event:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "live watcher sender should be preserved after successful notification"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_missing_service_returns_not_found() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "missing").await;
        let err = result.expect_err("missing-service async deregister should return NotFound");
        assert!(
            matches!(err, DiscoveryError::NotFound(ref id) if id == "missing"),
            "expected NotFound(missing), got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_missing_service_cleans_stale_registered_path() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        zk.registered_paths
            .lock()
            .await
            .insert("missing".to_string(), "/services/ps/missing".to_string());

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "missing").await;
        let err = result.expect_err("missing-service async deregister should return NotFound");
        assert!(
            matches!(err, DiscoveryError::NotFound(ref id) if id == "missing"),
            "expected NotFound(missing), got {err:?}"
        );
        assert!(
            !zk.registered_paths.lock().await.contains_key("missing"),
            "NotFound path should still clear stale registered path entry"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_async_deregister_missing_service_preserves_watchers() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        let _rx = zk.watch("ps").expect("watch should succeed");
        assert!(
            zk_has_watcher(&zk, "ps"),
            "watch sender should exist after subscribing"
        );

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::deregister_async(&zk, "missing").await;
        let err = result.expect_err("missing-service async deregister should return NotFound");
        assert!(
            matches!(err, DiscoveryError::NotFound(ref id) if id == "missing"),
            "expected NotFound(missing), got {err:?}"
        );
        assert!(
            zk_has_watcher(&zk, "ps"),
            "missing-service async deregister should not mutate existing watch sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_consul_discovery_creation() {
        let consul = ConsulDiscovery::new("http://localhost:8500")
            .with_datacenter("dc1")
            .with_token("secret-token");
        assert_eq!(consul.address, "http://localhost:8500");
        assert_eq!(
            consul.datacenter.as_deref(),
            Some("dc1"),
            "with_datacenter should store configured datacenter"
        );
        assert_eq!(
            consul.token.as_deref(),
            Some("secret-token"),
            "with_token should store configured ACL token"
        );
        assert_eq!(
            consul.service_name, "monolith",
            "Consul discovery should default to monolith service name"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_consul_discovery_creation_with_service_name_override() {
        let consul = ConsulDiscovery::new("http://localhost:8500")
            .with_service_name("custom-monolith-service");
        assert_eq!(
            consul.service_name, "custom-monolith-service",
            "with_service_name should override default Consul service name"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_disconnect_increments_watch_generation() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        let before = consul
            .watch_generation
            .load(std::sync::atomic::Ordering::SeqCst);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        let after = consul
            .watch_generation
            .load(std::sync::atomic::Ordering::SeqCst);
        assert_eq!(after, before + 1);
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_disconnect_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");

        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact dead watcher senders"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_disconnect_preserves_live_watchers() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");

        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher senders"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_disconnect_compacts_only_dead_watchers() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        let dead_rx = consul.watch("worker").expect("watch should succeed");
        let _live_rx = consul.watch("ps").expect("watch should succeed");
        assert_eq!(
            consul_watcher_count(&consul),
            2,
            "test setup should seed two watcher senders"
        );
        drop(dead_rx);

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");

        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact dead watcher sender for dropped receiver"
        );
        assert!(
            consul_has_watcher(&consul, "ps"),
            "disconnect should preserve watcher sender with active receiver"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_disconnect_clears_watch_poll_generation_entries() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        assert!(consul.should_spawn_watch_poll("worker"));
        assert!(consul.should_spawn_watch_poll("ps"));
        assert_eq!(
            consul_watch_poll_count(&consul),
            2,
            "test setup should seed watch-poll generation entries"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");

        assert!(
            consul_watch_poll_is_empty(&consul),
            "disconnect should clear active watch-poll generation entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_disconnect_preserves_local_service_cache() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        assert_eq!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .len(),
            1,
            "test setup should seed one cached service"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");

        assert_eq!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .len(),
            1,
            "disconnect should preserve local cached services"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_disconnect_clears_client_handle_and_allows_reconnect() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("connect should initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("connect should reinitialize client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "connect should recreate client handle after disconnect reset"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_should_spawn_watch_poll_once_per_generation() {
        let consul = ConsulDiscovery::new("http://localhost:8500");

        assert!(
            consul.should_spawn_watch_poll("ps"),
            "first watch on service type should spawn poller"
        );
        assert!(
            !consul.should_spawn_watch_poll("ps"),
            "second watch on same service type and generation should not respawn poller"
        );
        consul_watch_poll_remove(&consul, "ps");
        assert!(
            consul.should_spawn_watch_poll("ps"),
            "poller should respawn once prior generation entry is cleaned"
        );
        assert!(
            consul.should_spawn_watch_poll("worker"),
            "different service type should spawn its own poller"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.should_spawn_watch_poll("ps"),
            "after disconnect generation bump should allow respawn"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_cleanup_watch_poll_generation_preserves_newer_generation_entry() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        assert!(consul.should_spawn_watch_poll("worker"));
        let old_generation = consul
            .watch_generation
            .load(std::sync::atomic::Ordering::SeqCst);

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(consul.should_spawn_watch_poll("worker"));
        let new_generation = consul
            .watch_generation
            .load(std::sync::atomic::Ordering::SeqCst);
        assert!(
            new_generation > old_generation,
            "disconnect should advance watch generation"
        );

        consul.cleanup_watch_poll_generation("worker", old_generation);
        assert_eq!(
            consul_watch_poll_get(&consul, "worker"),
            Some(new_generation),
            "cleanup for stale generation must not remove newer generation entry"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_sync_watch_receives_removed_event_on_deregister() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("register should succeed");

        let mut rx = consul.watch("worker").expect("watch should succeed");
        consul
            .deregister("worker-0")
            .expect("deregister should succeed and notify watchers");

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_deduplicates_poll_generation_entries() {
        let consul = ConsulDiscovery::new("http://localhost:8500");

        let rx1 = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("first watch_async should succeed");
        assert_eq!(consul_watch_poll_count(&consul), 1);

        let rx2 = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("second watch_async should succeed");
        assert_eq!(
            consul_watch_poll_count(&consul),
            1,
            "same service type should not create duplicate poll-generation entries"
        );

        let rx3 = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "ps")
            .await
            .expect("watch_async for second service type should succeed");
        assert_eq!(
            consul_watch_poll_count(&consul),
            2,
            "second service type should create a second poll-generation entry"
        );

        drop(rx1);
        drop(rx2);
        drop(rx3);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if consul_watch_poll_is_empty(&consul) {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("watch poll generation entries should clear after subscribers drop");
        assert!(
            consul_watchers_is_empty(&consul),
            "watch_async should compact dead watcher sender entries after all receivers drop"
        );
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_watch_poll_is_empty(&consul),
            "disconnect should preserve cleared watch poll generation state"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_seeds_poll_generation_entry() {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive http scheme without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for valid address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for valid address without root slash"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after watcher receiver without root slash drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "case-insensitive-scheme watch_async without root slash should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_disconnect_clears_poll_generation_with_live_receiver() {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive http scheme without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for valid address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for valid address without root slash"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_host_without_port_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive host-only authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized host-only address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized host-only address without root slash"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after host-only watcher receiver without root slash drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "host-only watch_async without root slash should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_host_without_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive host-only authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized host-only address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized host-only address without root slash"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_and_root_slash_host_without_port_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive host-only authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized host-only root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized host-only root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after host-only watcher receiver with root slash drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "host-only watch_async with root slash should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_and_root_slash_host_without_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive host-only authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized host-only root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized host-only root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_hostname_without_port_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive hostname-only authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname-only address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname-only address without root slash"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after hostname-only watcher receiver without root slash drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "hostname-only watch_async without root slash should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_hostname_without_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive hostname-only authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname-only address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname-only address without root slash"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_and_root_slash_hostname_without_port_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive hostname-only authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname-only root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname-only root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after hostname-only root-slash watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "hostname-only root-slash watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_and_root_slash_hostname_without_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive hostname-only authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname-only root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname-only root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_hostname_with_port_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive hostname authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname address without root slash"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after hostname watcher receiver without root slash drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "hostname watch_async without root slash should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_hostname_with_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive hostname authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname address without root slash"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_and_root_slash_hostname_with_port_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive hostname authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after hostname root-slash watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "hostname root-slash watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_and_root_slash_hostname_with_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive hostname authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_and_root_slash_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HTTP://127.0.0.1:8500/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive scheme and root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after case-insensitive root-slash watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "case-insensitive root-slash watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_and_root_slash_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HTTP://127.0.0.1:8500/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive scheme and root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_seeds_poll_generation_entry() {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https scheme without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https address without root slash"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after case-insensitive https watcher receiver without root slash drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "case-insensitive https watch_async without root slash should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https scheme without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https address without root slash"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_and_root_slash_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https scheme and root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after case-insensitive https root-slash watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "case-insensitive https root-slash watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_and_root_slash_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https scheme and root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_ipv6_seeds_poll_generation_entry() {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https IPv6 authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https IPv6 address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https IPv6 address without root slash"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after case-insensitive https IPv6 watcher receiver without root slash drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "case-insensitive https IPv6 watch_async without root slash should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_ipv6_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https IPv6 authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https IPv6 address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https IPv6 address without root slash"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_ipv6_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive IPv6 authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized IPv6 address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized IPv6 address without root slash"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_and_root_slash_ipv6_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https IPv6 authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https IPv6 root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https IPv6 root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after case-insensitive https IPv6 root-slash watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "case-insensitive https IPv6 root-slash watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_and_root_slash_ipv6_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https IPv6 authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https IPv6 root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https IPv6 root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_and_root_slash_hostname_with_port_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https hostname authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https hostname root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https hostname root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after case-insensitive https hostname root-slash watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "case-insensitive https hostname root-slash watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_and_root_slash_hostname_with_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https hostname authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https hostname root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https hostname root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_hostname_with_port_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https hostname authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https hostname address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https hostname address without root slash"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after case-insensitive https hostname watcher receiver without root slash drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "case-insensitive https hostname watch_async without root slash should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_hostname_with_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https hostname authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https hostname address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https hostname address without root slash"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_and_root_slash_hostname_without_port_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https hostname-only authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https hostname-only root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https hostname-only root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after case-insensitive https hostname-only root-slash watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "case-insensitive https hostname-only root-slash watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_and_root_slash_host_without_port_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https host-only authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https host-only root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https host-only root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after case-insensitive https host-only root-slash watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "case-insensitive https host-only root-slash watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_and_root_slash_host_without_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https host-only authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https host-only root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https host-only root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_and_root_slash_hostname_without_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https hostname-only authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https hostname-only root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https hostname-only root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_host_without_port_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https host-only authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https host-only address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https host-only address without root slash"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after case-insensitive https host-only watcher receiver without root slash drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "case-insensitive https host-only watch_async without root slash should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_host_without_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https host-only authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https host-only address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https host-only address without root slash"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_hostname_without_port_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https hostname-only authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https hostname-only address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https hostname-only address without root slash"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after case-insensitive https hostname-only watcher receiver without root slash drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "case-insensitive https hostname-only watch_async without root slash should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_https_scheme_hostname_without_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive https hostname-only authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized case-insensitive https hostname-only address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized case-insensitive https hostname-only address without root slash"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_and_root_slash_ipv6_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive IPv6 authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized IPv6 root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized IPv6 root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after IPv6 root-slash watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "case-insensitive IPv6 root-slash watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_and_root_slash_ipv6_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive IPv6 authority with root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized IPv6 root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized IPv6 root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_case_insensitive_scheme_ipv6_seeds_poll_generation_entry() {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept case-insensitive IPv6 authority without root slash");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized IPv6 address without root slash"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized IPv6 address without root slash"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after IPv6 watcher receiver without root slash drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "case-insensitive IPv6 watch_async without root slash should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_host_port_without_scheme_seeds_poll_generation_entry() {
        let consul = ConsulDiscovery::new("127.0.0.1:8501");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept host:port by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized host:port address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized host:port address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "normalized host:port watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_host_port_without_scheme_disconnect_clears_poll_generation_with_live_receiver() {
        let consul = ConsulDiscovery::new("127.0.0.1:8501");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept host:port by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized host:port address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized host:port address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_host_without_port_without_scheme_seeds_poll_generation_entry() {
        let consul = ConsulDiscovery::new("127.0.0.1");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept host-only by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized host-only address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized host-only address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after host-only watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "normalized host-only watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_host_without_port_without_scheme_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept host-only by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized host-only address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized host-only address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_host_without_port_without_scheme_and_root_slash_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept host-only root-slash by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized host-only root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized host-only root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after host-only root-slash watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "normalized host-only root-slash watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_host_without_port_without_scheme_and_root_slash_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept host-only root-slash by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized host-only root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized host-only root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_host_port_without_scheme_and_root_slash_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1:8501/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept host:port root-slash by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized host:port root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized host:port root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after host:port root-slash watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "normalized host:port root-slash watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_host_port_without_scheme_and_root_slash_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1:8501/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept host:port root-slash by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized host:port root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized host:port root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_hostname_port_without_scheme_seeds_poll_generation_entry() {
        let consul = ConsulDiscovery::new("localhost:8501");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept hostname:port by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname:port address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname:port address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after hostname:port watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "normalized hostname:port watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_hostname_port_without_scheme_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("localhost:8501");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept hostname:port by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname:port address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname:port address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_hostname_port_without_scheme_and_root_slash_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("localhost:8501/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept hostname:port root-slash by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname:port root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname:port root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after hostname:port root-slash watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "normalized hostname:port root-slash watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_hostname_port_without_scheme_and_root_slash_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("localhost:8501/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept hostname:port root-slash by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname:port root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname:port root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_hostname_without_port_seeds_poll_generation_entry() {
        let consul = ConsulDiscovery::new("localhost");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept hostname by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname-only address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname-only address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after hostname-only watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "normalized hostname-only watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_hostname_without_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("localhost");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept hostname by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname-only address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname-only address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_hostname_without_port_and_root_slash_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("localhost/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept hostname root-slash by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname-only root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname-only root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after hostname-only root-slash watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "normalized hostname-only root-slash watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_hostname_without_port_and_root_slash_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("localhost/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept hostname root-slash by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized hostname-only root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized hostname-only root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_ipv6_without_port_without_scheme_seeds_poll_generation_entry() {
        let consul = ConsulDiscovery::new("[::1]");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept IPv6 host-only address by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized IPv6 host-only address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized IPv6 host-only address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after IPv6 host-only watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "normalized IPv6 host-only watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_ipv6_without_port_without_scheme_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("[::1]");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept IPv6 host-only address by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized IPv6 host-only address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized IPv6 host-only address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_ipv6_without_port_without_scheme_and_root_slash_seeds_poll_generation_entry(
    ) {
        let consul = ConsulDiscovery::new("[::1]/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept IPv6 host-only root-slash by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized IPv6 host-only root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized IPv6 host-only root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after IPv6 host-only root-slash watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "normalized IPv6 host-only root-slash watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_ipv6_without_port_without_scheme_and_root_slash_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("[::1]/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept IPv6 host-only root-slash by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized IPv6 host-only root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized IPv6 host-only root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_https_scheme_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("https://127.0.0.1:8501");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept explicit https scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for https address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for https address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_https_scheme_seeds_poll_generation_entry() {
        let consul = ConsulDiscovery::new("https://127.0.0.1:8501");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept explicit https scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for https address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for https address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after https watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "https watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_https_hostname_with_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("https://localhost:8501");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept explicit https hostname authority");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for https hostname address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for https hostname address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_https_hostname_with_port_seeds_poll_generation_entry() {
        let consul = ConsulDiscovery::new("https://localhost:8501");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept explicit https hostname authority");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for https hostname address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for https hostname address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after https hostname watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "https hostname watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_https_hostname_without_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("https://localhost");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept explicit https hostname-only authority");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for https hostname-only address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for https hostname-only address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_https_hostname_without_port_seeds_poll_generation_entry() {
        let consul = ConsulDiscovery::new("https://localhost");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept explicit https hostname-only authority");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for https hostname-only address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for https hostname-only address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after https hostname-only watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "https hostname-only watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_https_ipv6_with_port_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("https://[::1]:8501");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept explicit https IPv6 authority");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for https IPv6 address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for https IPv6 address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_https_ipv6_with_port_seeds_poll_generation_entry() {
        let consul = ConsulDiscovery::new("https://[::1]:8501");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept explicit https IPv6 authority");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for https IPv6 address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for https IPv6 address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after https IPv6 watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "https IPv6 watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_ipv6_with_port_seeds_poll_generation_entry() {
        let consul = ConsulDiscovery::new("[::1]:8501");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept bracketed IPv6 host:port by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized IPv6 host:port address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized IPv6 host:port address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after IPv6 watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "normalized IPv6 host:port watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_ipv6_with_port_disconnect_clears_poll_generation_with_live_receiver() {
        let consul = ConsulDiscovery::new("[::1]:8501");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept bracketed IPv6 host:port by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized IPv6 host:port address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized IPv6 host:port address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_ipv6_with_port_and_root_slash_seeds_poll_generation_entry() {
        let consul = ConsulDiscovery::new("[::1]:8501/");

        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept bracketed IPv6 host:port root-slash by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized IPv6 host:port root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized IPv6 host:port root-slash address"
        );

        drop(rx);
        tokio::time::timeout(std::time::Duration::from_secs(3), async {
            loop {
                if !consul_has_watch_poll_generation(&consul, "worker") {
                    break;
                }
                tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            }
        })
        .await
        .expect("poll-generation entry should clear after IPv6 root-slash watcher receiver drops");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "normalized IPv6 host:port root-slash watch_async should compact dead watcher sender after receiver drops"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_ipv6_with_port_and_root_slash_disconnect_clears_poll_generation_with_live_receiver(
    ) {
        let consul = ConsulDiscovery::new("[::1]:8501/");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("watch_async should accept bracketed IPv6 host:port root-slash by normalizing http scheme");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch_async should create watcher sender entry for normalized IPv6 host:port root-slash address"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping for normalized IPv6 host:port root-slash address"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_config_error_cleans_poll_generation_entry() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500/v1");

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("invalid watch address should be rejected before poll loop spawn");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("path is not allowed")),
            "expected ConfigError containing watch_service address-path context, got {err:?}"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "invalid watch_service config should not seed poll-generation bookkeeping entries"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "invalid watch_service config should not create watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_invalid_scheme_rejects_without_state_changes() {
        let consul = ConsulDiscovery::new("ftp://127.0.0.1:8500");

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("invalid scheme should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("invalid scheme")),
            "expected ConfigError containing watch_service invalid-scheme context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "invalid-scheme watch_async should not create watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "invalid-scheme watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_invalid_scheme_compacts_dead_watch_sender() {
        let consul = ConsulDiscovery::new("ftp://127.0.0.1:8500");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("invalid-scheme authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("invalid scheme")),
            "expected ConfigError containing watch_service invalid-scheme context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "invalid-scheme watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_invalid_scheme_preserves_live_watch_sender() {
        let consul = ConsulDiscovery::new("ftp://127.0.0.1:8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("invalid-scheme authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("invalid scheme")),
            "expected ConfigError containing watch_service invalid-scheme context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "invalid-scheme watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_invalid_port_rejects_without_state_changes() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:notaport");

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("invalid-port authority should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("invalid port")),
            "expected ConfigError containing watch_service invalid-port context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "invalid-port watch_async should not create watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "invalid-port watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_invalid_port_compacts_dead_watch_sender() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:notaport");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("invalid-port authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("invalid port")),
            "expected ConfigError containing watch_service invalid-port context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "invalid-port watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_invalid_port_preserves_live_watch_sender() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:notaport");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("invalid-port authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("invalid port")),
            "expected ConfigError containing watch_service invalid-port context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "invalid-port watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_out_of_range_port_rejects_without_state_changes() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:70000");

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("out-of-range port should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("invalid port")),
            "expected ConfigError containing watch_service out-of-range-port context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "out-of-range-port watch_async should not create watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "out-of-range-port watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_out_of_range_port_compacts_dead_watch_sender() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:70000");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("out-of-range authority port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("invalid port")),
            "expected ConfigError containing watch_service out-of-range-port context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "out-of-range-port watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_out_of_range_port_preserves_live_watch_sender() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:70000");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("out-of-range authority port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("invalid port")),
            "expected ConfigError containing watch_service out-of-range-port context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "out-of-range-port watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_invalid_ipv6_suffix_rejects_without_state_changes() {
        let consul = ConsulDiscovery::new("http://[::1]x:8500");

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("invalid IPv6 suffix should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("invalid authority")),
            "expected ConfigError containing watch_service invalid-IPv6-suffix context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "invalid-IPv6-suffix watch_async should not create watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "invalid-IPv6-suffix watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_invalid_ipv6_suffix_compacts_dead_watch_sender() {
        let consul = ConsulDiscovery::new("http://[::1]x:8500");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("invalid IPv6 suffix authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("invalid authority")),
            "expected ConfigError containing watch_service invalid-IPv6-suffix context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "invalid-IPv6-suffix watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_invalid_ipv6_suffix_preserves_live_watch_sender() {
        let consul = ConsulDiscovery::new("http://[::1]x:8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("invalid IPv6 suffix authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("invalid authority")),
            "expected ConfigError containing watch_service invalid-IPv6-suffix context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "invalid-IPv6-suffix watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_userinfo_authority_rejects_without_state_changes() {
        let consul = ConsulDiscovery::new("http://user@127.0.0.1:8500");

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("userinfo authority should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("userinfo in authority")),
            "expected ConfigError containing watch_service userinfo-authority context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "userinfo-authority watch_async should not create watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "userinfo-authority watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_userinfo_authority_compacts_dead_watch_sender() {
        let consul = ConsulDiscovery::new("http://user@127.0.0.1:8500");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("userinfo authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("userinfo in authority")),
            "expected ConfigError containing watch_service userinfo-authority context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "userinfo-authority watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_userinfo_authority_preserves_live_watch_sender() {
        let consul = ConsulDiscovery::new("http://user@127.0.0.1:8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("userinfo authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("userinfo in authority")),
            "expected ConfigError containing watch_service userinfo-authority context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "userinfo-authority watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_query_rejects_without_state_changes() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500?dc=prod");

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("query suffix should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("query is not allowed")),
            "expected ConfigError containing watch_service query-suffix context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "query-suffix watch_async should not create watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "query-suffix watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_query_compacts_dead_watch_sender() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500?dc=prod");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("query suffix should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("query is not allowed")),
            "expected ConfigError containing watch_service query-suffix context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "query-suffix watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_query_preserves_live_watch_sender() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500?dc=prod");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("query suffix should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("query is not allowed")),
            "expected ConfigError containing watch_service query-suffix context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "query-suffix watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_path_rejects_without_state_changes() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500/v1");

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("path suffix should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("path is not allowed")),
            "expected ConfigError containing watch_service path-suffix context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "path-suffix watch_async should not create watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "path-suffix watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_path_compacts_dead_watch_sender() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500/v1");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("path suffix should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("path is not allowed")),
            "expected ConfigError containing watch_service path-suffix context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "path-suffix watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_path_preserves_live_watch_sender() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500/v1");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("path suffix should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("path is not allowed")),
            "expected ConfigError containing watch_service path-suffix context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "path-suffix watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_fragment_rejects_without_state_changes() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500#consul");

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("fragment suffix should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("fragment is not allowed")),
            "expected ConfigError containing watch_service fragment-suffix context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "fragment-suffix watch_async should not create watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "fragment-suffix watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_fragment_compacts_dead_watch_sender() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500#consul");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("fragment suffix should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("fragment is not allowed")),
            "expected ConfigError containing watch_service fragment-suffix context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "fragment-suffix watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_fragment_preserves_live_watch_sender() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500#consul");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("fragment suffix should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("fragment is not allowed")),
            "expected ConfigError containing watch_service fragment-suffix context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "fragment-suffix watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_leading_trailing_whitespace_rejects_without_state_changes() {
        let consul = ConsulDiscovery::new(" http://127.0.0.1:8500 ");

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("leading/trailing whitespace should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("leading/trailing whitespace")),
            "expected ConfigError containing watch_service whitespace context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "whitespace-padded watch_async should not create watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "whitespace-padded watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_leading_trailing_whitespace_compacts_dead_watch_sender() {
        let consul = ConsulDiscovery::new(" http://127.0.0.1:8500 ");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("leading/trailing whitespace should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("leading/trailing whitespace")),
            "expected ConfigError containing watch_service leading/trailing-whitespace context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "whitespace-padded watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_leading_trailing_whitespace_preserves_live_watch_sender() {
        let consul = ConsulDiscovery::new(" http://127.0.0.1:8500 ");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("leading/trailing whitespace should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("leading/trailing whitespace")),
            "expected ConfigError containing watch_service leading/trailing-whitespace context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "whitespace-padded watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_whitespace_authority_rejects_without_state_changes() {
        let consul = ConsulDiscovery::new("http://127.0.0.1 :8500");

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("whitespace authority should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("whitespace in authority")),
            "expected ConfigError containing watch_service whitespace-authority context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "whitespace-authority watch_async should not create watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "whitespace-authority watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_whitespace_authority_compacts_dead_watch_sender() {
        let consul = ConsulDiscovery::new("http://127.0.0.1 :8500");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("whitespace authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("whitespace in authority")),
            "expected ConfigError containing watch_service whitespace-authority context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "whitespace-authority watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_whitespace_authority_preserves_live_watch_sender() {
        let consul = ConsulDiscovery::new("http://127.0.0.1 :8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("whitespace authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("whitespace in authority")),
            "expected ConfigError containing watch_service whitespace-authority context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "whitespace-authority watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_empty_host_rejects_without_state_changes() {
        let consul = ConsulDiscovery::new("http://:8500");

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("empty host should be rejected before watch state is created");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("empty host")),
            "expected ConfigError containing watch_service empty-host context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "empty-host watch_async should not create watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "empty-host watch_async should not seed poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_empty_host_compacts_dead_watch_sender() {
        let consul = ConsulDiscovery::new("http://:8500");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("empty host should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("empty host")),
            "expected ConfigError containing watch_service empty-host context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "empty-host watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_empty_host_preserves_live_watch_sender() {
        let consul = ConsulDiscovery::new("http://:8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("empty host should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("empty host")),
            "expected ConfigError containing watch_service empty-host context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "empty-host watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_empty_address_creates_state_and_disconnect_cleans_up() {
        let consul = ConsulDiscovery::new("");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("empty address should be accepted for watch_async via default endpoint");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "empty-address watch_async should create watcher sender entries"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "empty-address watch_async should seed poll-generation bookkeeping"
        );
        drop(rx);

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact empty-address watch sender entries after receiver drop"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear empty-address watch poll-generation bookkeeping"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_empty_address_disconnect_clears_poll_generation_with_live_receiver() {
        let consul = ConsulDiscovery::new("");
        let rx = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect("empty address should be accepted for watch_async via default endpoint");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        assert!(
            consul_has_watch_poll_generation(&consul, "worker"),
            "watch_async should seed poll-generation bookkeeping before disconnect"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "disconnect should preserve live watcher sender entries"
        );
        assert!(
            !consul_has_watch_poll_generation(&consul, "worker"),
            "disconnect should clear poll-generation bookkeeping even when receiver is live"
        );

        drop(rx);
        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "disconnect should compact watcher sender after receiver is dropped"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_config_error_compacts_dead_watch_sender() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500/v1");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("invalid watch address should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("path is not allowed")),
            "expected ConfigError containing watch_service address-path context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "config-error watch_async should compact dead watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_watch_async_config_error_preserves_live_watch_sender() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500/v1");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let err = <ConsulDiscovery as ServiceDiscoveryAsync>::watch_async(&consul, "worker")
            .await
            .expect_err("invalid watch address should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("watch_service")
                    && msg.contains("invalid address")
                    && msg.contains("path is not allowed")),
            "expected ConfigError containing watch_service address-path context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "config-error watch_async should preserve live watcher sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_consul_sync_register_removes_dead_watchers() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        drop(rx);
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("register should succeed");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be removed after notification"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_consul_sync_deregister_removes_dead_watchers() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("register should succeed");

        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        consul
            .deregister("worker-0")
            .expect("deregister should succeed and trigger cleanup");
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be removed after deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[test]
    fn test_consul_sync_deregister_missing_service_preserves_watchers() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = consul.deregister("missing");
        let err = result.expect_err("sync missing-service deregister should return NotFound");
        assert!(
            matches!(err, DiscoveryError::NotFound(ref id) if id == "missing"),
            "expected NotFound(missing), got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "sync missing-service deregister should not mutate active watch sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_watch_receives_removed_event_on_deregister() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("register should succeed");

        let mut rx = consul.watch("worker").expect("watch should succeed");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("async deregister should return internal backend failure");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing deregister_entity context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_removes_dead_watchers() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("register should succeed");

        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("async deregister should return internal backend failure");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing deregister_entity context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be removed after async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_failure_returns_error_and_cleans_cache() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("async deregister should return internal backend failure");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing deregister_entity context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "async deregister should remove service from local cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_host_port_without_scheme_uses_operation_context() {
        let consul = ConsulDiscovery::new("127.0.0.1:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("host:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized host:port deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized host:port async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized host:port async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_host_port_without_scheme_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("127.0.0.1:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("host:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized host:port deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized host:port async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_host_without_port_without_scheme_uses_operation_context() {
        let consul = ConsulDiscovery::new("127.0.0.1");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("host-only address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized host-only deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized host-only async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized host-only async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_host_without_port_without_scheme_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("127.0.0.1");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("host-only address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized host-only deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized host-only async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_host_without_port_without_scheme_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("host-only root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized host-only root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized host-only root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized host-only root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_host_without_port_without_scheme_and_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("host-only root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized host-only root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized host-only root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_host_port_without_scheme_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("host:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized host:port root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized host:port root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized host:port root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_host_port_without_scheme_and_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("host:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized host:port root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized host:port root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_hostname_port_without_scheme_uses_operation_context() {
        let consul = ConsulDiscovery::new("localhost:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("hostname:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized hostname:port deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname:port async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname:port async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_hostname_port_without_scheme_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("localhost:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("hostname:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized hostname:port deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname:port async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_hostname_port_without_scheme_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("localhost:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result
            .expect_err("hostname:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized hostname:port root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname:port root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname:port root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_hostname_port_without_scheme_and_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("localhost:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result
            .expect_err("hostname:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized hostname:port root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname:port root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_hostname_without_port_uses_operation_context() {
        let consul = ConsulDiscovery::new("localhost");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("hostname address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized hostname deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_hostname_without_port_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("localhost");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("hostname address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized hostname deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_hostname_without_port_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("localhost/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("hostname root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized hostname root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_hostname_without_port_and_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("localhost/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("hostname root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized hostname root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_ipv6_without_port_without_scheme_uses_operation_context() {
        let consul = ConsulDiscovery::new("[::1]");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("IPv6 host-only address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized IPv6 host-only deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized IPv6 host-only async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized IPv6 host-only async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_ipv6_without_port_without_scheme_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("[::1]");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("IPv6 host-only address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized IPv6 host-only deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized IPv6 host-only async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_ipv6_without_port_without_scheme_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("[::1]/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("IPv6 host-only root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized IPv6 host-only root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized IPv6 host-only root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized IPv6 host-only root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_ipv6_without_port_without_scheme_and_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("[::1]/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("IPv6 host-only root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized IPv6 host-only root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized IPv6 host-only root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_https_hostname_with_port_uses_operation_context() {
        let consul = ConsulDiscovery::new("https://localhost:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("https hostname address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing https hostname deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "https hostname async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on https hostname async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_https_hostname_with_port_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("https://localhost:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("https hostname address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing https hostname deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on https hostname async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_https_hostname_without_port_uses_operation_context() {
        let consul = ConsulDiscovery::new("https://localhost");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("https hostname-only address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing https hostname-only deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "https hostname-only async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on https hostname-only async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_https_hostname_without_port_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("https://localhost");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("https hostname-only address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing https hostname-only deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on https hostname-only async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_https_scheme_uses_operation_context() {
        let consul = ConsulDiscovery::new("https://127.0.0.1:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("https address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing https deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "https async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on https async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_https_scheme_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("https://127.0.0.1:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("https address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing https deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on https async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_https_ipv6_with_port_uses_operation_context() {
        let consul = ConsulDiscovery::new("https://[::1]:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("https IPv6 address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing https IPv6 deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "https IPv6 async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on https IPv6 async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_https_ipv6_with_port_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("https://[::1]:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("https IPv6 address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing https IPv6 deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on https IPv6 async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_ipv6_with_port_uses_operation_context() {
        let consul = ConsulDiscovery::new("[::1]:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err =
            result.expect_err("IPv6 host:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 host:port deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized IPv6 host:port async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized IPv6 host:port async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_ipv6_with_port_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("[::1]:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err =
            result.expect_err("IPv6 host:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 host:port deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized IPv6 host:port async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_ipv6_with_port_and_root_slash_uses_operation_context() {
        let consul = ConsulDiscovery::new("[::1]:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err =
            result.expect_err("IPv6 host:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 host:port root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized IPv6 host:port root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized IPv6 host:port root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_ipv6_with_port_and_root_slash_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("[::1]:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err =
            result.expect_err("IPv6 host:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 host:port root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized IPv6 host:port root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_empty_address_uses_default_endpoint_context() {
        let consul = ConsulDiscovery::new("");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("empty-address async deregister should fail against default endpoint");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8500")),
            "expected Internal containing default-endpoint deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "empty-address async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on empty-address async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_and_root_slash_uses_operation_context() {
        let consul = ConsulDiscovery::new("HTTP://127.0.0.1:8500/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("case-insensitive scheme + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8500")),
            "expected Internal containing normalized-root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized-root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized-root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_and_root_slash_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("HTTP://127.0.0.1:8500/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("case-insensitive scheme + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8500")),
            "expected Internal containing normalized-root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized-root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_and_root_slash_ipv6_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive IPv6 authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized IPv6 root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized IPv6 root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_and_root_slash_ipv6_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive IPv6 authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized IPv6 root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_no_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive scheme without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8500")),
            "expected Internal containing normalized no-root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized no-root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized no-root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_no_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive scheme without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8500")),
            "expected Internal containing normalized no-root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized no-root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_host_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive host-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized host-only no-root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized host-only no-root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized host-only no-root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_host_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive host-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized host-only no-root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized host-only no-root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_and_root_slash_host_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive host-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized host-only root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized host-only root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized host-only root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_and_root_slash_host_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive host-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized host-only root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized host-only root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_ipv6_no_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive IPv6 authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 no-root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized IPv6 no-root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized IPv6 no-root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_ipv6_no_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive IPv6 authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 no-root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized IPv6 no-root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_hostname_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive hostname-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized hostname-only no-root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname-only no-root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname-only no-root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_hostname_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive hostname-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized hostname-only no-root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname-only no-root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_and_root_slash_hostname_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive hostname-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized hostname-only root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname-only root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname-only root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_and_root_slash_hostname_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive hostname-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized hostname-only root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname-only root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_hostname_with_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive hostname authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8500")),
            "expected Internal containing normalized hostname no-root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname no-root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname no-root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_hostname_with_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive hostname authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8500")),
            "expected Internal containing normalized hostname no-root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname no-root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_and_root_slash_hostname_with_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive hostname authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8500")),
            "expected Internal containing normalized hostname root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_scheme_and_root_slash_hostname_with_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive hostname authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8500")),
            "expected Internal containing normalized hostname root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https scheme + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_and_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https scheme + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_and_root_slash_ipv6_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https IPv6 authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https IPv6 root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https IPv6 root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https IPv6 root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_and_root_slash_ipv6_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https IPv6 authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https IPv6 root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https IPv6 root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_no_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https scheme without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https no-root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https no-root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https no-root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_no_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https scheme without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https no-root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https no-root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_ipv6_no_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https IPv6 authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https IPv6 no-root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https IPv6 no-root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https IPv6 no-root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_ipv6_no_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https IPv6 authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https IPv6 no-root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https IPv6 no-root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_and_root_slash_hostname_with_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https hostname root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https hostname root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https hostname root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_and_root_slash_hostname_with_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https hostname root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https hostname root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_hostname_with_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https hostname deregister context without root slash, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https hostname async deregister without root slash should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https hostname async deregister failure without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_hostname_with_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https hostname deregister context without root slash, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https hostname async deregister notification without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_and_root_slash_hostname_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized case-insensitive https hostname-only root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https hostname-only root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https hostname-only root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_and_root_slash_host_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https host-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized case-insensitive https host-only root-slash deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https host-only root-slash async deregister should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https host-only root-slash async deregister failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_and_root_slash_host_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https host-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized case-insensitive https host-only root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https host-only root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_and_root_slash_hostname_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost/");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized case-insensitive https hostname-only root-slash deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https hostname-only root-slash async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_host_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https host-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized case-insensitive https host-only deregister context without root slash, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https host-only async deregister without root slash should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https host-only async deregister failure without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_host_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https host-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized case-insensitive https host-only deregister context without root slash, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https host-only async deregister notification without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_hostname_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized case-insensitive https hostname-only deregister context without root slash, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https hostname-only async deregister without root slash should remove service from local cache"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https hostname-only async deregister failure without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_case_insensitive_https_scheme_hostname_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("deregister_entity")),
            "expected Internal containing normalized case-insensitive https hostname-only deregister context without root slash, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https hostname-only async deregister notification without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_empty_address_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("empty-address async deregister should fail against default endpoint");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("deregister_entity") && msg.contains("8500")),
            "expected Internal containing default-endpoint deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on empty-address async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_missing_service_returns_not_found() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "missing").await;
        let err = result.expect_err("missing-service async deregister should return NotFound");
        assert!(
            matches!(err, DiscoveryError::NotFound(ref id) if id == "missing"),
            "expected NotFound(missing), got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_missing_service_preserves_watchers() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "missing").await;
        let err = result.expect_err("missing-service async deregister should return NotFound");
        assert!(
            matches!(err, DiscoveryError::NotFound(ref id) if id == "missing"),
            "expected NotFound(missing), got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "missing-service async deregister should not mutate existing watch sender entries"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_config_error_still_notifies_and_returns_error() {
        let consul = ConsulDiscovery::new("http://[::1");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");

        let mut rx = consul.watch("worker").expect("watch should succeed");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("invalid Consul address should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address") && msg.contains("deregister_entity")),
            "expected ConfigError containing invalid-address deregister context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "async deregister should remove service from local cache even on config failure"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == "worker-0"),
            "expected ServiceRemoved(worker-0), got {event:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved after successful notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_config_error_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://[::1");
        consul
            .register(ServiceInfo::new(
                "worker-0",
                "worker-0",
                "worker",
                "127.0.0.1",
                6000,
            ))
            .expect("sync register should seed local cache");

        let rx = consul.watch("worker").expect("watch should succeed");
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, "worker-0")
            .await;
        let err = result.expect_err("invalid Consul address should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address") && msg.contains("deregister_entity")),
            "expected ConfigError containing invalid-address deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dropped watcher sender should be compacted on async deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_failure_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("async register should return internal backend failure");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing register_entity context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "failed async register should compact dead watcher sender"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_failure_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("async register should return internal backend failure");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing register_entity context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_failure_does_not_cache_service() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(&consul, service)
            .await;
        let err = result.expect_err("async register should return internal backend failure");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing register_entity context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "failed async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_host_port_without_scheme_uses_operation_context() {
        let consul = ConsulDiscovery::new("127.0.0.1:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("host:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized host:port register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized host:port async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_host_port_without_scheme_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("127.0.0.1:8501");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("host:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized host:port register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized host:port async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_host_port_without_scheme_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("127.0.0.1:8501");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("host:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized host:port register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized host:port async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_host_without_port_without_scheme_uses_operation_context() {
        let consul = ConsulDiscovery::new("127.0.0.1");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("host-only address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized host-only register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized host-only async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_host_without_port_without_scheme_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("127.0.0.1");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("host-only address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized host-only register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized host-only async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_host_without_port_without_scheme_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("127.0.0.1");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("host-only address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized host-only register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized host-only async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_host_without_port_without_scheme_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("host-only root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized host-only root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized host-only root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_host_without_port_without_scheme_and_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("host-only root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized host-only root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized host-only root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_host_without_port_without_scheme_and_root_slash_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("host-only root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized host-only root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized host-only root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_host_port_without_scheme_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1:8501/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("host:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized host:port root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized host:port root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_host_port_without_scheme_and_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1:8501/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("host:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized host:port root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized host:port root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_host_port_without_scheme_and_root_slash_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1:8501/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("host:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized host:port root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized host:port root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_hostname_port_without_scheme_uses_operation_context() {
        let consul = ConsulDiscovery::new("localhost:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("hostname:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized hostname:port register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname:port async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_hostname_port_without_scheme_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("localhost:8501");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("hostname:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized hostname:port register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname:port async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_hostname_port_without_scheme_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("localhost:8501");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("hostname:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized hostname:port register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname:port async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_hostname_port_without_scheme_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("localhost:8501/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("hostname:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized hostname:port root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname:port root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_hostname_port_without_scheme_and_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("localhost:8501/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("hostname:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized hostname:port root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname:port root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_hostname_port_without_scheme_and_root_slash_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("localhost:8501/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("hostname:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized hostname:port root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname:port root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_hostname_without_port_uses_operation_context() {
        let consul = ConsulDiscovery::new("localhost");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("hostname address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized hostname register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_hostname_without_port_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("localhost");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("hostname address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized hostname register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_hostname_without_port_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("localhost");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("hostname address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized hostname register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_hostname_without_port_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("localhost/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("hostname root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized hostname root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_hostname_without_port_and_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("localhost/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("hostname root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized hostname root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_hostname_without_port_and_root_slash_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("localhost/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("hostname root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized hostname root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_ipv6_without_port_without_scheme_uses_operation_context() {
        let consul = ConsulDiscovery::new("[::1]");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("IPv6 host-only address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized IPv6 host-only register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized IPv6 host-only async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_ipv6_without_port_without_scheme_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("[::1]");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("IPv6 host-only address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized IPv6 host-only register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized IPv6 host-only async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_ipv6_without_port_without_scheme_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("[::1]");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("IPv6 host-only address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized IPv6 host-only register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized IPv6 host-only async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_ipv6_without_port_without_scheme_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("[::1]/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("IPv6 host-only root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized IPv6 host-only root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized IPv6 host-only root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_ipv6_without_port_without_scheme_and_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("[::1]/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("IPv6 host-only root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized IPv6 host-only root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized IPv6 host-only root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_ipv6_without_port_without_scheme_and_root_slash_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("[::1]/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("IPv6 host-only root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized IPv6 host-only root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized IPv6 host-only root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_https_hostname_with_port_uses_operation_context() {
        let consul = ConsulDiscovery::new("https://localhost:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("https hostname address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing https hostname register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "https hostname async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_https_hostname_with_port_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("https://localhost:8501");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("https hostname address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing https hostname register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on https hostname async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_https_hostname_with_port_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("https://localhost:8501");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("https hostname address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing https hostname register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on https hostname async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_https_hostname_without_port_uses_operation_context() {
        let consul = ConsulDiscovery::new("https://localhost");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("https hostname-only address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing https hostname-only register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "https hostname-only async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_https_hostname_without_port_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("https://localhost");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("https hostname-only address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing https hostname-only register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on https hostname-only async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_https_hostname_without_port_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("https://localhost");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("https hostname-only address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing https hostname-only register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on https hostname-only async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_https_scheme_uses_operation_context() {
        let consul = ConsulDiscovery::new("https://127.0.0.1:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("https address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing https register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "https async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_https_scheme_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("https://127.0.0.1:8501");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("https address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing https register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on https async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_https_scheme_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("https://127.0.0.1:8501");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("https address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing https register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on https async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_https_ipv6_with_port_uses_operation_context() {
        let consul = ConsulDiscovery::new("https://[::1]:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("https IPv6 address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing https IPv6 register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "https IPv6 async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_https_ipv6_with_port_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("https://[::1]:8501");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("https IPv6 address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing https IPv6 register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on https IPv6 async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_https_ipv6_with_port_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("https://[::1]:8501");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("https IPv6 address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing https IPv6 register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on https IPv6 async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_ipv6_with_port_uses_operation_context() {
        let consul = ConsulDiscovery::new("[::1]:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err =
            result.expect_err("IPv6 host:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 host:port register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized IPv6 host:port async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_ipv6_with_port_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("[::1]:8501");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err =
            result.expect_err("IPv6 host:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 host:port register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized IPv6 host:port async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_ipv6_with_port_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("[::1]:8501");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err =
            result.expect_err("IPv6 host:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 host:port register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized IPv6 host:port async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_ipv6_with_port_and_root_slash_uses_operation_context() {
        let consul = ConsulDiscovery::new("[::1]:8501/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err =
            result.expect_err("IPv6 host:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 host:port root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized IPv6 host:port root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_ipv6_with_port_and_root_slash_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("[::1]:8501/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err =
            result.expect_err("IPv6 host:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 host:port root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized IPv6 host:port root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_ipv6_with_port_and_root_slash_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("[::1]:8501/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err =
            result.expect_err("IPv6 host:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 host:port root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized IPv6 host:port root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_empty_address_uses_default_endpoint_context() {
        let consul = ConsulDiscovery::new("");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("empty-address async register should fail against default endpoint");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8500")),
            "expected Internal containing default-endpoint register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "empty-address async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result
            .expect_err("case-insensitive https scheme + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_and_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result
            .expect_err("case-insensitive https scheme + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_and_root_slash_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result
            .expect_err("case-insensitive https scheme + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_and_root_slash_ipv6_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https IPv6 authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https IPv6 root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https IPv6 root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_and_root_slash_ipv6_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https IPv6 authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https IPv6 root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https IPv6 root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_and_root_slash_ipv6_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https IPv6 authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https IPv6 root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https IPv6 root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_no_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https scheme without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https register context without root slash, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https async register without root slash should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_no_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https scheme without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https register context without root slash, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https async register failure without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_no_root_slash_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https scheme without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https register context without root slash, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https async register failure without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_ipv6_no_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https IPv6 authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https IPv6 register context without root slash, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https IPv6 async register without root slash should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_ipv6_no_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https IPv6 authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https IPv6 register context without root slash, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https IPv6 async register failure without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_ipv6_no_root_slash_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https IPv6 authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https IPv6 register context without root slash, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https IPv6 async register failure without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_and_root_slash_hostname_with_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https hostname authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https hostname root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https hostname root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_and_root_slash_hostname_with_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https hostname authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https hostname root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https hostname root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_and_root_slash_hostname_with_port_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https hostname authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https hostname root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https hostname root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_hostname_with_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https hostname authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https hostname register context without root slash, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https hostname async register without root slash should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_hostname_with_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https hostname authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https hostname register context without root slash, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https hostname async register failure without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_hostname_with_port_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https hostname authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https hostname register context without root slash, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https hostname async register failure without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_and_root_slash_hostname_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https hostname-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized case-insensitive https hostname-only root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https hostname-only root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_and_root_slash_host_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https host-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized case-insensitive https host-only root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https host-only root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_and_root_slash_host_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https host-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized case-insensitive https host-only root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https host-only root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_and_root_slash_host_without_port_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https host-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized case-insensitive https host-only root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https host-only root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_and_root_slash_hostname_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https hostname-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized case-insensitive https hostname-only root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https hostname-only root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_and_root_slash_hostname_without_port_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https hostname-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized case-insensitive https hostname-only root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https hostname-only root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_host_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https host-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized case-insensitive https host-only register context without root slash, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https host-only async register without root slash should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_host_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https host-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized case-insensitive https host-only register context without root slash, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https host-only async register failure without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_host_without_port_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https host-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized case-insensitive https host-only register context without root slash, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https host-only async register failure without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_hostname_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https hostname-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized case-insensitive https hostname-only register context without root slash, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized case-insensitive https hostname-only async register without root slash should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_hostname_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https hostname-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized case-insensitive https hostname-only register context without root slash, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized case-insensitive https hostname-only async register failure without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_https_scheme_hostname_without_port_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive https hostname-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized case-insensitive https hostname-only register context without root slash, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized case-insensitive https hostname-only async register failure without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_no_root_slash_uses_operation_context() {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1:8500");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result
            .expect_err("case-insensitive scheme without root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8500")),
            "expected Internal containing normalized no-root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized no-root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_no_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1:8500");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result
            .expect_err("case-insensitive scheme without root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8500")),
            "expected Internal containing normalized no-root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized no-root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_no_root_slash_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1:8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result
            .expect_err("case-insensitive scheme without root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8500")),
            "expected Internal containing normalized no-root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized no-root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_host_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive host-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized host-only no-root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized host-only no-root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_host_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive host-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized host-only no-root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized host-only no-root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_host_without_port_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive host-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized host-only no-root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized host-only no-root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_and_root_slash_host_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive host-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized host-only root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized host-only root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_and_root_slash_host_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive host-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized host-only root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized host-only root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_and_root_slash_host_without_port_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive host-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized host-only root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized host-only root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_ipv6_no_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive IPv6 authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 no-root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized IPv6 no-root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_ipv6_no_root_slash_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive IPv6 authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 no-root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized IPv6 no-root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_ipv6_no_root_slash_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive IPv6 authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 no-root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized IPv6 no-root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_hostname_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive hostname-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized hostname-only no-root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname-only no-root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_hostname_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive hostname-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized hostname-only no-root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname-only no-root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_hostname_without_port_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive hostname-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized hostname-only no-root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname-only no-root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_and_root_slash_hostname_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive hostname-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized hostname-only root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname-only root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_and_root_slash_hostname_without_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive hostname-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized hostname-only root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname-only root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_and_root_slash_hostname_without_port_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive hostname-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("register_entity")),
            "expected Internal containing normalized hostname-only root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname-only root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_hostname_with_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive hostname authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8500")),
            "expected Internal containing normalized hostname no-root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname no-root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_hostname_with_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive hostname authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8500")),
            "expected Internal containing normalized hostname no-root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname no-root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_hostname_with_port_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive hostname authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8500")),
            "expected Internal containing normalized hostname no-root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname no-root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_and_root_slash_hostname_with_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result
            .expect_err("case-insensitive hostname authority + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8500")),
            "expected Internal containing normalized hostname root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized hostname root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_and_root_slash_hostname_with_port_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result
            .expect_err("case-insensitive hostname authority + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8500")),
            "expected Internal containing normalized hostname root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized hostname root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_and_root_slash_hostname_with_port_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result
            .expect_err("case-insensitive hostname authority + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8500")),
            "expected Internal containing normalized hostname root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized hostname root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_and_root_slash_uses_operation_context() {
        let consul = ConsulDiscovery::new("HTTP://127.0.0.1:8500/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("case-insensitive scheme + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8500")),
            "expected Internal containing normalized-root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized-root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_and_root_slash_ipv6_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive IPv6 authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 root-slash register context, got {err:?}"
        );
        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "normalized IPv6 root-slash async register should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_and_root_slash_ipv6_compacts_dead_watchers(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive IPv6 authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized IPv6 root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_and_root_slash_ipv6_keeps_live_watchers(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err(
            "case-insensitive IPv6 authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized IPv6 root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_and_root_slash_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("HTTP://127.0.0.1:8500/");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("case-insensitive scheme + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8500")),
            "expected Internal containing normalized-root-slash register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on normalized-root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_case_insensitive_scheme_and_root_slash_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("HTTP://127.0.0.1:8500/");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("case-insensitive scheme + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8500")),
            "expected Internal containing normalized-root-slash register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on normalized-root-slash async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_empty_address_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("empty-address async register should fail against default endpoint");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8500")),
            "expected Internal containing default-endpoint register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watcher sender should be compacted on empty-address async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_empty_address_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("empty-address async register should fail against default endpoint");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("register_entity") && msg.contains("8500")),
            "expected Internal containing default-endpoint register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on empty-address async register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_connection_failure_is_internal() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("discover should return internal backend failure");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing get_service_nodes context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_connection_failure_preserves_local_cache() {
        let consul = ConsulDiscovery::new("http://localhost:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("discover should return internal backend failure");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing get_service_nodes context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async failure");
        assert_eq!(
            cached.len(),
            1,
            "async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_connection_failure_is_connection_failed() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err("discover should fail when ZooKeeper is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_connection_failure_preserves_local_cache() {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err("discover should fail when ZooKeeper is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context, got {err:?}"
        );

        let cached = zk
            .discover("ps")
            .expect("discover should succeed after async failure");
        assert_eq!(
            cached.len(),
            1,
            "async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "ps-0");
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_single_ipv6_host_connection_failure_is_connection_failed(
    ) {
        let zk = ZkDiscovery::new("[::1]:1", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err =
            result.expect_err("discover should fail when valid single IPv6 host endpoint is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv6 host discover, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_single_ipv6_host_connection_failure_preserves_local_cache(
    ) {
        let zk = ZkDiscovery::new("[::1]:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err =
            result.expect_err("discover should fail when valid single IPv6 host endpoint is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv6 host discover, got {err:?}"
        );

        let cached = zk
            .discover("ps")
            .expect("discover should succeed after async failure");
        assert_eq!(
            cached.len(),
            1,
            "valid single IPv6 host async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "ps-0");
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_single_ipv4_host_connection_failure_is_connection_failed(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err =
            result.expect_err("discover should fail when valid single IPv4 host endpoint is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv4 host discover, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_single_ipv4_host_connection_failure_preserves_local_cache(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err =
            result.expect_err("discover should fail when valid single IPv4 host endpoint is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single IPv4 host discover, got {err:?}"
        );

        let cached = zk
            .discover("ps")
            .expect("discover should succeed after async failure");
        assert_eq!(
            cached.len(),
            1,
            "valid single IPv4 host async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "ps-0");
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_single_hostname_host_connection_failure_is_connection_failed(
    ) {
        let zk = ZkDiscovery::new("localhost:1", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result
            .expect_err("discover should fail when valid single hostname host endpoint is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single hostname host discover, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_single_hostname_host_connection_failure_preserves_local_cache(
    ) {
        let zk = ZkDiscovery::new("localhost:1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result
            .expect_err("discover should fail when valid single hostname host endpoint is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid single hostname host discover, got {err:?}"
        );

        let cached = zk
            .discover("ps")
            .expect("discover should succeed after async failure");
        assert_eq!(
            cached.len(),
            1,
            "valid single hostname host async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "ps-0");
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_multi_hosts_connection_failure_is_connection_failed() {
        let zk =
            ZkDiscovery::new("127.0.0.1:1,127.0.0.1:2", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result
            .expect_err("discover should fail when valid multi-host endpoints are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid multi-host discover, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_multi_hosts_connection_failure_preserves_local_cache() {
        let zk =
            ZkDiscovery::new("127.0.0.1:1,127.0.0.1:2", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result
            .expect_err("discover should fail when valid multi-host endpoints are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid multi-host discover, got {err:?}"
        );

        let cached = zk
            .discover("ps")
            .expect("discover should succeed after async failure");
        assert_eq!(
            cached.len(),
            1,
            "valid multi-host async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "ps-0");
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_mixed_ipv4_ipv6_hosts_connection_failure_is_connection_failed(
    ) {
        let zk =
            ZkDiscovery::new("[::1]:1,127.0.0.1:2", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result
            .expect_err("discover should fail when valid mixed-family hosts are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid mixed-family discover, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_mixed_ipv4_ipv6_hosts_connection_failure_preserves_local_cache(
    ) {
        let zk =
            ZkDiscovery::new("[::1]:1,127.0.0.1:2", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result
            .expect_err("discover should fail when valid mixed-family hosts are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid mixed-family discover, got {err:?}"
        );

        let cached = zk
            .discover("ps")
            .expect("discover should succeed after async failure");
        assert_eq!(
            cached.len(),
            1,
            "valid mixed-family async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "ps-0");
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_ipv6_multi_hosts_connection_failure_is_connection_failed(
    ) {
        let zk = ZkDiscovery::new("[::1]:1,[::2]:2", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err =
            result.expect_err("discover should fail when valid IPv6 multi-host endpoints are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid IPv6 multi-host discover, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_ipv6_multi_hosts_connection_failure_preserves_local_cache(
    ) {
        let zk = ZkDiscovery::new("[::1]:1,[::2]:2", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err =
            result.expect_err("discover should fail when valid IPv6 multi-host endpoints are unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid IPv6 multi-host discover, got {err:?}"
        );

        let cached = zk
            .discover("ps")
            .expect("discover should succeed after async failure");
        assert_eq!(
            cached.len(),
            1,
            "valid IPv6 multi-host async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "ps-0");
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_host_only_multi_hosts_connection_failure_is_connection_failed()
    {
        let zk = ZkDiscovery::new("127.0.0.1,127.0.0.1", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result
            .expect_err("discover should fail when valid host-only multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only multi-host discover, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_host_only_multi_hosts_connection_failure_preserves_local_cache(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1,127.0.0.1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result
            .expect_err("discover should fail when valid host-only multi-host list is unreachable");
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only multi-host discover, got {err:?}"
        );

        let cached = zk
            .discover("ps")
            .expect("discover should succeed after async failure");
        assert_eq!(
            cached.len(),
            1,
            "valid host-only multi-host async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "ps-0");
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_host_only_mixed_ipv4_ipv6_hosts_connection_failure_is_connection_failed(
    ) {
        let zk = ZkDiscovery::new("[::1],127.0.0.1", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err(
            "discover should fail when valid host-only mixed-family list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only mixed-family discover, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_host_only_mixed_ipv4_ipv6_hosts_connection_failure_preserves_local_cache(
    ) {
        let zk = ZkDiscovery::new("[::1],127.0.0.1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err(
            "discover should fail when valid host-only mixed-family list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only mixed-family discover, got {err:?}"
        );

        let cached = zk
            .discover("ps")
            .expect("discover should succeed after async failure");
        assert_eq!(
            cached.len(),
            1,
            "valid host-only mixed-family async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "ps-0");
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_host_only_ipv6_multi_hosts_connection_failure_is_connection_failed(
    ) {
        let zk = ZkDiscovery::new("[::1],[::2]", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err(
            "discover should fail when valid host-only IPv6 multi-host list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only IPv6 multi-host discover, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_host_only_ipv6_multi_hosts_connection_failure_preserves_local_cache(
    ) {
        let zk = ZkDiscovery::new("[::1],[::2]", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err(
            "discover should fail when valid host-only IPv6 multi-host list is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only IPv6 multi-host discover, got {err:?}"
        );

        let cached = zk
            .discover("ps")
            .expect("discover should succeed after async failure");
        assert_eq!(
            cached.len(),
            1,
            "valid host-only IPv6 multi-host async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "ps-0");
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_host_only_single_ipv6_host_connection_failure_is_connection_failed(
    ) {
        let zk = ZkDiscovery::new("[::1]", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err(
            "discover should fail when valid host-only single IPv6 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv6 host discover, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_host_only_single_ipv6_host_connection_failure_preserves_local_cache(
    ) {
        let zk = ZkDiscovery::new("[::1]", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err(
            "discover should fail when valid host-only single IPv6 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv6 host discover, got {err:?}"
        );

        let cached = zk
            .discover("ps")
            .expect("discover should succeed after async failure");
        assert_eq!(
            cached.len(),
            1,
            "valid host-only single IPv6 host async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "ps-0");
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_host_only_single_ipv4_host_connection_failure_is_connection_failed(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err(
            "discover should fail when valid host-only single IPv4 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv4 host discover, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_host_only_single_ipv4_host_connection_failure_preserves_local_cache(
    ) {
        let zk = ZkDiscovery::new("127.0.0.1", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err(
            "discover should fail when valid host-only single IPv4 host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single IPv4 host discover, got {err:?}"
        );

        let cached = zk
            .discover("ps")
            .expect("discover should succeed after async failure");
        assert_eq!(
            cached.len(),
            1,
            "valid host-only single IPv4 host async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "ps-0");
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_host_only_single_hostname_host_connection_failure_is_connection_failed(
    ) {
        let zk = ZkDiscovery::new("localhost", "/services").with_session_timeout(100);
        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err(
            "discover should fail when valid host-only single hostname host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single hostname host discover, got {err:?}"
        );
    }

    #[cfg(feature = "zookeeper")]
    #[tokio::test]
    async fn test_zk_discover_async_valid_host_only_single_hostname_host_connection_failure_preserves_local_cache(
    ) {
        let zk = ZkDiscovery::new("localhost", "/services").with_session_timeout(100);
        zk.register(ServiceInfo::new("ps-0", "ps-0", "ps", "127.0.0.1", 5000))
            .expect("sync register should seed local cache");

        let result = <ZkDiscovery as ServiceDiscoveryAsync>::discover_async(&zk, "ps").await;
        let err = result.expect_err(
            "discover should fail when valid host-only single hostname host is unreachable",
        );
        assert!(
            matches!(err, DiscoveryError::ConnectionFailed(ref msg) if msg.contains("ZK connect failed")),
            "expected ConnectionFailed containing ZK connect context for valid host-only single hostname host discover, got {err:?}"
        );

        let cached = zk
            .discover("ps")
            .expect("discover should succeed after async failure");
        assert_eq!(
            cached.len(),
            1,
            "valid host-only single hostname host async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "ps-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_config_error_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://[::1");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("invalid Consul address should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address") && msg.contains("register_entity")),
            "expected ConfigError containing invalid-address register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "config-error register failure should compact dead watcher sender"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_config_error_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("http://[::1");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("invalid Consul address should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address") && msg.contains("register_entity")),
            "expected ConfigError containing invalid-address register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on config-error register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_config_error_does_not_cache_service() {
        let consul = ConsulDiscovery::new("http://[::1");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(&consul, service)
            .await;
        let err = result.expect_err("invalid Consul address should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address") && msg.contains("register_entity")),
            "expected ConfigError containing invalid-address register context, got {err:?}"
        );

        assert!(
            consul
                .discover("worker")
                .expect("discover should succeed")
                .is_empty(),
            "config-error register failure should not populate local service cache"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_config_error_is_classified() {
        let consul = ConsulDiscovery::new("http://[::1");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("invalid Consul address should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address") && msg.contains("get_service_nodes")),
            "expected ConfigError containing invalid-address discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_invalid_port_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:notaport");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("invalid-port Consul address should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address") && msg.contains("get_service_nodes")),
            "expected ConfigError containing invalid-port discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_out_of_range_port_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:70000");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("out-of-range authority port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid port")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing out-of-range-port discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_host_port_without_scheme_keeps_port_context() {
        let consul = ConsulDiscovery::new("127.0.0.1:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable host:port Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context and normalized port, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_host_port_without_scheme_preserves_local_cache() {
        let consul = ConsulDiscovery::new("127.0.0.1:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("host:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context and normalized port, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async host:port failure");
        assert_eq!(
            cached.len(),
            1,
            "host:port async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_host_without_port_without_scheme_uses_operation_context() {
        let consul = ConsulDiscovery::new("127.0.0.1");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable host-only Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing discover context for normalized host-only address, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_host_without_port_without_scheme_preserves_local_cache() {
        let consul = ConsulDiscovery::new("127.0.0.1");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("host-only address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing discover context for normalized host-only address, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async host-only failure");
        assert_eq!(
            cached.len(),
            1,
            "host-only async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_host_without_port_without_scheme_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable host-only root-slash Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing discover context for normalized host-only root-slash address, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_host_without_port_without_scheme_and_root_slash_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("host-only root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing discover context for normalized host-only root-slash address, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async host-only root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "host-only root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_host_port_without_scheme_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1:8501/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable host:port root-slash Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context and normalized host port root-slash address, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_host_port_without_scheme_and_root_slash_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("host:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context and normalized host port root-slash address, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async host:port root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "host:port root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_hostname_port_without_scheme_uses_operation_context() {
        let consul = ConsulDiscovery::new("localhost:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable hostname:port Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context and normalized hostname port, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_hostname_port_without_scheme_preserves_local_cache() {
        let consul = ConsulDiscovery::new("localhost:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("hostname:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context and normalized hostname port, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async hostname:port failure");
        assert_eq!(
            cached.len(),
            1,
            "hostname:port async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_hostname_port_without_scheme_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("localhost:8501/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable hostname:port root-slash Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context and normalized hostname port root-slash address, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_hostname_port_without_scheme_and_root_slash_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("localhost:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("hostname:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context and normalized hostname port root-slash address, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async hostname:port root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "hostname:port root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_hostname_without_port_uses_operation_context() {
        let consul = ConsulDiscovery::new("localhost");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable hostname-only Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing discover context for normalized hostname address, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_hostname_without_port_preserves_local_cache() {
        let consul = ConsulDiscovery::new("localhost");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("hostname address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing discover context for normalized hostname address, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async hostname failure");
        assert_eq!(
            cached.len(),
            1,
            "hostname async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_hostname_without_port_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("localhost/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable hostname root-slash Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing discover context for normalized hostname root-slash address, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_hostname_without_port_and_root_slash_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("localhost/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("hostname root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing discover context for normalized hostname root-slash address, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async hostname root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "hostname root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_ipv6_without_port_without_scheme_uses_operation_context() {
        let consul = ConsulDiscovery::new("[::1]");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable IPv6 host-only Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing discover context for normalized IPv6 host-only address, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_ipv6_without_port_without_scheme_preserves_local_cache() {
        let consul = ConsulDiscovery::new("[::1]");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("IPv6 host-only address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing discover context for normalized IPv6 host-only address, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async IPv6 host-only failure");
        assert_eq!(
            cached.len(),
            1,
            "IPv6 host-only async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_ipv6_without_port_without_scheme_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("[::1]/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable IPv6 host-only root-slash Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing discover context for normalized IPv6 host-only root-slash address, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_ipv6_without_port_without_scheme_and_root_slash_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("[::1]/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("IPv6 host-only root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing discover context for normalized IPv6 host-only root-slash address, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async IPv6 host-only root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "IPv6 host-only root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_https_hostname_with_port_uses_operation_context() {
        let consul = ConsulDiscovery::new("https://localhost:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable https hostname Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context for https hostname address, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_https_hostname_with_port_preserves_local_cache() {
        let consul = ConsulDiscovery::new("https://localhost:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("https hostname address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context for https hostname address, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async https hostname failure");
        assert_eq!(
            cached.len(),
            1,
            "https hostname async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_https_hostname_without_port_uses_operation_context() {
        let consul = ConsulDiscovery::new("https://localhost");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable https hostname-only Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing discover context for https hostname-only address, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_https_hostname_without_port_preserves_local_cache() {
        let consul = ConsulDiscovery::new("https://localhost");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("https hostname-only address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing discover context for https hostname-only address, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async https hostname-only failure");
        assert_eq!(
            cached.len(),
            1,
            "https hostname-only async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_https_scheme_uses_operation_context() {
        let consul = ConsulDiscovery::new("https://127.0.0.1:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable https Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context for https address, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_https_scheme_preserves_local_cache() {
        let consul = ConsulDiscovery::new("https://127.0.0.1:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("https address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context for https address, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async https failure");
        assert_eq!(
            cached.len(),
            1,
            "https async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_https_ipv6_with_port_uses_operation_context() {
        let consul = ConsulDiscovery::new("https://[::1]:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable https IPv6 Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context for https IPv6 address, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_https_ipv6_with_port_preserves_local_cache() {
        let consul = ConsulDiscovery::new("https://[::1]:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("https IPv6 address should fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context for https IPv6 address, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async https IPv6 failure");
        assert_eq!(
            cached.len(),
            1,
            "https IPv6 async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_ipv6_with_port_uses_operation_context() {
        let consul = ConsulDiscovery::new("[::1]:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable IPv6 host:port Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context and normalized IPv6 port, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_ipv6_with_port_preserves_local_cache() {
        let consul = ConsulDiscovery::new("[::1]:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err =
            result.expect_err("IPv6 host:port address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context and normalized IPv6 port, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async IPv6 host:port failure");
        assert_eq!(
            cached.len(),
            1,
            "IPv6 host:port async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_ipv6_with_port_and_root_slash_uses_operation_context() {
        let consul = ConsulDiscovery::new("[::1]:8501/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("unreachable IPv6 host:port root-slash Consul address should fail");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context and normalized IPv6 root-slash port, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_ipv6_with_port_and_root_slash_preserves_local_cache() {
        let consul = ConsulDiscovery::new("[::1]:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err =
            result.expect_err("IPv6 host:port root-slash address should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing discover context and normalized IPv6 root-slash port, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async IPv6 host:port root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "IPv6 host:port root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_invalid_scheme_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("ftp://127.0.0.1:8500");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("invalid-scheme Consul address should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid scheme")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing invalid-scheme discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_address_path_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500/v1");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("address path should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("path is not allowed")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing address-path discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_invalid_scheme_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("ftp://127.0.0.1:8500");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul).await;
        let err = result.expect_err("invalid-scheme Consul address should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid scheme")
                    && msg.contains("connect")),
            "expected ConfigError containing invalid-scheme connect context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_host_port_without_scheme_initializes_client_handle() {
        let consul = ConsulDiscovery::new("127.0.0.1:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("host:port address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "host:port connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_host_port_without_scheme_disconnect_and_reconnect() {
        let consul = ConsulDiscovery::new("127.0.0.1:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("host:port address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "host:port connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear host:port-normalized client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("host:port reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for normalized host:port address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_host_without_port_without_scheme_initializes_client_handle() {
        let consul = ConsulDiscovery::new("127.0.0.1");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("host-only address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "host-only connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_host_without_port_without_scheme_disconnect_and_reconnect() {
        let consul = ConsulDiscovery::new("127.0.0.1");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("host-only address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "host-only connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear host-only-normalized client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("host-only reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for normalized host-only address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_host_without_port_without_scheme_and_root_slash_initializes_client_handle(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("host-only root-slash address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "host-only root-slash connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_host_without_port_without_scheme_and_root_slash_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("host-only root-slash address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "host-only root-slash connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear host-only root-slash-normalized client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("host-only root-slash reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for normalized host-only root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_host_port_without_scheme_and_root_slash_initializes_client_handle() {
        let consul = ConsulDiscovery::new("127.0.0.1:8501/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("host:port root-slash address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "host:port root-slash connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_host_port_without_scheme_and_root_slash_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("127.0.0.1:8501/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("host:port root-slash address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "host:port root-slash connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear host:port root-slash-normalized client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("host:port root-slash reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for normalized host:port root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_hostname_port_without_scheme_initializes_client_handle() {
        let consul = ConsulDiscovery::new("localhost:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("hostname:port address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "hostname:port connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_hostname_port_without_scheme_disconnect_and_reconnect() {
        let consul = ConsulDiscovery::new("localhost:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("hostname:port address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "hostname:port connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear hostname:port-normalized client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("hostname:port reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for normalized hostname:port address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_hostname_port_without_scheme_and_root_slash_initializes_client_handle(
    ) {
        let consul = ConsulDiscovery::new("localhost:8501/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect(
                "hostname:port root-slash address should normalize and initialize Consul client handle",
            );
        assert!(
            consul.client.lock().await.is_some(),
            "hostname:port root-slash connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_hostname_port_without_scheme_and_root_slash_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("localhost:8501/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect(
                "hostname:port root-slash address should normalize and initialize Consul client handle",
            );
        assert!(
            consul.client.lock().await.is_some(),
            "hostname:port root-slash connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear hostname:port root-slash-normalized client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("hostname:port root-slash reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for normalized hostname:port root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_hostname_without_port_initializes_client_handle() {
        let consul = ConsulDiscovery::new("localhost");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("hostname address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "hostname connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_hostname_without_port_disconnect_and_reconnect() {
        let consul = ConsulDiscovery::new("localhost");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("hostname address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "hostname connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear hostname-normalized client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("hostname reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for normalized hostname address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_hostname_without_port_and_root_slash_initializes_client_handle() {
        let consul = ConsulDiscovery::new("localhost/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("hostname root-slash address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "hostname root-slash connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_hostname_without_port_and_root_slash_disconnect_and_reconnect() {
        let consul = ConsulDiscovery::new("localhost/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("hostname root-slash address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "hostname root-slash connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear hostname root-slash-normalized client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("hostname root-slash reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for normalized hostname root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_ipv6_without_port_without_scheme_initializes_client_handle() {
        let consul = ConsulDiscovery::new("[::1]");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("IPv6 host-only address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "IPv6 host-only connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_ipv6_without_port_without_scheme_disconnect_and_reconnect() {
        let consul = ConsulDiscovery::new("[::1]");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("IPv6 host-only address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "IPv6 host-only connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear IPv6 host-only normalized client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("IPv6 host-only reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for normalized IPv6 host-only address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_ipv6_without_port_without_scheme_and_root_slash_initializes_client_handle(
    ) {
        let consul = ConsulDiscovery::new("[::1]/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("IPv6 host-only root-slash address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "IPv6 host-only root-slash connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_ipv6_without_port_without_scheme_and_root_slash_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("[::1]/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("IPv6 host-only root-slash address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "IPv6 host-only root-slash connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear IPv6 host-only root-slash normalized client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("IPv6 host-only root-slash reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for normalized IPv6 host-only root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_https_hostname_with_port_initializes_client_handle() {
        let consul = ConsulDiscovery::new("https://localhost:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("https hostname address should initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "https hostname connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_https_hostname_with_port_disconnect_and_reconnect() {
        let consul = ConsulDiscovery::new("https://localhost:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("https hostname address should initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "https hostname connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear https hostname client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("https hostname reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for https hostname address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_https_hostname_without_port_initializes_client_handle() {
        let consul = ConsulDiscovery::new("https://localhost");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("https hostname-only address should initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "https hostname-only connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_https_hostname_without_port_disconnect_and_reconnect() {
        let consul = ConsulDiscovery::new("https://localhost");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("https hostname-only address should initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "https hostname-only connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear https hostname-only client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("https hostname-only reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for https hostname-only address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_https_scheme_initializes_client_handle() {
        let consul = ConsulDiscovery::new("https://127.0.0.1:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("https address should initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "https connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_https_scheme_disconnect_and_reconnect() {
        let consul = ConsulDiscovery::new("https://127.0.0.1:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("https address should initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "https connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear https client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("https reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for https address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_https_ipv6_with_port_initializes_client_handle() {
        let consul = ConsulDiscovery::new("https://[::1]:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("https IPv6 address should initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "https IPv6 connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_https_ipv6_with_port_disconnect_and_reconnect() {
        let consul = ConsulDiscovery::new("https://[::1]:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("https IPv6 address should initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "https IPv6 connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear https IPv6 client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("https IPv6 reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for https IPv6 address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_ipv6_with_port_initializes_client_handle() {
        let consul = ConsulDiscovery::new("[::1]:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("IPv6 host:port address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "IPv6 host:port connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_ipv6_with_port_disconnect_and_reconnect() {
        let consul = ConsulDiscovery::new("[::1]:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("IPv6 host:port address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "IPv6 host:port connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear IPv6 host:port-normalized client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("IPv6 host:port reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for normalized IPv6 host:port address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_ipv6_with_port_and_root_slash_initializes_client_handle() {
        let consul = ConsulDiscovery::new("[::1]:8501/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("IPv6 host:port root-slash address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "IPv6 host:port root-slash connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_ipv6_with_port_and_root_slash_disconnect_and_reconnect() {
        let consul = ConsulDiscovery::new("[::1]:8501/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("IPv6 host:port root-slash address should normalize and initialize Consul client handle");
        assert!(
            consul.client.lock().await.is_some(),
            "IPv6 host:port root-slash connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear IPv6 host:port root-slash-normalized client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("IPv6 host:port root-slash reconnect should recreate client handle after disconnect");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should reinitialize client handle for normalized IPv6 host:port root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_invalid_port_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:notaport");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul).await;
        let err = result.expect_err("invalid-port authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid port")
                    && msg.contains("connect")),
            "expected ConfigError containing invalid-port connect context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_out_of_range_port_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:70000");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul).await;
        let err = result.expect_err("out-of-range authority port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid port")
                    && msg.contains("connect")),
            "expected ConfigError containing out-of-range-port connect context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_leading_trailing_whitespace_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new(" http://127.0.0.1:8500 ");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul).await;
        let err = result.expect_err("leading/trailing whitespace should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("leading/trailing whitespace")
                    && msg.contains("connect")),
            "expected ConfigError containing leading/trailing-whitespace connect context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_and_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result
            .expect_err("case-insensitive https scheme + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_and_root_slash_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result
            .expect_err("case-insensitive https scheme + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized case-insensitive https failure");
        assert_eq!(
            cached.len(),
            1,
            "normalized case-insensitive https async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_and_root_slash_ipv6_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https IPv6 authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https IPv6 root-slash discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_and_root_slash_ipv6_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https IPv6 authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https IPv6 root-slash discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized case-insensitive https IPv6 failure");
        assert_eq!(
            cached.len(),
            1,
            "normalized case-insensitive https IPv6 root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_no_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https scheme without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https discover context without root slash, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_no_root_slash_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https scheme without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https discover context without root slash, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized case-insensitive https failure without root slash");
        assert_eq!(
            cached.len(),
            1,
            "normalized case-insensitive https async discover failure without root slash should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_ipv6_no_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https IPv6 authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https IPv6 discover context without root slash, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_ipv6_no_root_slash_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https IPv6 authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https IPv6 discover context without root slash, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized case-insensitive https IPv6 failure without root slash");
        assert_eq!(
            cached.len(),
            1,
            "normalized case-insensitive https IPv6 async discover failure without root slash should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_and_root_slash_hostname_with_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https hostname root-slash discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_and_root_slash_hostname_with_port_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https hostname root-slash discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized case-insensitive https hostname failure");
        assert_eq!(
            cached.len(),
            1,
            "normalized case-insensitive https hostname root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_hostname_with_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https hostname discover context without root slash, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_hostname_with_port_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized case-insensitive https hostname discover context without root slash, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized case-insensitive https hostname failure without root slash");
        assert_eq!(
            cached.len(),
            1,
            "normalized case-insensitive https hostname async discover failure without root slash should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_and_root_slash_hostname_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized case-insensitive https hostname-only root-slash discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_and_root_slash_host_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https host-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized case-insensitive https host-only root-slash discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_and_root_slash_host_without_port_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https host-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized case-insensitive https host-only root-slash discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized case-insensitive https host-only root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "normalized case-insensitive https host-only root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_and_root_slash_hostname_without_port_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized case-insensitive https hostname-only root-slash discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized case-insensitive https hostname-only failure");
        assert_eq!(
            cached.len(),
            1,
            "normalized case-insensitive https hostname-only root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_host_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https host-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized case-insensitive https host-only discover context without root slash, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_host_without_port_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https host-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized case-insensitive https host-only discover context without root slash, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized case-insensitive https host-only failure without root slash");
        assert_eq!(
            cached.len(),
            1,
            "normalized case-insensitive https host-only async discover failure without root slash should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_hostname_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized case-insensitive https hostname-only discover context without root slash, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_https_scheme_hostname_without_port_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive https hostname-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized case-insensitive https hostname-only discover context without root slash, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized case-insensitive https hostname-only failure without root slash");
        assert_eq!(
            cached.len(),
            1,
            "normalized case-insensitive https hostname-only async discover failure without root slash should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_address_path_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500/v1");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul).await;
        let err = result.expect_err("address path should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("path is not allowed")
                    && msg.contains("connect")),
            "expected ConfigError containing address-path connect context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_address_query_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500?dc=prod");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul).await;
        let err = result.expect_err("address query should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("query is not allowed")
                    && msg.contains("connect")),
            "expected ConfigError containing address-query connect context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_address_fragment_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500#consul");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul).await;
        let err = result.expect_err("address fragment should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("fragment is not allowed")
                    && msg.contains("connect")),
            "expected ConfigError containing address-fragment connect context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_userinfo_authority_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://user@127.0.0.1:8500");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul).await;
        let err = result.expect_err("userinfo authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("userinfo in authority")
                    && msg.contains("connect")),
            "expected ConfigError containing userinfo-authority connect context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_whitespace_authority_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1 :8500");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul).await;
        let err = result.expect_err("whitespace authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("whitespace in authority")
                    && msg.contains("connect")),
            "expected ConfigError containing whitespace-authority connect context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_address_query_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500?dc=prod");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("address query should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("query is not allowed")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing address-query discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_leading_trailing_whitespace_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new(" http://127.0.0.1:8500 ");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("leading/trailing whitespace should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("leading/trailing whitespace")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing leading/trailing-whitespace discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_address_fragment_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500#consul");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("address fragment should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("fragment is not allowed")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing address-fragment discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_empty_host_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://:8500");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul).await;
        let err = result.expect_err("empty-host authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("empty host")
                    && msg.contains("connect")),
            "expected ConfigError containing empty-host connect context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_invalid_ipv6_suffix_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://[::1]x:8500");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul).await;
        let err = result.expect_err("invalid IPv6 suffix authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid authority")
                    && msg.contains("connect")),
            "expected ConfigError containing invalid-IPv6-suffix connect context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_no_root_slash_succeeds() {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1:8500");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive scheme without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized no-root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_no_root_slash_disconnect_and_reconnect() {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1:8500");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive scheme without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized no-root-slash client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized no-root-slash address");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized no-root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_ipv6_no_root_slash_succeeds() {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive IPv6 authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized IPv6 no-root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_ipv6_no_root_slash_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive IPv6 authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized IPv6 no-root-slash client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized IPv6 no-root-slash address");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized IPv6 no-root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_host_without_port_succeeds() {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive host-only authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized host-only no-root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_host_without_port_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive host-only authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized host-only no-root-slash client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized host-only no-root-slash address");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized host-only no-root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_and_root_slash_host_without_port_succeeds() {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive host-only authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized host-only root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_and_root_slash_host_without_port_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive host-only authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized host-only root-slash client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized host-only root-slash address");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized host-only root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_hostname_without_port_succeeds() {
        let consul = ConsulDiscovery::new("HtTp://localhost");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive hostname-only authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized hostname-only no-root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_hostname_without_port_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive hostname-only authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized hostname-only no-root-slash client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized hostname-only no-root-slash address");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized hostname-only no-root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_and_root_slash_hostname_without_port_succeeds(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive hostname-only authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized hostname-only root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_and_root_slash_hostname_without_port_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive hostname-only authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized hostname-only root-slash client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect(
                "reconnect should reinitialize client handle for normalized hostname-only root-slash address",
            );
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized hostname-only root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_hostname_with_port_succeeds() {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive hostname authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized hostname no-root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_hostname_with_port_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive hostname authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized hostname no-root-slash client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized hostname no-root-slash address");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized hostname no-root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_and_root_slash_hostname_with_port_succeeds(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive hostname authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized hostname root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_and_root_slash_hostname_with_port_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive hostname authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized hostname root-slash client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized hostname root-slash address");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized hostname root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_and_root_slash_succeeds() {
        let consul = ConsulDiscovery::new("HTTP://127.0.0.1:8500/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive scheme and root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_and_root_slash_ipv6_succeeds() {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive IPv6 authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized IPv6 root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_and_root_slash_ipv6_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive IPv6 authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized IPv6 root-slash client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized IPv6 root-slash address");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized IPv6 root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_scheme_and_root_slash_disconnect_and_reconnect() {
        let consul = ConsulDiscovery::new("HTTP://127.0.0.1:8500/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive scheme and root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized case-insensitive root-slash client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized address");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized case-insensitive root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_and_root_slash_succeeds() {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https scheme and root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_and_root_slash_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https scheme and root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized case-insensitive https root-slash client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized https address");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized case-insensitive https root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_and_root_slash_ipv6_succeeds() {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https IPv6 authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized case-insensitive https IPv6 root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_and_root_slash_ipv6_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https IPv6 authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized case-insensitive https IPv6 root-slash client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized case-insensitive https IPv6 root-slash address");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized case-insensitive https IPv6 root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_no_root_slash_succeeds() {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https scheme without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized case-insensitive https address without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_no_root_slash_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https scheme without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized case-insensitive https client handle without root slash"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized case-insensitive https address without root slash");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized case-insensitive https address without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_ipv6_no_root_slash_succeeds() {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https IPv6 authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized case-insensitive https IPv6 address without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_ipv6_no_root_slash_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://[::1]:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https IPv6 authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized case-insensitive https IPv6 client handle without root slash"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized case-insensitive https IPv6 address without root slash");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized case-insensitive https IPv6 address without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_and_root_slash_hostname_with_port_succeeds(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https hostname authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized case-insensitive https hostname root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_and_root_slash_hostname_with_port_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https hostname authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized case-insensitive https hostname root-slash client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized case-insensitive https hostname root-slash address");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized case-insensitive https hostname root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_hostname_with_port_succeeds() {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https hostname authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized case-insensitive https hostname address without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_hostname_with_port_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost:8501");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https hostname authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized case-insensitive https hostname client handle without root slash"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized case-insensitive https hostname address without root slash");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized case-insensitive https hostname address without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_and_root_slash_hostname_without_port_succeeds(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https hostname-only authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized case-insensitive https hostname-only root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_and_root_slash_host_without_port_succeeds(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https host-only authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized case-insensitive https host-only root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_and_root_slash_host_without_port_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https host-only authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized case-insensitive https host-only root-slash client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized case-insensitive https host-only root-slash address");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized case-insensitive https host-only root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_and_root_slash_hostname_without_port_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost/");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https hostname-only authority with root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized case-insensitive https hostname-only root-slash client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized case-insensitive https hostname-only root-slash address");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized case-insensitive https hostname-only root-slash address"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_host_without_port_succeeds() {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https host-only authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized case-insensitive https host-only address without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_host_without_port_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://127.0.0.1");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https host-only authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized case-insensitive https host-only client handle without root slash"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized case-insensitive https host-only address without root slash");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized case-insensitive https host-only address without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_hostname_without_port_succeeds() {
        let consul = ConsulDiscovery::new("HtTpS://localhost");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https hostname-only authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle for normalized case-insensitive https hostname-only address without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_case_insensitive_https_scheme_hostname_without_port_disconnect_and_reconnect(
    ) {
        let consul = ConsulDiscovery::new("HtTpS://localhost");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("case-insensitive https hostname-only authority without root slash should be accepted");
        assert!(
            consul.client.lock().await.is_some(),
            "successful connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear normalized case-insensitive https hostname-only client handle without root slash"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for normalized case-insensitive https hostname-only address without root slash");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for normalized case-insensitive https hostname-only address without root slash"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_empty_address_initializes_default_client_handle() {
        let consul = ConsulDiscovery::new("");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("empty address should normalize to default Consul endpoint");
        assert!(
            consul.client.lock().await.is_some(),
            "empty-address connect should initialize client handle using default endpoint"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_connect_empty_address_disconnect_and_reconnect() {
        let consul = ConsulDiscovery::new("");
        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("empty address should normalize to default Consul endpoint");
        assert!(
            consul.client.lock().await.is_some(),
            "empty-address connect should initialize client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::disconnect(&consul)
            .await
            .expect("disconnect should succeed");
        assert!(
            consul.client.lock().await.is_none(),
            "disconnect should clear empty-address normalized client handle"
        );

        <ConsulDiscovery as ServiceDiscoveryAsync>::connect(&consul)
            .await
            .expect("reconnect should reinitialize client handle for empty-address normalization");
        assert!(
            consul.client.lock().await.is_some(),
            "reconnect should recreate client handle for empty-address normalized endpoint"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_whitespace_authority_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1 :8500");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("whitespace authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("whitespace in authority")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing whitespace-authority discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_userinfo_authority_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://user@127.0.0.1:8500");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("userinfo authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("userinfo in authority")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing userinfo-authority discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_empty_address_uses_default_endpoint_context() {
        let consul = ConsulDiscovery::new("");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("empty-address discover should fail against local endpoint");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8500")),
            "expected Internal containing default-endpoint discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_empty_address_preserves_local_cache() {
        let consul = ConsulDiscovery::new("");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("empty-address discover should fail against default endpoint");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8500")),
            "expected Internal containing default-endpoint discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async empty-address failure");
        assert_eq!(
            cached.len(),
            1,
            "empty-address async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_no_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1:8500");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result
            .expect_err("case-insensitive scheme without root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8500")),
            "expected Internal containing normalized no-root-slash discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_no_root_slash_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result
            .expect_err("case-insensitive scheme without root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8500")),
            "expected Internal containing normalized no-root-slash discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized no-root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "normalized no-root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_ipv6_no_root_slash_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive IPv6 authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 no-root-slash discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_ipv6_no_root_slash_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive IPv6 authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 no-root-slash discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized IPv6 no-root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "normalized IPv6 no-root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_host_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive host-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized host-only no-root-slash discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_host_without_port_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive host-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized host-only no-root-slash discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized host-only no-root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "normalized host-only no-root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_and_root_slash_host_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive host-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized host-only root-slash discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_and_root_slash_host_without_port_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTp://127.0.0.1/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive host-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized host-only root-slash discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized host-only root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "normalized host-only root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_hostname_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive hostname-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized hostname-only no-root-slash discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_hostname_without_port_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive hostname-only authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized hostname-only no-root-slash discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized hostname-only no-root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "normalized hostname-only no-root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_and_root_slash_hostname_without_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive hostname-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized hostname-only root-slash discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_and_root_slash_hostname_without_port_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive hostname-only authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg) if msg.contains("get_service_nodes")),
            "expected Internal containing normalized hostname-only root-slash discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized hostname-only root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "normalized hostname-only root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_hostname_with_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive hostname authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8500")),
            "expected Internal containing normalized hostname no-root-slash discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_hostname_with_port_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive hostname authority without root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8500")),
            "expected Internal containing normalized hostname no-root-slash discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized hostname no-root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "normalized hostname no-root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_and_root_slash_hostname_with_port_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result
            .expect_err("case-insensitive hostname authority + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8500")),
            "expected Internal containing normalized hostname root-slash discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_and_root_slash_hostname_with_port_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HtTp://localhost:8500/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result
            .expect_err("case-insensitive hostname authority + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8500")),
            "expected Internal containing normalized hostname root-slash discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized hostname root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "normalized hostname root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_and_root_slash_uses_operation_context() {
        let consul = ConsulDiscovery::new("HTTP://127.0.0.1:8500/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("case-insensitive scheme + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8500")),
            "expected Internal containing normalized-root-slash discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_and_root_slash_ipv6_uses_operation_context(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501/");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive IPv6 authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 root-slash discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_and_root_slash_ipv6_preserves_local_cache(
    ) {
        let consul = ConsulDiscovery::new("HTTP://[::1]:8501/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err(
            "case-insensitive IPv6 authority + root slash should normalize and fail in backend call",
        );
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8501")),
            "expected Internal containing normalized IPv6 root-slash discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized IPv6 root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "normalized IPv6 root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_case_insensitive_scheme_and_root_slash_preserves_local_cache() {
        let consul = ConsulDiscovery::new("HTTP://127.0.0.1:8500/");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("case-insensitive scheme + root slash should normalize and fail in backend call");
        assert!(
            matches!(err, DiscoveryError::Internal(ref msg)
                if msg.contains("get_service_nodes") && msg.contains("8500")),
            "expected Internal containing normalized-root-slash discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async normalized-root-slash failure");
        assert_eq!(
            cached.len(),
            1,
            "normalized-root-slash async discover failure should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_invalid_ipv6_suffix_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://[::1]x:8500");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("invalid IPv6 suffix should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid authority")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing invalid-IPv6-suffix discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_invalid_scheme_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("ftp://127.0.0.1:8500");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("invalid scheme should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid scheme")
                    && msg.contains("register_entity")),
            "expected ConfigError containing invalid-scheme register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on invalid-scheme register validation failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_invalid_scheme_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("ftp://127.0.0.1:8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("invalid scheme should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid scheme")
                    && msg.contains("register_entity")),
            "expected ConfigError containing invalid-scheme register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on invalid-scheme register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_invalid_ipv6_suffix_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://[::1]x:8500");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("invalid IPv6 suffix should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid authority")
                    && msg.contains("register_entity")),
            "expected ConfigError containing invalid-IPv6-suffix register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on invalid-IPv6-suffix register validation failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_invalid_ipv6_suffix_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("http://[::1]x:8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("invalid IPv6 suffix should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid authority")
                    && msg.contains("register_entity")),
            "expected ConfigError containing invalid-IPv6-suffix register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on invalid-IPv6-suffix register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_address_fragment_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500#consul");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("address fragment should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("fragment is not allowed")
                    && msg.contains("register_entity")),
            "expected ConfigError containing address-fragment register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on address-fragment register validation failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_address_path_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500/v1");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("address path should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("path is not allowed")
                    && msg.contains("register_entity")),
            "expected ConfigError containing address-path register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on address-path register validation failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_address_query_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500?dc=prod");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("address query should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("query is not allowed")
                    && msg.contains("register_entity")),
            "expected ConfigError containing address-query register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on address-query register validation failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_address_query_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500?dc=prod");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("address query should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("query is not allowed")
                    && msg.contains("register_entity")),
            "expected ConfigError containing address-query register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on address-query register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_address_fragment_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500#consul");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("address fragment should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("fragment is not allowed")
                    && msg.contains("register_entity")),
            "expected ConfigError containing address-fragment register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on address-fragment register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_address_path_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500/v1");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("address path should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("path is not allowed")
                    && msg.contains("register_entity")),
            "expected ConfigError containing address-path register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on address-path register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_invalid_scheme_still_notifies_and_returns_error() {
        let consul = ConsulDiscovery::new("ftp://127.0.0.1:8500");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id).await;
        let err = result.expect_err("invalid-scheme address should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid scheme")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing invalid-scheme deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == &service.id),
            "expected ServiceRemoved({}), got {event:?}",
            service.id
        );
        assert!(
            consul
                .discover("worker")
                .expect("sync discover should succeed after async deregister failure")
                .is_empty(),
            "local cache entry should remain removed even when async deregister fails due to invalid scheme"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved after invalid-scheme deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_invalid_scheme_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("ftp://127.0.0.1:8500");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("invalid-scheme address should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid scheme")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing invalid-scheme deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "invalid-scheme deregister should compact dead watcher sender entries"
        );
        assert!(
            consul
                .discover("worker")
                .expect("sync discover should succeed after async deregister failure")
                .is_empty(),
            "local cache entry should remain removed even when invalid-scheme deregister fails"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_invalid_port_still_notifies_and_returns_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:notaport");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("invalid-port authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid port")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing invalid-port deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == &service.id),
            "expected ServiceRemoved({}), got {event:?}",
            service.id
        );
        assert!(
            consul
                .discover("worker")
                .expect("sync discover should succeed after async deregister failure")
                .is_empty(),
            "local cache entry should remain removed even when async deregister fails due to invalid port"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved after invalid-port deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_invalid_port_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:notaport");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("invalid-port authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid port")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing invalid-port deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on invalid-port deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_out_of_range_port_still_notifies_and_returns_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:70000");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("out-of-range authority port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid port")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing out-of-range-port deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == &service.id),
            "expected ServiceRemoved({}), got {event:?}",
            service.id
        );
        assert!(
            consul
                .discover("worker")
                .expect("sync discover should succeed after async deregister failure")
                .is_empty(),
            "local cache entry should remain removed even when async deregister fails due to out-of-range port"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved after out-of-range-port deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_out_of_range_port_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:70000");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("out-of-range authority port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid port")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing out-of-range-port deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on out-of-range-port deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_invalid_ipv6_suffix_still_notifies_and_returns_error() {
        let consul = ConsulDiscovery::new("http://[::1]x:8500");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("invalid IPv6 suffix authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid authority")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing invalid-IPv6-suffix deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == &service.id),
            "expected ServiceRemoved({}), got {event:?}",
            service.id
        );
        assert!(
            consul
                .discover("worker")
                .expect("sync discover should succeed after async deregister failure")
                .is_empty(),
            "local cache entry should remain removed even when async deregister fails due to invalid IPv6 suffix"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved after invalid-IPv6-suffix deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_invalid_ipv6_suffix_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://[::1]x:8500");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("invalid IPv6 suffix authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid authority")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing invalid-IPv6-suffix deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on invalid-IPv6-suffix deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_userinfo_authority_still_notifies_and_returns_error() {
        let consul = ConsulDiscovery::new("http://user@127.0.0.1:8500");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id).await;
        let err = result.expect_err("userinfo authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("userinfo in authority")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing userinfo-authority deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == &service.id),
            "expected ServiceRemoved({}), got {event:?}",
            service.id
        );
        assert!(
            consul
                .discover("worker")
                .expect("sync discover should succeed after async deregister failure")
                .is_empty(),
            "local cache entry should remain removed even when async deregister fails due to userinfo authority"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved after userinfo-authority deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_userinfo_authority_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://user@127.0.0.1:8500");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("userinfo authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("userinfo in authority")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing userinfo-authority deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on userinfo-authority deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_whitespace_authority_still_notifies_and_returns_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1 :8500");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id).await;
        let err = result.expect_err("whitespace authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("whitespace in authority")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing whitespace-authority deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == &service.id),
            "expected ServiceRemoved({}), got {event:?}",
            service.id
        );
        assert!(
            consul
                .discover("worker")
                .expect("sync discover should succeed after async deregister failure")
                .is_empty(),
            "local cache entry should remain removed even when async deregister fails due to whitespace authority"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved after whitespace-authority deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_whitespace_authority_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1 :8500");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("whitespace authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("whitespace in authority")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing whitespace-authority deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on whitespace-authority deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_leading_trailing_whitespace_still_notifies_and_returns_error() {
        let consul = ConsulDiscovery::new(" http://127.0.0.1:8500 ");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("leading/trailing whitespace should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("leading/trailing whitespace")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing leading/trailing-whitespace deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == &service.id),
            "expected ServiceRemoved({}), got {event:?}",
            service.id
        );
        assert!(
            consul
                .discover("worker")
                .expect("sync discover should succeed after async deregister failure")
                .is_empty(),
            "local cache entry should remain removed even when async deregister fails due to leading/trailing whitespace"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved after leading/trailing-whitespace deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_leading_trailing_whitespace_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new(" http://127.0.0.1:8500 ");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("leading/trailing whitespace should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("leading/trailing whitespace")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing leading/trailing-whitespace deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on leading/trailing-whitespace deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_empty_host_still_notifies_and_returns_error() {
        let consul = ConsulDiscovery::new("http://:8500");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("empty-host authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("empty host")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing empty-host deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == &service.id),
            "expected ServiceRemoved({}), got {event:?}",
            service.id
        );
        assert!(
            consul
                .discover("worker")
                .expect("sync discover should succeed after async deregister failure")
                .is_empty(),
            "local cache entry should remain removed even when async deregister fails due to empty host"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved after empty-host deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_empty_host_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://:8500");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("empty-host authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("empty host")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing empty-host deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on empty-host deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_address_query_still_notifies_and_returns_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500?dc=prod");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("address query should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("query is not allowed")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing address-query deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == &service.id),
            "expected ServiceRemoved({}), got {event:?}",
            service.id
        );
        assert!(
            consul
                .discover("worker")
                .expect("sync discover should succeed after async deregister failure")
                .is_empty(),
            "local cache entry should remain removed even when async deregister fails due to address query"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved after address-query deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_address_query_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500?dc=prod");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("address query should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("query is not allowed")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing address-query deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "address-query deregister should compact dead watcher sender entries"
        );
        assert!(
            consul
                .discover("worker")
                .expect("sync discover should succeed after async deregister failure")
                .is_empty(),
            "local cache entry should remain removed even when address-query deregister fails"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_address_fragment_still_notifies_and_returns_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500#consul");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("address fragment should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("fragment is not allowed")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing address-fragment deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == &service.id),
            "expected ServiceRemoved({}), got {event:?}",
            service.id
        );
        assert!(
            consul
                .discover("worker")
                .expect("sync discover should succeed after async deregister failure")
                .is_empty(),
            "local cache entry should remain removed even when async deregister fails due to address fragment"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved after address-fragment deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_address_fragment_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500#consul");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("address fragment should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("fragment is not allowed")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing address-fragment deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on address-fragment deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_address_path_still_notifies_and_returns_error() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500/v1");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let mut rx = consul.watch("worker").expect("watch should succeed");

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("address path should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("path is not allowed")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing address-path deregister context, got {err:?}"
        );

        let event = tokio::time::timeout(std::time::Duration::from_millis(200), rx.recv())
            .await
            .expect("timed out waiting for ServiceRemoved")
            .expect("watch channel closed unexpectedly");
        assert!(
            matches!(event, DiscoveryEvent::ServiceRemoved(ref id) if id == &service.id),
            "expected ServiceRemoved({}), got {event:?}",
            service.id
        );
        assert!(
            consul
                .discover("worker")
                .expect("sync discover should succeed after async deregister failure")
                .is_empty(),
            "local cache entry should remain removed even when async deregister fails due to address path"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved after address-path deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_deregister_address_path_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500/v1");
        let service = ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000);
        consul
            .register(service.clone())
            .expect("sync register should seed local cache");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result =
            <ConsulDiscovery as ServiceDiscoveryAsync>::deregister_async(&consul, &service.id)
                .await;
        let err = result.expect_err("address path should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("path is not allowed")
                    && msg.contains("deregister_entity")),
            "expected ConfigError containing address-path deregister context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on address-path deregister notification"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_empty_host_is_classified_as_config_error() {
        let consul = ConsulDiscovery::new("http://:8500");
        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("empty-host authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("empty host")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing empty-host discover context, got {err:?}"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_empty_host_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://:8500");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("empty-host authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("empty host")
                    && msg.contains("register_entity")),
            "expected ConfigError containing empty-host register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on empty-host register validation failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_empty_host_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("http://:8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("empty-host authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("empty host")
                    && msg.contains("register_entity")),
            "expected ConfigError containing empty-host register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on empty-host register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_invalid_port_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:notaport");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("invalid-port authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid port")
                    && msg.contains("register_entity")),
            "expected ConfigError containing invalid-port register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on invalid-port register validation failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_out_of_range_port_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:70000");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("out-of-range authority port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid port")
                    && msg.contains("register_entity")),
            "expected ConfigError containing out-of-range-port register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on out-of-range-port register validation failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_out_of_range_port_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:70000");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("out-of-range authority port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid port")
                    && msg.contains("register_entity")),
            "expected ConfigError containing out-of-range-port register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on out-of-range-port register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_invalid_port_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:notaport");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("invalid-port authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid port")
                    && msg.contains("register_entity")),
            "expected ConfigError containing invalid-port register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on invalid-port register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_userinfo_authority_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://user@127.0.0.1:8500");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("userinfo authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("userinfo in authority")
                    && msg.contains("register_entity")),
            "expected ConfigError containing userinfo-authority register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on userinfo-authority register validation failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_userinfo_authority_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("http://user@127.0.0.1:8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("userinfo authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("userinfo in authority")
                    && msg.contains("register_entity")),
            "expected ConfigError containing userinfo-authority register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on userinfo-authority register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_whitespace_authority_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1 :8500");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("whitespace authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("whitespace in authority")
                    && msg.contains("register_entity")),
            "expected ConfigError containing whitespace-authority register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on whitespace-authority register validation failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_whitespace_authority_keeps_live_watchers() {
        let consul = ConsulDiscovery::new("http://127.0.0.1 :8500");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("whitespace authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("whitespace in authority")
                    && msg.contains("register_entity")),
            "expected ConfigError containing whitespace-authority register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on whitespace-authority register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_leading_trailing_whitespace_compacts_dead_watchers() {
        let consul = ConsulDiscovery::new(" http://127.0.0.1:8500 ");
        let rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );
        drop(rx);

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("leading/trailing whitespace should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("leading/trailing whitespace")
                    && msg.contains("register_entity")),
            "expected ConfigError containing leading/trailing-whitespace register context, got {err:?}"
        );
        assert!(
            !consul_has_watcher(&consul, "worker"),
            "dead watch sender should be compacted on leading/trailing-whitespace register validation failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_async_register_leading_trailing_whitespace_keeps_live_watchers() {
        let consul = ConsulDiscovery::new(" http://127.0.0.1:8500 ");
        let _rx = consul.watch("worker").expect("watch should succeed");
        assert!(
            consul_has_watcher(&consul, "worker"),
            "watch sender should exist after subscribing"
        );

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::register_async(
            &consul,
            ServiceInfo::new("worker-0", "worker-0", "worker", "127.0.0.1", 6000),
        )
        .await;
        let err = result.expect_err("leading/trailing whitespace should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("leading/trailing whitespace")
                    && msg.contains("register_entity")),
            "expected ConfigError containing leading/trailing-whitespace register context, got {err:?}"
        );
        assert!(
            consul_has_watcher(&consul, "worker"),
            "live watcher sender should be preserved on leading/trailing-whitespace register failure"
        );
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_config_error_preserves_local_cache() {
        let consul = ConsulDiscovery::new("http://[::1");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("invalid Consul address should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address") && msg.contains("get_service_nodes")),
            "expected ConfigError containing invalid-address discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async config error");
        assert_eq!(
            cached.len(),
            1,
            "async discover config error should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_out_of_range_port_preserves_local_cache() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:70000");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("out-of-range authority port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid port")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing out-of-range-port discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async out-of-range-port config error");
        assert_eq!(
            cached.len(),
            1,
            "out-of-range-port async discover config error should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_address_path_preserves_local_cache() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500/v1");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("address path should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("path is not allowed")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing address-path discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async address-path config error");
        assert_eq!(
            cached.len(),
            1,
            "address-path async discover config error should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_invalid_ipv6_suffix_preserves_local_cache() {
        let consul = ConsulDiscovery::new("http://[::1]x:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("invalid IPv6 suffix authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid authority")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing invalid-IPv6-suffix discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async invalid-IPv6-suffix config error");
        assert_eq!(
            cached.len(),
            1,
            "invalid-IPv6-suffix async discover config error should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_leading_trailing_whitespace_preserves_local_cache() {
        let consul = ConsulDiscovery::new(" http://127.0.0.1:8500 ");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("leading/trailing whitespace should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("leading/trailing whitespace")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing leading/trailing-whitespace discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async leading/trailing-whitespace config error");
        assert_eq!(
            cached.len(),
            1,
            "leading/trailing-whitespace async discover config error should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_address_query_preserves_local_cache() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500?dc=prod");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("address query should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("query is not allowed")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing address-query discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async address-query config error");
        assert_eq!(
            cached.len(),
            1,
            "address-query async discover config error should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_address_fragment_preserves_local_cache() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:8500#consul");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("address fragment should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("fragment is not allowed")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing address-fragment discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async address-fragment config error");
        assert_eq!(
            cached.len(),
            1,
            "address-fragment async discover config error should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_empty_host_preserves_local_cache() {
        let consul = ConsulDiscovery::new("http://:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("empty-host authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("empty host")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing empty-host discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async empty-host config error");
        assert_eq!(
            cached.len(),
            1,
            "empty-host async discover config error should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_invalid_scheme_preserves_local_cache() {
        let consul = ConsulDiscovery::new("ftp://127.0.0.1:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("invalid scheme should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid scheme")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing invalid-scheme discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async invalid-scheme config error");
        assert_eq!(
            cached.len(),
            1,
            "invalid-scheme async discover config error should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_invalid_port_preserves_local_cache() {
        let consul = ConsulDiscovery::new("http://127.0.0.1:notaport");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("invalid authority port should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("invalid port")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing invalid-port discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async invalid-port config error");
        assert_eq!(
            cached.len(),
            1,
            "invalid-port async discover config error should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_userinfo_authority_preserves_local_cache() {
        let consul = ConsulDiscovery::new("http://user@127.0.0.1:8500");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("userinfo authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("userinfo in authority")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing userinfo-authority discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async userinfo-authority config error");
        assert_eq!(
            cached.len(),
            1,
            "userinfo-authority async discover config error should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }

    #[cfg(feature = "consul")]
    #[tokio::test]
    async fn test_consul_discover_async_whitespace_authority_preserves_local_cache() {
        let consul = ConsulDiscovery::new("http://127.0.0.1 :8500");
        consul
            .register(ServiceInfo::new(
                "worker-0", "worker-0", "worker", "127.0.0.1", 6000,
            ))
            .expect("sync register should seed local cache");

        let result = <ConsulDiscovery as ServiceDiscoveryAsync>::discover_async(&consul, "worker")
            .await;
        let err = result.expect_err("whitespace authority should return config error");
        assert!(
            matches!(err, DiscoveryError::ConfigError(ref msg)
                if msg.contains("invalid address")
                    && msg.contains("whitespace in authority")
                    && msg.contains("get_service_nodes")),
            "expected ConfigError containing whitespace-authority discover context, got {err:?}"
        );

        let cached = consul
            .discover("worker")
            .expect("discover should succeed after async whitespace-authority config error");
        assert_eq!(
            cached.len(),
            1,
            "whitespace-authority async discover config error should not evict local cache entries"
        );
        assert_eq!(cached[0].id, "worker-0");
    }
}
